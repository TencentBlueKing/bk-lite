import { useRef, useState } from 'react';
import { Toast } from 'antd-mobile';
import { invoke } from '@tauri-apps/api/core';

interface UseSpeechRecognitionReturn {
    recognizedText: string;
    setRecognizedText: (text: string) => void;
    initSpeechRecognition: () => void;
    startSpeechRecognition: () => Promise<void>;
    stopSpeechRecognition: () => void;
    checkMicrophonePermissionSilent: () => Promise<boolean>;
}

export const useSpeechRecognition = (
    isLongPressRef: React.MutableRefObject<boolean>,
    isRecordingRef: React.MutableRefObject<boolean>
): UseSpeechRecognitionReturn => {
    const recognitionRef = useRef<any>(null);
    const [recognizedText, setRecognizedText] = useState('');

    // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
    const initSpeechRecognition = () => {
        if (!recognitionRef.current) {
            const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

            if (SpeechRecognition) {
                const recognition = new SpeechRecognition();
                recognition.lang = 'zh-CN';
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.maxAlternatives = 1;

                recognition.onstart = () => {
                    console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨');
                };

                recognition.onresult = (event: any) => {
                    let allText = '';
                    for (let i = 0; i < event.results.length; i++) {
                        allText += event.results[i][0].transcript;
                    }
                    setRecognizedText(allText);
                    console.log('ğŸ“ è¯†åˆ«ç»“æœ:', allText);
                };

                recognition.onerror = (event: any) => {
                    console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);

                    let errorMessage = '';
                    switch (event.error) {
                        case 'not-allowed':
                            errorMessage = 'è¯·å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£æƒé™';
                            break;
                        case 'no-speech':
                            console.log('â¸ï¸ æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼ˆé™éŸ³ä¸­ï¼‰');
                            return;
                        case 'audio-capture':
                            errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡';
                            break;
                        case 'network':
                            errorMessage = 'ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥';
                            break;
                        case 'aborted':
                            console.log('ğŸ›‘ è¯­éŸ³è¯†åˆ«å·²å–æ¶ˆ');
                            return;
                        default:
                            errorMessage = 'è¯­éŸ³è¯†åˆ«å¤±è´¥';
                    }

                    if (errorMessage) {
                        Toast.show({ content: errorMessage, icon: 'fail', duration: 2000 });
                    }
                };

                recognition.onend = () => {
                    console.log('â¹ï¸ è¯­éŸ³è¯†åˆ«å·²ç»“æŸ');

                    if (isLongPressRef.current && isRecordingRef.current) {
                        console.log('ğŸ”„ ç”¨æˆ·ä»åœ¨å½•éŸ³ï¼Œè‡ªåŠ¨é‡å¯è¯†åˆ«...');
                        try {
                            recognition.start();
                        } catch (error) {
                            console.error('é‡å¯è¯†åˆ«å¤±è´¥:', error);
                        }
                    }
                };

                recognitionRef.current = recognition;
            }
        }
    };

    // æ£€æŸ¥éº¦å…‹é£æƒé™ (Tauri ç¯å¢ƒ)
    const checkMicrophonePermissionTauri = async (): Promise<boolean> => {
        try {
            const result = await invoke('check_microphone_permission');
            console.log('Tauri éº¦å…‹é£æƒé™æ£€æŸ¥ç»“æœ:', result);
            return true; // Tauri ç¯å¢ƒä¸‹ç”±åŸç”Ÿå±‚å¤„ç†
        } catch (error) {
            console.error('Tauri æƒé™æ£€æŸ¥å¤±è´¥:', error);
            return false;
        }
    };

    // æ£€æŸ¥éº¦å…‹é£æƒé™ (Web ç¯å¢ƒ)
    const checkMicrophonePermissionWeb = async (): Promise<boolean> => {
        try {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                console.log('æµè§ˆå™¨ä¸æ”¯æŒ MediaDevices API');
                return false;
            }

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop());
            return true;
        } catch (error) {
            console.error('éº¦å…‹é£æƒé™æ£€æŸ¥å¤±è´¥:', error);
            return false;
        }
    };

    // æ£€æŸ¥éº¦å…‹é£æƒé™
    const checkMicrophonePermission = async (): Promise<boolean> => {
        // æ£€æµ‹æ˜¯å¦åœ¨ Tauri ç¯å¢ƒä¸­
        const isTauri = '__TAURI__' in window;

        if (isTauri) {
            return await checkMicrophonePermissionTauri();
        } else {
            return await checkMicrophonePermissionWeb();
        }
    };

    // é™é»˜æ£€æŸ¥éº¦å…‹é£æƒé™çŠ¶æ€(ä¸ä¼šè§¦å‘æƒé™å¼¹çª—)
    const checkMicrophonePermissionSilent = async (): Promise<boolean> => {
        try {
            // æ£€æµ‹æ˜¯å¦åœ¨ Tauri ç¯å¢ƒä¸­
            const isTauri = '__TAURI__' in window;

            if (isTauri) {
                // Tauri ç¯å¢ƒä¸‹ç›´æ¥è¿”å› trueï¼Œç”±åŸç”Ÿå±‚å¤„ç†
                return true;
            }

            // Web ç¯å¢ƒï¼šå°è¯•å¤šç§æ–¹å¼æ£€æµ‹æƒé™

            // æ–¹æ³•1: ä½¿ç”¨ Permissions API æŸ¥è¯¢æƒé™çŠ¶æ€(ä¸ä¼šè§¦å‘å¼¹çª—)
            if (navigator.permissions && navigator.permissions.query) {
                try {
                    const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
                    console.log('Permissions API æŸ¥è¯¢ç»“æœ:', result.state);
                    if (result.state === 'granted') {
                        return true;
                    }
                    if (result.state === 'denied') {
                        return false;
                    }
                    // state === 'prompt' æ—¶ç»§ç»­æ£€æµ‹
                } catch (err) {
                    console.log(err, 'Permissions API ä¸æ”¯æŒ microphone æŸ¥è¯¢');
                }
            }

            // æ–¹æ³•2: å°è¯•æšä¸¾è®¾å¤‡ï¼ˆå·²æˆæƒæ—¶ä¸ä¼šè§¦å‘å¼¹çª—ï¼‰
            if (navigator.mediaDevices && navigator.mediaDevices.enumerateDevices) {
                try {
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    const audioInputs = devices.filter(device => device.kind === 'audioinput');
                    // å¦‚æœèƒ½è·å–åˆ°è®¾å¤‡æ ‡ç­¾ï¼Œè¯´æ˜å·²æœ‰æƒé™
                    const hasLabels = audioInputs.some(device => device.label !== '');
                    if (hasLabels) {
                        console.log('é€šè¿‡è®¾å¤‡æšä¸¾æ£€æµ‹åˆ°å·²æˆæƒ');
                        return true;
                    }
                } catch (err) {
                    console.log('è®¾å¤‡æšä¸¾å¤±è´¥:', err);
                }
            }

            // å¦‚æœæ‰€æœ‰æ£€æµ‹éƒ½ä¸ç¡®å®šï¼Œè¿”å› falseï¼Œè®©ç”¨æˆ·ä¸»åŠ¨è§¦å‘æƒé™
            console.log('æ— æ³•ç¡®å®šæƒé™çŠ¶æ€ï¼Œéœ€è¦ç”¨æˆ·ä¸»åŠ¨è§¦å‘');
            return false;
        } catch (error) {
            console.error('é™é»˜æƒé™æ£€æŸ¥å¤±è´¥:', error);
            return false;
        }
    };

    // å¼€å§‹è¯­éŸ³è¯†åˆ«
    const startSpeechRecognition = async () => {
        const isSecureContext = window.isSecureContext;
        if (!isSecureContext) {
            Toast.show({
                content: 'è¯­éŸ³è¯†åˆ«éœ€è¦ HTTPS ç¯å¢ƒ',
                icon: 'fail',
                duration: 2000
            });
            return;
        }

        const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
        if (!SpeechRecognition) {
            console.log('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
            Toast.show({
                content: 'å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«',
                icon: 'fail',
                duration: 2000
            });
            return;
        }

        const hasPermission = await checkMicrophonePermission();
        console.log('éº¦å…‹é£æƒé™:', hasPermission);
        if (!hasPermission) {
            Toast.show({
                content: 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®',
                icon: 'fail',
                duration: 2000
            });
            return;
        }

        initSpeechRecognition();

        if (recognitionRef.current) {
            try {
                recognitionRef.current.start();
            } catch (error) {
                console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
                Toast.show({
                    content: 'è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥',
                    icon: 'fail',
                    duration: 2000
                });
            }
        } else {
            Toast.show({
                content: 'è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥',
                icon: 'fail',
                duration: 2000
            });
        }
    };

    // åœæ­¢è¯­éŸ³è¯†åˆ«
    const stopSpeechRecognition = () => {
        if (recognitionRef.current) {
            try {
                recognitionRef.current.stop();
            } catch (error) {
                console.error('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
            }
        }
    };

    return {
        recognizedText,
        setRecognizedText,
        initSpeechRecognition,
        startSpeechRecognition,
        stopSpeechRecognition,
        checkMicrophonePermissionSilent,
    };
};
