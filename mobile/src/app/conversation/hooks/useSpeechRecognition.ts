import { useRef, useState } from 'react';
import { Toast } from 'antd-mobile';

interface UseSpeechRecognitionReturn {
    recognizedText: string;
    setRecognizedText: (text: string) => void;
    initSpeechRecognition: () => void;
    startSpeechRecognition: () => Promise<void>;
    stopSpeechRecognition: () => void;
}

export const useSpeechRecognition = (
    isLongPressRef: React.MutableRefObject<boolean>,
    isRecordingRef: React.MutableRefObject<boolean>
): UseSpeechRecognitionReturn => {
    const recognitionRef = useRef<any>(null);
    const [recognizedText, setRecognizedText] = useState('');

    // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
    const initSpeechRecognition = () => {
        if (!recognitionRef.current) {
            const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

            if (SpeechRecognition) {
                const recognition = new SpeechRecognition();
                recognition.lang = 'zh-CN';
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.maxAlternatives = 1;

                recognition.onstart = () => {
                    console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨');
                };

                recognition.onresult = (event: any) => {
                    let allText = '';
                    for (let i = 0; i < event.results.length; i++) {
                        allText += event.results[i][0].transcript;
                    }
                    setRecognizedText(allText);
                    console.log('ğŸ“ è¯†åˆ«ç»“æœ:', allText);
                };

                recognition.onerror = (event: any) => {
                    console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error);

                    let errorMessage = '';
                    switch (event.error) {
                        case 'not-allowed':
                            errorMessage = 'è¯·å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£æƒé™';
                            break;
                        case 'no-speech':
                            console.log('â¸ï¸ æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼ˆé™éŸ³ä¸­ï¼‰');
                            return;
                        case 'audio-capture':
                            errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡';
                            break;
                        case 'network':
                            errorMessage = 'ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥';
                            break;
                        case 'aborted':
                            console.log('ğŸ›‘ è¯­éŸ³è¯†åˆ«å·²å–æ¶ˆ');
                            return;
                        default:
                            errorMessage = 'è¯­éŸ³è¯†åˆ«å¤±è´¥';
                    }

                    if (errorMessage) {
                        Toast.show({ content: errorMessage, icon: 'fail', duration: 2000 });
                    }
                };

                recognition.onend = () => {
                    console.log('â¹ï¸ è¯­éŸ³è¯†åˆ«å·²ç»“æŸ');

                    if (isLongPressRef.current && isRecordingRef.current) {
                        console.log('ğŸ”„ ç”¨æˆ·ä»åœ¨å½•éŸ³ï¼Œè‡ªåŠ¨é‡å¯è¯†åˆ«...');
                        try {
                            recognition.start();
                        } catch (error) {
                            console.error('é‡å¯è¯†åˆ«å¤±è´¥:', error);
                        }
                    }
                };

                recognitionRef.current = recognition;
            }
        }
    };

    // æ£€æŸ¥éº¦å…‹é£æƒé™
    const checkMicrophonePermission = async (): Promise<boolean> => {
        try {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                console.log('æµè§ˆå™¨ä¸æ”¯æŒ MediaDevices API');
                return false;
            }

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop());
            return true;
        } catch (error) {
            console.error('éº¦å…‹é£æƒé™æ£€æŸ¥å¤±è´¥:', error);
            return false;
        }
    };

    // å¼€å§‹è¯­éŸ³è¯†åˆ«
    const startSpeechRecognition = async () => {
        const isSecureContext = window.isSecureContext;
        if (!isSecureContext) {
            Toast.show({
                content: 'è¯­éŸ³è¯†åˆ«éœ€è¦ HTTPS ç¯å¢ƒ',
                icon: 'fail',
                duration: 2000
            });
            return;
        }

        const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
        if (!SpeechRecognition) {
            console.log('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
            Toast.show({
                content: 'å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«',
                icon: 'fail',
                duration: 2000
            });
            return;
        }

        const hasPermission = await checkMicrophonePermission();
        if (!hasPermission) {
            Toast.show({
                content: 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®',
                icon: 'fail',
                duration: 2000
            });
            return;
        }

        initSpeechRecognition();

        if (recognitionRef.current) {
            try {
                recognitionRef.current.start();
            } catch (error) {
                console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
                Toast.show({
                    content: 'è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥',
                    icon: 'fail',
                    duration: 2000
                });
            }
        } else {
            Toast.show({
                content: 'è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥',
                icon: 'fail',
                duration: 2000
            });
        }
    };

    // åœæ­¢è¯­éŸ³è¯†åˆ«
    const stopSpeechRecognition = () => {
        if (recognitionRef.current) {
            try {
                recognitionRef.current.stop();
            } catch (error) {
                console.error('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
            }
        }
    };

    return {
        recognizedText,
        setRecognizedText,
        initSpeechRecognition,
        startSpeechRecognition,
        stopSpeechRecognition,
    };
};
