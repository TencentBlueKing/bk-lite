"""é‡‡é›†æœåŠ¡ V2 - åŸºäº YAML é…ç½®çš„æ–°ç‰ˆæœ¬é‡‡é›†æœåŠ¡"""
import asyncio
import copy
import importlib
import json
import time
import traceback
from typing import Dict, Any, Optional, List
from sanic.log import logger

from core.nats_utils import nats_request
from core.yaml_reader import yaml_reader
from core.plugin_executor import PluginExecutor
from plugins.base_utils import expand_ip_range
from utils.async_executor import AsyncExecutor
from plugins.base_utils import convert_to_prometheus_format


class CollectionService:
    """
    é‡‡é›†æœåŠ¡- åŸºäº YAML é…ç½®çš„æ–°æ¶æ„
    
    å·¥ä½œæµç¨‹ï¼š
    1. æ ¹æ® plugin_name æ¨æ–­ modelï¼ˆæˆ–ç›´æ¥ä¼ å…¥ modelï¼‰
    2. è¯»å– plugins/inputs/{model}/plugin.yml
    3. ç¡®å®šæ‰§è¡Œå™¨ç±»å‹ï¼ˆjob/protocolï¼‰
    4. é€šè¿‡ PluginExecutor æ‰§è¡Œé‡‡é›†
    """

    def __init__(self, params: Optional[dict] = None, max_workers: Optional[int] = None):
        self._node_info_map = {}
        self.namespace = "bklite"
        self.yaml_reader = yaml_reader
        self.params = params
        self.plugin_name = self.params.pop("plugin_name", None)
        self.model_id = self.params["model_id"]
        self.hosts = self.ip_split(self.params.get("hosts", ""))
        # æ˜¯å¦å¯ç”¨å¹¶å‘ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        self.enable_concurrent = len(self.hosts) >= 2
        if self.enable_concurrent:
            # åˆå§‹åŒ–å¼‚æ­¥æ‰§è¡Œå™¨
            self.async_executor = AsyncExecutor(max_workers=max_workers)
        else:
            self.async_executor = None

    @staticmethod
    def ip_split(ip_range):
        if "-" in ip_range:
            result = expand_ip_range(ip_range=ip_range)
        else:
            result = ip_range.split(",")

        return result

    async def collect(self):
        """
        Returns:
            é‡‡é›†ç»“æœï¼ˆPrometheus æ ¼å¼å­—ç¬¦ä¸² æˆ– å­—å…¸ï¼‰
        """
        logger.info(f"{'=' * 30}")
        logger.info(f"ğŸ¯ Starting collection V2: model={self.model_id} Plugin: {self.plugin_name}")
        if not self.hosts:
            logger.warning("âŒ Hosts parameter is empty")

        try:
            # æ ¹æ®å‚æ•°ç¡®å®šæ‰§è¡Œå™¨ç±»å‹ï¼ˆjob æˆ– protocolï¼‰
            executor_type = self.params["executor_type"]
            logger.info(f"ğŸ”§ Executor type: {executor_type}")

            #  è·å–æ‰§è¡Œå™¨é…ç½®
            executor_config = self.yaml_reader.get_executor_config(self.model_id, executor_type)

            # å¯¹äºéäº‘åè®®é‡‡é›†ï¼Œå…ˆè·å–èŠ‚ç‚¹ä¿¡æ¯
            if executor_config.is_job:
                await self.set_nodes_info_map()

            # åˆ¤æ–­æ˜¯å¦å¯ç”¨å¹¶å‘
            if self.enable_concurrent:
                logger.info(f"ğŸš€ Concurrent mode enabled for {len(self.hosts)} hosts")
                collect_data = await self._collect_concurrent(executor_config)
            else:
                logger.info(f"ğŸ“ Sequential mode for {len(self.hosts)} host(s)")
                collect_data = await self._collect_sequential(executor_config)

            # åˆå¹¶å¤šä¸»æœºæ•°æ®å¹¶è½¬æ¢ä¸º Prometheus æ ¼å¼
            merged_data = self._merge_raw_data(collect_data)
            result = convert_to_prometheus_format(merged_data)

            logger.info(f"âœ… Collection completed successfully")
            logger.info('=' * 60)
            return result

        except FileNotFoundError as e:
            logger.error(f"âŒ YAML config not found: {e}")
            logger.info(f"{'=' * 60}")
            return self._generate_error_response(f"Plugin config not found for model '{self.model_id}'")

        except Exception as e:
            logger.error(f"âŒ Collection failed: {traceback.format_exc()}")
            logger.info(f"{'=' * 60}")
            return self._generate_error_response(str(e))

        finally:
            # æ¸…ç†çº¿ç¨‹æ± èµ„æº
            if self.async_executor:
                self.async_executor.shutdown(wait=False)

    async def _collect_single_host(self, host: str, executor_config) -> Dict[str, Any]:
        """é‡‡é›†å•ä¸ªä¸»æœºçš„æ•°æ®"""
        try:
            # ä¸ºæ¯ä¸ªä¸»æœºåˆ›å»ºç‹¬ç«‹çš„å‚æ•°å‰¯æœ¬
            host_params = copy.deepcopy(self.params)
            host_params["host"] = host

            if executor_config.is_job:
                if host in self._node_info_map:
                    host_params["node_info"] = self._node_info_map[host]

            executor = PluginExecutor(self.model_id, executor_config, host_params)
            return await executor.execute()
        except Exception as e:
            logger.error(f"âŒ Host {host} collection failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "host": host
            }

    async def _collect_sequential(self, executor_config) -> List[Dict[str, Any]]:
        """ä¸²è¡Œé‡‡é›†ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        collect_data = []
        for host in self.hosts:
            result = await self._collect_single_host(host, executor_config)
            collect_data.append(result)
        return collect_data

    async def _collect_concurrent(self, executor_config) -> List[Dict[str, Any]]:
        """å¹¶å‘é‡‡é›†ï¼ˆä½¿ç”¨å¼‚æ­¥ä»»åŠ¡ä¼˜åŒ–ï¼‰"""
        # åˆ›å»ºæ‰€æœ‰ä¸»æœºçš„é‡‡é›†ä»»åŠ¡
        tasks = [
            self._collect_single_host(host, executor_config)
            for host in self.hosts
        ]
        # ä½¿ç”¨ asyncio.gather å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        return await asyncio.gather(*tasks, return_exceptions=False)

    def _merge_raw_data(self, raw_data_list: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆå¹¶å¤šä¸ªä¸»æœºçš„åŸå§‹æ•°æ®"""
        merged = {}
        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ  host å­—æ®µï¼ˆäº‘å¹³å°é‡‡é›†ä¸éœ€è¦ï¼‰
        has_hosts = self.hosts and len(self.hosts) > 0

        for i, data in enumerate(raw_data_list):
            # åªæœ‰åœ¨æœ‰ hosts çš„æƒ…å†µä¸‹æ‰è·å– current_host
            current_host = None
            if has_hosts and i < len(self.hosts):
                current_host = self.hosts[i]

            # å¤„ç†é‡‡é›†å¤±è´¥çš„æƒ…å†µ
            if not data.get("success", True):
                error_context = f"Host {current_host}" if current_host else f"Index {i}"
                logger.warning(f"âš ï¸  {error_context} collection failed")

                # æå–é”™è¯¯ä¿¡æ¯
                result_data = data.get("result", {})
                error_msg = result_data.get("cmdb_collect_error", data.get("error", "Unknown error"))

                # åˆ›å»ºé”™è¯¯è®°å½•ï¼Œä¿ç•™åˆ°ç»“æœä¸­
                error_record = {
                    "collect_status": "failed",
                    "collect_error": error_msg,
                    "bk_obj_id": self.model_id
                }
                # åªæœ‰åœ¨æœ‰ host çš„æƒ…å†µä¸‹æ‰æ·»åŠ  host å­—æ®µ
                if current_host:
                    error_record["host"] = current_host

                # å°†é”™è¯¯è®°å½•æ·»åŠ åˆ°å¯¹åº”çš„æ¨¡å‹ä¸­
                if self.model_id not in merged:
                    merged[self.model_id] = []
                merged[self.model_id].append(error_record)
                continue

            result_data = data.get("result", {})
            for model_id, items in result_data.items():
                if model_id not in merged:
                    merged[model_id] = []

                if not items:
                    merged[model_id].extend([{"bk_obj_id": model_id, "collect_status": "success"}])
                    continue

                # ä¸ºæ¯ä¸ª item æ·»åŠ çŠ¶æ€å’Œ host æ ‡ç­¾ï¼ˆä»…åœ¨æœ‰ host æ—¶æ·»åŠ ï¼‰
                if isinstance(items, list):
                    for item in items:
                        if isinstance(item, dict):
                            # åªæœ‰åœ¨æœ‰ host çš„æƒ…å†µä¸‹æ‰æ·»åŠ  host å­—æ®µ
                            if current_host:
                                item['host'] = current_host
                            item["bk_obj_id"] = model_id
                            item['collect_status'] = 'success'
                    merged[model_id].extend(items)
                elif isinstance(items, dict):
                    # å•ä¸ªå­—å…¸çš„æƒ…å†µ
                    if current_host:
                        items['host'] = current_host
                    items['collect_status'] = 'success'
                    merged[model_id].append(items)

        return merged

    def _generate_error_response(self, error_message: str):
        return self._generate_error_metrics(Exception(error_message), self.model_id)

    def _generate_error_metrics(self, error: Exception, model: str) -> str:
        """ç”Ÿæˆé”™è¯¯æŒ‡æ ‡ï¼ˆPrometheus æ ¼å¼ï¼‰"""
        current_timestamp = int(time.time() * 1000)
        error_type = type(error).__name__
        error_message = str(error).replace('"', '\\"')  # è½¬ä¹‰åŒå¼•å·
        plugin_label = f'plugin="{self.plugin_name}",' if self.plugin_name else ''
        prometheus_lines = [
            "# HELP collection_status Collection status indicator",
            "# TYPE collection_status gauge",
            f'collection_status{{{plugin_label}model="{model}",status="error",error_type="{error_type}"}} 1 {current_timestamp}',
            "",
            "# HELP collection_error Collection error details",
            "# TYPE collection_error gauge",
            f'collection_error{{{plugin_label}model="{model}",message="{error_message}"}} 1 {current_timestamp}'
        ]

        return "\n".join(prometheus_lines) + "\n"

    def list_regions(self):
        """
        åˆ—å‡ºåŒºåŸŸï¼ˆä¿ç•™å‘åå…¼å®¹æ¥å£ï¼‰
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä¸»è¦ç”¨äºäº‘å¹³å°æ’ä»¶
        """
        if not self.model_id:
            return {"result": [], "success": False}

        try:
            # è¯»å– YAML é…ç½®
            plugin_config = self.yaml_reader.read_plugin_config(self.model_id)
            executor_config = self.yaml_reader.get_executor_config(self.model_id,
                                                                   plugin_config.get('default_executor', 'protocol'))

            # åªæœ‰ protocol ç±»å‹æ”¯æŒ list_regions
            if not executor_config.is_cloud_protocol:
                logger.warning(f"list_regions not supported for executor type: {executor_config.executor_type}")
                return {"result": [], "success": False}

            # åŠ è½½é‡‡é›†å™¨
            collector_info = executor_config.get_collector_info()
            module = importlib.import_module(collector_info['module'])
            plugin_class = getattr(module, collector_info['class'])

            # å®ä¾‹åŒ–å¹¶è°ƒç”¨
            plugin_instance = plugin_class(self.params or {})
            result = plugin_instance.list_regions()

            return {"result": result.get("data", []), "success": result.get("result", False)}

        except Exception as e:  # noqa
            import traceback
            logger.error(f"Error list_regions for {self.plugin_name or self.model_id}: {traceback.format_exc()}")
            return {"result": [], "success": False}

    async def set_nodes_info_map(self):
        """æŸ¥è¯¢èŠ‚ç‚¹ä¿¡æ¯"""
        try:
            exec_params = {
                "args": [{"page_size": -1}],
                "kwargs": {}
            }
            subject = f"{self.namespace}.node_list"
            payload = json.dumps(exec_params).encode()

            response = await nats_request(subject, payload=payload, timeout=10.0)

            if response.get('success') and response['result']['nodes']:
                for node in response['result']['nodes']:
                    self._node_info_map[node["ip"]] = node
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to get node info: {e}")
