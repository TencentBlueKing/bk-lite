# -- coding: utf-8 --
# @File: collect.py
# @Time: 2025/2/27 10:41
# @Author: windyzhao
import time
import uuid
from typing import List

from sanic import Blueprint
from sanic.log import logger
from sanic import response

from core.task_queue import get_task_queue
from plugins.base_utils import expand_ip_range

collect_router = Blueprint("collect", url_prefix="/collect")


def _parse_hosts(hosts_param: str) -> List[str]:
    """
    è§£æhostså‚æ•°ï¼Œæ”¯æŒé€—å·åˆ†éš”å’ŒIPæ®µ
    
    æ”¯æŒæ ¼å¼ï¼š
    - å•ä¸ªIP/åŸŸå: "192.168.1.1" æˆ– "ecs.cn-beijing.aliyuncs.com"
    - é€—å·åˆ†éš”: "192.168.1.1,192.168.1.2"
    - IPæ®µ: "192.168.1.1-192.168.1.10"
    - æ··åˆ: "192.168.1.1,192.168.1.5-192.168.1.8"
    
    Args:
        hosts_param: hostså‚æ•°å­—ç¬¦ä¸²
        
    Returns:
        è§£æåçš„IP/åŸŸååˆ—è¡¨
    """
    if not hosts_param or not hosts_param.strip():
        return []
    
    result = []
    segments = [seg.strip() for seg in hosts_param.split(",") if seg.strip()]
    
    for segment in segments:
        if "-" in segment and segment.count(".") >= 3:
            # å¯èƒ½æ˜¯IPæ®µï¼ˆ192.168.1.1-192.168.1.10ï¼‰
            try:
                expanded = expand_ip_range(segment)
                result.extend(expanded)
                logger.debug(f"Expanded IP range '{segment}' to {len(expanded)} IPs")
            except Exception as e:
                logger.warning(f"Failed to expand IP range '{segment}': {e}, treating as literal")
                result.append(segment)
        else:
            # å•ä¸ªIP/åŸŸå/endpoint
            result.append(segment)
    
    return result


@collect_router.get("/collect_info")
async def collect(request):
    """
    é…ç½®é‡‡é›† - å¼‚æ­¥æ¨¡å¼
    ç«‹å³è¿”å›è¯·æ±‚å·²æ¥æ”¶çš„æŒ‡æ ‡ï¼Œå®é™…é‡‡é›†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—å¼‚æ­¥æ‰§è¡Œ

    å‚æ•°æ¥æºï¼š
    - Headers: cmdb* å¼€å¤´çš„å‚æ•°
    - Query: URL å‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰

    å¿…éœ€å‚æ•°ï¼š
        plugin_name: æ’ä»¶åç§° (mysql_info, redis_info ç­‰)

    å¯é€‰ Tags å‚æ•°ï¼ˆHeadersï¼Œç”± Telegraf ä¼ é€’ï¼‰ï¼š
        X-Instance-ID: å®ä¾‹æ ‡è¯†
        X-Instance-Type: å®ä¾‹ç±»å‹
        X-Collect-Type: é‡‡é›†ç±»å‹ï¼ˆé»˜è®¤ discoveryï¼‰
        X-Config-Type: é…ç½®ç±»å‹

    ç¤ºä¾‹è¯·æ±‚ï¼š
        curl -X GET "http://localhost:8083/api/collect/collect_info" \
             -H "cmdbplugin_name: mysql_info" \
             -H "cmdbhostname: 192.168.1.100" \
             -H "cmdbport: 3306" \
             -H "cmdbusername: root" \
             -H "cmdbpassword: ********" \
             -H "X-Instance-ID: mysql-192.168.1.100" \
             -H "X-Instance-Type: mysql" \
             -H "X-Collect-Type: discovery" \
             -H "X-Config-Type: auto"

    è¿”å›ï¼š
        Prometheus æ ¼å¼çš„"è¯·æ±‚å·²æ¥æ”¶"æŒ‡æ ‡ï¼ŒåŒ…å« task_id ç”¨äºè¿½è¸ª
    """
    logger.info("=== Plugin collection request received ===")

    # Sanic è¦æ±‚è¯·æ±‚ä½“è¢«æ¶ˆè´¹ï¼ˆå³ä½¿æ˜¯ GET è¯·æ±‚ï¼‰ï¼Œå¦åˆ™å¯èƒ½å‡ºç°
    # "<Request ...> body not consumed." æ—¥å¿—å‘Šè­¦ã€‚
    await request.receive_body()

    # 1. è§£æå‚æ•°ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
    params = {k.split("cmdb", 1)[-1]: v for k, v in dict(request.headers).items() if k.startswith("cmdb")}
    if not params:
        params = {i[0]: i[1] for i in request.query_args}

    # 2. æå– Tagsï¼ˆä» Headersï¼‰
    instance_id = request.headers.get("instance_id")
    instance_type = request.headers.get("instance_type")
    collect_type = request.headers.get("collect_type")
    config_type = request.headers.get("config_type")

    model_id = params.get("model_id")
    if not model_id:
        # è¿”å›é”™è¯¯æŒ‡æ ‡
        current_timestamp = int(time.time() * 1000)
        error_lines = [
            "# HELP collection_request_error Collection request error",
            "# TYPE collection_request_error gauge",
            f'collection_request_error{{model_id="",instance_id="{instance_id}",error="model_id is Null"}} 1 {current_timestamp}'
        ]

        return response.raw(
            "\n".join(error_lines) + "\n",
            content_type='text/plain; version=0.0.4; charset=utf-8',
            status=500
        )


    try:
        # 3. æ„å»ºåŸºç¡€ä»»åŠ¡å‚æ•°
        task_params = {
            **params,  # åŸæœ‰å‚æ•°ï¼ˆåŒ…å« plugin_nameï¼‰
            # Tags å‚æ•°ï¼ˆ5ä¸ªæ ¸å¿ƒæ ‡ç­¾ï¼‰
            "tags": {
                "instance_id": instance_id,
                "instance_type": instance_type,
                "collect_type": collect_type,
                "config_type": config_type,
            }
        }

        # 4. è·å–ä»»åŠ¡é˜Ÿåˆ—
        task_queue = get_task_queue()
        
        # 5. æ£€æŸ¥æ˜¯å¦æœ‰hostså‚æ•°
        hosts_param = params.get("hosts", "").strip()
        
        if hosts_param:
            # ========== åœºæ™¯Aï¼šæœ‰hostså‚æ•° â†’ æ‹†åˆ†ä»»åŠ¡ ==========
            hosts_list = _parse_hosts(hosts_param)
            
            if not hosts_list:
                # hostså‚æ•°è§£æä¸ºç©º
                current_timestamp = int(time.time() * 1000)
                error_lines = [
                    "# HELP collection_request_error Collection request error",
                    "# TYPE collection_request_error gauge",
                    f'collection_request_error{{model_id="{model_id}",error="Failed to parse hosts parameter"}} 1 {current_timestamp}'
                ]
                return response.raw(
                    "\n".join(error_lines) + "\n",
                    content_type='text/plain; version=0.0.4; charset=utf-8',
                    status=400
                )
            
            # ç”Ÿæˆæ‰¹æ¬¡ID
            batch_id = f"batch_{uuid.uuid4().hex[:16]}"
            
            logger.info("=" * 70)
            logger.info(f"ğŸ“¦ Task splitting: {len(hosts_list)} host(s) â†’ {len(hosts_list)} task(s)")
            logger.info(f"ğŸ“‹ Batch ID: {batch_id}")
            logger.info(f"ğŸ¯ Model: {model_id}")
            logger.info("=" * 70)
            
            task_infos = []
            success_count = 0
            failed_count = 0
            
            # å¾ªç¯æ¯ä¸ªhoståˆ›å»ºä»»åŠ¡
            for idx, host in enumerate(hosts_list, 1):
                try:
                    # æ„å»ºå•ä¸ªhostçš„ä»»åŠ¡å‚æ•°
                    single_host_params = {
                        **task_params,
                        "host": host,  # å•ä¸ªIPæˆ–endpoint
                        "batch_id": batch_id,
                        "batch_index": idx,
                        "batch_total": len(hosts_list)
                    }
                    
                    # åˆ›å»ºä»»åŠ¡
                    task_info = await task_queue.enqueue_collect_task(single_host_params)
                    task_infos.append({
                        "host": host,
                        "task_id": task_info["task_id"],
                        "job_id": task_info.get("job_id", ""),
                        "status": task_info["status"]
                    })
                    
                    if task_info["status"] == "queued":
                        success_count += 1
                        logger.info(f"  âœ… [{idx}/{len(hosts_list)}] {host}: {task_info['task_id']}")
                    else:
                        logger.warning(f"  âš ï¸  [{idx}/{len(hosts_list)}] {host}: {task_info['status']}")
                        
                except Exception as e:
                    failed_count += 1
                    logger.error(f"  âŒ [{idx}/{len(hosts_list)}] {host}: {e}")
                    task_infos.append({
                        "host": host,
                        "task_id": "",
                        "status": "failed",
                        "error": str(e)
                    })
            
            # è¾“å‡ºæ±‡æ€»
            skipped_count = len(hosts_list) - success_count - failed_count
            logger.info("=" * 70)
            logger.info(f"ğŸ“Š Summary: {success_count} queued, {failed_count} failed, {skipped_count} skipped")
            logger.info("=" * 70)
            
            # è¿”å›æ‰¹æ¬¡å“åº”
            current_timestamp = int(time.time() * 1000)
            prometheus_lines = [
                "# HELP collection_batch_accepted Indicates that collection batch was accepted",
                "# TYPE collection_batch_accepted gauge",
                f'collection_batch_accepted{{model_id="{model_id}",batch_id="{batch_id}",total="{len(hosts_list)}",queued="{success_count}",failed="{failed_count}"}} 1 {current_timestamp}'
            ]
            
            return response.raw(
                "\n".join(prometheus_lines) + "\n",
                content_type='text/plain; version=0.0.4; charset=utf-8',
                headers={
                    'X-Batch-ID': batch_id,
                    'X-Task-Count': str(len(task_infos)),
                    'X-Success-Count': str(success_count)
                }
            )
        else:
            # ========== åœºæ™¯Bï¼šæ— hostså‚æ•° â†’ å•ä»»åŠ¡ ==========
            # äº‘é‡‡é›†ä½¿ç”¨é»˜è®¤endpointï¼Œæˆ–å•IPé‡‡é›†
            logger.info(f"ğŸ“¦ Single task mode: model={model_id}")
            
            task_info = await task_queue.enqueue_collect_task(task_params)
            task_status = task_info.get("status", "unknown")
            logger.info(
                f"Plugin task enqueue result: task_id={task_info['task_id']}, "
                f"status={task_status}, model_id={model_id}, job_id={task_info.get('job_id', '')}"
            )
            
            # è¿”å›å•ä»»åŠ¡å“åº”
            current_timestamp = int(time.time() * 1000)
            prometheus_lines = [
                "# HELP collection_request_accepted Indicates that collection request was accepted",
                "# TYPE collection_request_accepted gauge",
                f'collection_request_accepted{{model_id="{model_id}",task_id="{task_info["task_id"]}",status="{task_status}"}} 1 {current_timestamp}'
            ]
            
            return response.raw(
                "\n".join(prometheus_lines) + "\n",
                content_type='text/plain; version=0.0.4; charset=utf-8',
                headers={
                    'X-Task-ID': task_info['task_id'],
                    'X-Job-ID': task_info.get('job_id', ""),
                    'X-Task-Status': task_status
                }
            )

    except Exception as e:
        logger.error(f"Error queuing plugin task: {e}", exc_info=True)

        # è¿”å›é”™è¯¯æŒ‡æ ‡
        current_timestamp = int(time.time() * 1000)
        error_lines = [
            "# HELP collection_request_error Collection request error",
            "# TYPE collection_request_error gauge",
            f'collection_request_error{{model_id="{model_id}",error="{str(e)}"}} 1 {current_timestamp}'
        ]

        return response.raw(
            "\n".join(error_lines) + "\n",
            content_type='text/plain; version=0.0.4; charset=utf-8',
            status=500
        )
