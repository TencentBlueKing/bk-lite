# Algorithms æ¨¡å‹æœåŠ¡è®¾è®¡æŒ‡å—

> æœ¬æŒ‡å—ç”¨äºæŒ‡å¯¼æ–°æ¨¡å‹ç®—æ³•æœåŠ¡çš„è®¾è®¡ä¸å®ç°ï¼Œç¡®ä¿æ¶æ„ä¸€è‡´æ€§å’Œä»£ç è´¨é‡ã€‚
>
> æ›´æ–°æ—¶é—´ï¼š2026å¹´1æœˆ7æ—¥

## ğŸ“ è®¾è®¡åŸåˆ™

### æ ¸å¿ƒåŸåˆ™ï¼šæ¸è¿›å¼è®¾è®¡ï¼Œæ°å¦‚å…¶åˆ†

1. **æœ€å°å¯ç”¨**ï¼šé¦–å…ˆå®ç°æ ¸å¿ƒåŠŸèƒ½ï¼ˆè®­ç»ƒ+æœåŠ¡ï¼‰ï¼Œç¡®ä¿ç«¯åˆ°ç«¯å¯ç”¨
2. **é¿å…è¿‡æ—©æŠ½è±¡**ï¼šä¸æå‰è®¾è®¡æœªæ¥å¯èƒ½éœ€è¦çš„åŠŸèƒ½ï¼ˆè§ä¸‹æ–¹è¯¦ç»†è¯´æ˜ï¼‰
3. **æ˜“äºæ‰©å±•**ï¼šé€šè¿‡æ¸…æ™°çš„æŠ½è±¡æ”¯æŒåç»­åŠŸèƒ½æ·»åŠ 
4. **ç»Ÿä¸€æ¶æ„**ï¼šéµå¾ªç°æœ‰ä¸‰ä¸ªæœåŠ¡çš„æ¶æ„æ¨¡å¼

---

### ğŸš« é¿å…è¿‡æ—©æŠ½è±¡ï¼ˆAnti-Premature Abstractionï¼‰

**æ ¸å¿ƒç†å¿µ**ï¼š
- âœ… **å…ˆå®ç°ï¼ŒåæŠ½è±¡**ï¼šç­‰çœŸæ­£éœ€è¦æ—¶å†æå–å…¬å…±é€»è¾‘
- âœ… **åŠ¡å®è®¾è®¡**ï¼šä»£ç é‡å¤ä¼˜äºé”™è¯¯çš„æŠ½è±¡
- âœ… **æ˜ç¡®èŒè´£**ï¼šåŸºç±»å®šä¹‰æ¥å£å¥‘çº¦ï¼Œä¸å®ç°ä¸šåŠ¡é€»è¾‘

---

## ğŸ—ï¸ æ ‡å‡†é¡¹ç›®ç»“æ„

```
algorithms/
â””â”€â”€ classify_{domain}_server/          # æ¨¡å‹æœåŠ¡æ ¹ç›®å½•
    â”œâ”€â”€ README.md                       # é¡¹ç›®è¯´æ˜ï¼ˆç®€æ´å³å¯ï¼‰
    â”œâ”€â”€ Makefile                        # æ„å»ºå’Œè¿è¡Œè„šæœ¬
    â”œâ”€â”€ pyproject.toml                  # Pythoné¡¹ç›®é…ç½®ï¼ˆuvç®¡ç†ä¾èµ–ï¼‰
    â”œâ”€â”€ pytest.ini                      # æµ‹è¯•é…ç½®
    â”œâ”€â”€ .env.example                    # ç¯å¢ƒå˜é‡ç¤ºä¾‹
    â”œâ”€â”€ .gitignore                      # Gitå¿½ç•¥æ–‡ä»¶
    â”œâ”€â”€ mc                              # MinIO Client äºŒè¿›åˆ¶ï¼ˆç”¨äºæ•°æ®ä¸‹è½½ï¼Œå¼€å‘è€…æ‰‹åŠ¨å¼•å…¥ï¼Œæ— éœ€ä¸‹è½½ï¼‰
    â”‚
    â”œâ”€â”€ classify_{domain}_server/       # ä¸»åŒ…
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ cli/                        # å‘½ä»¤è¡Œæ¥å£
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ bootstrap.py            # CLIå…¥å£ï¼ˆä½¿ç”¨fireï¼‰
    â”‚   â”‚
    â”‚   â”œâ”€â”€ serving/                    # åœ¨çº¿æœåŠ¡å±‚
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ service.py              # BentoMLæœåŠ¡å®šä¹‰
    â”‚   â”‚   â”œâ”€â”€ config.py               # æœåŠ¡é…ç½®
    â”‚   â”‚   â”œâ”€â”€ schemas.py              # API Schemaï¼ˆPydanticï¼‰
    â”‚   â”‚   â”œâ”€â”€ exceptions.py           # è‡ªå®šä¹‰å¼‚å¸¸
    â”‚   â”‚   â”œâ”€â”€ metrics.py              # PrometheusæŒ‡æ ‡
    â”‚   â”‚   â””â”€â”€ models/                 # æ¨¡å‹åŠ è½½å™¨
    â”‚   â”‚       â”œâ”€â”€ __init__.py
    â”‚   â”‚       â”œâ”€â”€ loader.py           # ç»Ÿä¸€æ¨¡å‹åŠ è½½
    â”‚   â”‚       â””â”€â”€ dummy_model.py      # é™çº§ç­–ç•¥ï¼ŒåŠ è½½æ¨¡å‹å¤±è´¥æ—¶ä½¿ç”¨ï¼Œå¯é€‰
    â”‚   â”‚
    â”‚   â””â”€â”€ training/                   # ç¦»çº¿è®­ç»ƒå±‚
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ trainer.py              # é€šç”¨è®­ç»ƒå™¨
    â”‚       â”œâ”€â”€ data_loader.py          # æ•°æ®åŠ è½½
    â”‚       â”œâ”€â”€ mlflow_utils.py         # MLflowå·¥å…·å‡½æ•°
    â”‚       â”œâ”€â”€ config/                 # è®­ç»ƒé…ç½®
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â””â”€â”€ loader.py           # é…ç½®åŠ è½½å™¨
    â”‚       â”œâ”€â”€ preprocessing/          # æ•°æ®é¢„å¤„ç†
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ preprocessor.py     # åŸºç¡€é¢„å¤„ç†å™¨
    â”‚       â”‚   â””â”€â”€ feature_engineering.py  # ç‰¹å¾å·¥ç¨‹ï¼ˆå¿…é€‰ï¼Œæ¯ä¸ªç®—æ³•é¢†åŸŸéƒ½éœ€è¦å®ç°åŸºç¡€ç‰ˆæœ¬ï¼Œä½†æ˜¯è®­ç»ƒæ—¶å¯é€‰æ˜¯å¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ç”¨ï¼‰
    â”‚       â””â”€â”€ models/                 # è®­ç»ƒæ¨¡å‹å®ç°
    â”‚           â”œâ”€â”€ __init__.py
    â”‚           â”œâ”€â”€ base.py             # æŠ½è±¡åŸºç±» + ModelRegistry
    â”‚           â”œâ”€â”€ {algorithm}_model.py # å…·ä½“æ¨¡å‹å®ç°
    â”‚           â””â”€â”€ {algorithm}_wrapper.py # MLflowæ¨ç†åŒ…è£…å™¨ï¼ˆå¯é€‰ï¼‰
    â”‚
    â”œâ”€â”€ support-files/                  # æ”¯æŒæ–‡ä»¶
    â”‚   â”œâ”€â”€ release/                    # å‘å¸ƒç›¸å…³æ–‡ä»¶
    â”‚   â”‚   â”œâ”€â”€ Dockerfile              # å®¹å™¨é•œåƒå®šä¹‰
    â”‚   â”‚   â”œâ”€â”€ startup.sh              # å®¹å™¨å¯åŠ¨è„šæœ¬
    â”‚   â”‚   â””â”€â”€ supervisor/             # Supervisorè¿›ç¨‹ç®¡ç†é…ç½®
    â”‚   â”‚       â”œâ”€â”€ supervisord.conf
    â”‚   â”‚       â””â”€â”€ conf.d/
    â”‚   â”‚           â”œâ”€â”€ bentoml.conf    # BentoMLæœåŠ¡é…ç½®
    â”‚   â”‚           â””â”€â”€ mlflow.conf     # MLflow UIé…ç½®
    â”‚   â”œâ”€â”€ scripts/                    # è„šæœ¬ç›®å½•
    â”‚   â”‚   â”œâ”€â”€ train.json              # é»˜è®¤è®­ç»ƒé…ç½®
    â”‚   â”‚   â”œâ”€â”€ train-model.sh          # è®­ç»ƒæ‰§è¡Œè„šæœ¬ï¼ˆMinIOä¸‹è½½+è®­ç»ƒï¼‰
    â”‚   â”‚   â”œâ”€â”€ test-predict.sh         # é¢„æµ‹æµ‹è¯•è„šæœ¬
    â”‚   â”‚   â””â”€â”€ data/                   # è®­ç»ƒæ—¶æ•°æ®ç›®å½•ï¼ˆè¿è¡Œæ—¶åˆ›å»ºï¼‰
    â”‚   â”‚       â”œâ”€â”€ downloads/          # MinIOä¸‹è½½çš„å‹ç¼©åŒ…
    â”‚   â”‚       â”œâ”€â”€ datasets/           # è§£å‹åçš„æ•°æ®é›†
    â”‚   â”‚       â””â”€â”€ configs/            # ä»MinIOä¸‹è½½çš„é…ç½®
    â”‚   â””â”€â”€ train.json.example          # è®­ç»ƒé…ç½®ç¤ºä¾‹ï¼ˆæ–‡æ¡£å‚è€ƒï¼‰
    â”‚
    â””â”€â”€ tests/                          # æµ‹è¯•ç”¨ä¾‹
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ conftest.py                 # pytesté…ç½®å’Œfixtures
        â””â”€â”€ test_*.py                   # æµ‹è¯•æ–‡ä»¶
```

### å…³é”®ç›®å½•è¯´æ˜

#### 1. `classify_{domain}_server/` - ä¸»åŒ…
- **cli/**: å‘½ä»¤è¡Œå·¥å…·ï¼ˆ`train`, `serve`ï¼‰
- **serving/**: åœ¨çº¿æœåŠ¡ï¼ˆBentoML + Prometheusç›‘æ§ï¼‰
- **training/**: ç¦»çº¿è®­ç»ƒï¼ˆTrainer + MLflowé›†æˆï¼‰

#### 2. `support-files/` - æ”¯æŒæ–‡ä»¶
- **release/**: å®¹å™¨åŒ–éƒ¨ç½²ç›¸å…³
  - `Dockerfile`: ç»Ÿä¸€çš„é•œåƒæ„å»ºï¼ˆPython 3.12 + uv + fontsï¼‰
  - `startup.sh`: å®¹å™¨å¯åŠ¨å…¥å£
  - `supervisor/`: è¿›ç¨‹ç®¡ç†é…ç½®ï¼ˆæœåŠ¡+MLflow UIï¼‰
- **scripts/**: è®­ç»ƒå’Œæµ‹è¯•è„šæœ¬
  - `train.json`: é»˜è®¤è®­ç»ƒé…ç½®
  - `train-model.sh`: è‡ªåŠ¨åŒ–è®­ç»ƒæµç¨‹ï¼ˆMinIOä¸‹è½½+è§£å‹+è®­ç»ƒï¼‰
  - `data/`: è¿è¡Œæ—¶æ•°æ®ç›®å½•ï¼ˆä¸çº³å…¥ç‰ˆæœ¬æ§åˆ¶ï¼‰

#### 3. æ•°æ®æµå‘
```
MinIO (datasets bucket)
  â†“ train-model.sh ä¸‹è½½
scripts/data/downloads/*.zip
  â†“ unzip
scripts/data/datasets/*_data.csv (æ–‡ä»¶æ ¼å¼ä¸å›ºå®šï¼Œä¸åŒè®­ç»ƒç±»å‹ä¼šæœ‰å¯¹åº”çš„æ ¼å¼)
  â†“ Trainer è¯»å–
training/data_loader.py
  â†“ é¢„å¤„ç†
training/preprocessing/
  â†“ è®­ç»ƒ
training/models/
  â†“ ä¿å­˜
MLflow Model Registry
  â†“ åŠ è½½
serving/models/loader.py
  â†“ é¢„æµ‹
serving/service.py
```

---

## ğŸ”„ ç»Ÿä¸€è®­ç»ƒæµç¨‹

### UniversalTrainer æ ¸å¿ƒè®¾è®¡

**æ ‡å‡†10æ­¥è®­ç»ƒæµç¨‹**ï¼š
1. MLflow å®éªŒè®¾ç½®
2. æ•°æ®åŠ è½½ï¼ˆæ”¯æŒç›®å½•/æ–‡ä»¶æ¨¡å¼ï¼‰
  - ç›®å½•æ¨¡å¼ï¼šä¼ é€’çš„è·¯å¾„æ˜¯ç›®å½•ï¼Œä¸€èˆ¬åŒ…å«ä¸‰ä¸ªæ–‡ä»¶ train_data val_data test_data æ–‡ä»¶ç±»å‹è§†è®­ç»ƒç±»å‹è€Œå®š
  - æ–‡ä»¶æ¨¡å¼ï¼šä¼ é€’çš„è·¯å¾„æ˜¯å…·ä½“æ–‡ä»¶è·¯å¾„ï¼Œéœ€è¦åœ¨æ•°æ®é¢„å¤„ç†æ—¶è¿›è¡Œåˆ†å‰²æˆtrain_data val_data test_dataï¼Œåˆ†å‰²æ¯”ä¾‹ä»£ç å†™æ­»å›ºå®šæ¯”ä¾‹
3. æ•°æ®é¢„å¤„ç†
4. æ¨¡å‹å®ä¾‹åŒ–ï¼ˆé€šè¿‡ ModelRegistry åŠ¨æ€åŠ è½½ï¼‰
5. å¼€å§‹ MLflow run
6. è®°å½•é…ç½®å‚æ•°
7. è¶…å‚æ•°ä¼˜åŒ–ï¼ˆä½¿ç”¨ Hyperoptï¼‰
8. æ¨¡å‹è®­ç»ƒ
9. æ¨¡å‹è¯„ä¼°ï¼ˆtrain/val/testï¼‰
10. æ¨¡å‹ä¿å­˜å’Œæ³¨å†Œ

**è¶…å‚æ•°ä¼˜åŒ–æ¶æ„**ï¼ˆTrainer è°ƒåº¦ï¼ŒModel å®ç°ï¼‰ï¼š

```python
def _optimize_hyperparams(self, train_data, val_data) -> Optional[Dict[str, Any]]:
    """è¶…å‚æ•°ä¼˜åŒ–ç»Ÿä¸€è°ƒåº¦
    
    æ¶æ„ï¼šTrainer è´Ÿè´£é…ç½®æ£€æŸ¥å’Œé”™è¯¯å¤„ç†ï¼ŒModel å®ç°å…·ä½“ä¼˜åŒ–é€»è¾‘
    """
    # 1. æ£€æŸ¥æ˜¯å¦å¯ç”¨ï¼ˆmax_evals=0 è¡¨ç¤ºè·³è¿‡ï¼‰
    max_evals = getattr(self.config, 'max_evals', 0)
    if max_evals == 0:
        return {}
    
    # 2. è°ƒç”¨æ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•ï¼ˆä½¿ç”¨ Hyperoptï¼‰
    try:
        return self.model.optimize_hyperparams(train_data, val_data, max_evals)
    except Exception as e:
        logger.error(f"ä¼˜åŒ–å¤±è´¥: {e}")
        return {}
```

**å…³é”®æ–¹æ³•**ï¼š
- `_create_model()`: é€šè¿‡ ModelRegistry åŠ¨æ€åˆ›å»ºæ¨¡å‹å®ä¾‹
- `_preprocess_data()`: æ•°æ®é¢„å¤„ç†ï¼ˆå­ç±»å®ç°ï¼‰
- `_optimize_hyperparams()`: ç»Ÿä¸€çš„è¶…å‚æ•°ä¼˜åŒ–è°ƒåº¦
- `_evaluate_train_fitting()`: è¯„ä¼°è®­ç»ƒé›†æ‹Ÿåˆåº¦
- `_evaluate_test()`: è¯„ä¼°æµ‹è¯•é›†æ€§èƒ½
- `_save_model_to_mlflow()`: ä¿å­˜æ¨¡å‹ä¸º MLflow æ ¼å¼

è¯¦ç»†å®ç°è¯·å‚è€ƒç°æœ‰é¡¹ç›®ï¼š`classify_timeseries_server/training/trainer.py`

---

## ğŸ¯ æ¨¡å‹åŸºç±»è®¾è®¡

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

**åŸºç±»èŒè´£**ï¼š
- âœ… **å®šä¹‰æ¥å£å¥‘çº¦**ï¼šé€šè¿‡ `@abstractmethod` å£°æ˜å¿…é¡»å®ç°çš„æ–¹æ³•
- âœ… **æä¾›å·¥å…·æ–¹æ³•**ï¼šå¦‚ `get_params()`ã€`_check_fitted()` ç­‰é€šç”¨è¾…åŠ©
- âŒ **ä¸å®ç°ä¸šåŠ¡é€»è¾‘**ï¼šä¸åœ¨åŸºç±»ä¸­å®ç°å…·ä½“çš„è¯„ä¼°ã€é¢„å¤„ç†ç­‰é€»è¾‘

### ç»Ÿä¸€æ¥å£å®šä¹‰

```python
"""æ¨¡å‹åŸºç±» - æ ‡å‡†æ¥å£å®šä¹‰"""

from abc import ABC, abstractmethod
from typing import Any, Dict, Optional, Type
import pandas as pd
import numpy as np
from loguru import logger


class Base{Domain}Model(ABC):
    """æ¨¡å‹åŸºç±» - å®šä¹‰ç»Ÿä¸€æ¥å£
    
    è®¾è®¡åŸåˆ™ï¼š
    1. åŸºç±»åªå®šä¹‰æ¥å£å¥‘çº¦ï¼ˆ@abstractmethodï¼‰
    2. ä¸å®ç°å…·ä½“çš„ä¸šåŠ¡é€»è¾‘ï¼ˆå¦‚è¯„ä¼°ç®—æ³•ï¼‰
    3. å­ç±»å®Œæ•´å®ç°å„è‡ªçš„è¯„ä¼°é€»è¾‘
    
    å¿…é¡»å®ç°çš„æ ¸å¿ƒæ–¹æ³•ï¼š
    - fit(): è®­ç»ƒæ¨¡å‹
    - predict(): é¢„æµ‹
    - evaluate(): è¯„ä¼°æ€§èƒ½
    - optimize_hyperparams(): è¶…å‚æ•°ä¼˜åŒ–
    
    å¯é€‰å®ç°çš„æ–¹æ³•ï¼š
    - get_params(): è·å–æ¨¡å‹å‚æ•°
    - save()/load(): æ¨¡å‹æŒä¹…åŒ–
    
    å‘½åè§„èŒƒï¼š
    {Domain} åº”æ›¿æ¢ä¸ºç®—æ³•é¢†åŸŸçš„ PascalCase å•è¯ï¼Œä¾‹å¦‚ï¼š
    - æ—¶é—´åºåˆ—ï¼šBaseTimeSeriesModel
    - æ—¥å¿—åˆ†æï¼šBaseLogClusterModel
    - å¼‚å¸¸æ£€æµ‹ï¼šBaseAnomalyModel
    """
    
    def __init__(self, **kwargs):
        """åˆå§‹åŒ–æ¨¡å‹
        
        Args:
            **kwargs: æ¨¡å‹ç‰¹å®šçš„å‚æ•°
        """
        self.model = None
        self.config = kwargs
        self.is_fitted = False
    
    @abstractmethod
    def fit(self, 
            train_data: Any,
            val_data: Optional[Any] = None,
            **kwargs) -> 'Base{Domain}Model':
        """è®­ç»ƒæ¨¡å‹
        
        Args:
            train_data: è®­ç»ƒæ•°æ®
            val_data: éªŒè¯æ•°æ®ï¼ˆå¯é€‰ï¼‰
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            self: è®­ç»ƒåçš„æ¨¡å‹å®ä¾‹
        """
        pass
    
    @abstractmethod
    def predict(self, X: Any) -> np.ndarray:
        """é¢„æµ‹
        
        Args:
            X: è¾“å…¥æ•°æ®
            
        Returns:
            é¢„æµ‹ç»“æœ
            
        Raises:
            RuntimeError: æ¨¡å‹æœªè®­ç»ƒ
        """
        pass
    
    @abstractmethod
    def evaluate(self, 
                 test_data: Any,
                 ground_truth: Optional[Any] = None,
                 prefix: str = "test") -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆâš ï¸ å­ç±»å¿…é¡»å®Œæ•´å®ç°ï¼‰
        
        è®¾è®¡è¦æ±‚ï¼š
        1. å„æ¨¡å‹å®ç°è‡ªå·±çš„è¯„ä¼°é€»è¾‘ï¼Œä¸è°ƒç”¨åŸºç±»æ–¹æ³•
        2. æ ¹æ®ç®—æ³•ç‰¹æ€§é€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡
        3. è¿”å›çš„æŒ‡æ ‡åº”ä¸ä»»åŠ¡ç±»å‹åŒ¹é…
        
        Args:
            test_data: æµ‹è¯•æ•°æ®ï¼ˆæ ¼å¼ç”±å­ç±»å®šä¹‰ï¼‰
            ground_truth: çœŸå®æ ‡ç­¾ï¼ˆç›‘ç£ä»»åŠ¡ä½¿ç”¨ï¼Œå¯é€‰ï¼‰
            prefix: æŒ‡æ ‡åç§°å‰ç¼€ï¼ˆé»˜è®¤"test"ï¼‰
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸ï¼Œæ ¼å¼: {f"{prefix}_metric_name": value}
            
        ç¤ºä¾‹ï¼š
            # æ—¥å¿—èšç±»
            {"test_num_templates": 50, "test_coverage_rate": 0.95}
            
            # å¼‚å¸¸æ£€æµ‹
            {"test_precision": 0.85, "test_recall": 0.78, "test_f1": 0.81}
            
            # æ—¶åºé¢„æµ‹
            {"test_rmse": 12.5, "test_mae": 8.3, "test_mape": 0.15}
            
        æ³¨æ„ï¼š
        - å†…éƒ¨æ•°æ®ä½¿ç”¨ _ å‰ç¼€ï¼ˆå¦‚ _predictions, _y_trueï¼‰
        - ä»¥ _ å¼€å¤´çš„å­—æ®µä¸ä¼šè¢« MLflow è®°å½•
        - å„æ¨¡å‹çš„è¯„ä¼°é€»è¾‘å®Œå…¨ç‹¬ç«‹ï¼Œä¿æŒè‡ªæ²»
        
        è¯„ä¼°æŒ‡æ ‡å‘½åè§„èŒƒï¼š
        - ç»Ÿä¸€ä½¿ç”¨å°å†™ä¸‹åˆ’çº¿ï¼ˆsnake_caseï¼‰
        - ä¼˜å…ˆä½¿ç”¨è¡Œä¸šæ ‡å‡†ç¼©å†™ï¼ˆå¦‚ rmseã€maeã€f1ã€aucã€precisionã€recallï¼‰
        - è‡ªå®šä¹‰æŒ‡æ ‡ä½¿ç”¨æè¿°æ€§è‹±æ–‡å•è¯ï¼ˆå¦‚ num_templatesã€coverage_rateï¼‰
        - é¿å…æ··ç”¨ç¼©å†™å’Œå…¨ç§°ï¼ˆå¦‚ precision_f1scoreï¼‰
        """
        pass
    
    @abstractmethod
    def optimize_hyperparams(
        self,
        train_data: Any,
        val_data: Any,
        max_evals: int,
        **kwargs
    ) -> Dict[str, Any]:
        """è¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¿…é¡»å®ç°ï¼‰
        
        ä½¿ç”¨ Hyperopt è¿›è¡Œè´å¶æ–¯ä¼˜åŒ–ï¼Œå¯»æ‰¾æœ€ä¼˜è¶…å‚æ•°ç»„åˆã€‚
        
        Args:
            train_data: è®­ç»ƒæ•°æ®
            val_data: éªŒè¯æ•°æ®
            max_evals: æœ€å¤§è¯„ä¼°æ¬¡æ•°
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            æœ€ä¼˜è¶…å‚æ•°å­—å…¸
            
        å®ç°è¦æ±‚ï¼š
        1. å®šä¹‰æœç´¢ç©ºé—´ï¼ˆä» self.config è¯»å– search_spaceï¼‰
        2. å®šä¹‰ç›®æ ‡å‡½æ•°ï¼ˆè®­ç»ƒæ¨¡å‹å¹¶åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ï¼‰
        3. ä½¿ç”¨ hyperopt.fmin() æ‰§è¡Œä¼˜åŒ–
        4. è¿”å›æœ€ä¼˜å‚æ•°å­—å…¸
        
        ç¤ºä¾‹ï¼š
            from hyperopt import fmin, tpe, hp, Trials
            
            def objective(params):
                model = self.__class__(**params)
                model.fit(train_data)
                metrics = model.evaluate(val_data, prefix="val")
                return metrics["val_loss"]  # æœ€å°åŒ–ç›®æ ‡
            
            space = {
                'param1': hp.choice('param1', [10, 20, 30]),
                'param2': hp.uniform('param2', 0.1, 1.0)
            }
            
            best = fmin(objective, space, algo=tpe.suggest, max_evals=max_evals)
            return best
        """
        pass
    
    def get_params(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹å‚æ•°"""
        return self.config.copy()
    
    def _check_fitted(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ"""
        if not self.is_fitted:
            raise RuntimeError(f"{self.__class__.__name__} å¿…é¡»å…ˆè°ƒç”¨ fit()")


class ModelRegistry:
    """æ¨¡å‹æ³¨å†Œæœºåˆ¶ - æ”¯æŒåŠ¨æ€æ¨¡å‹åŠ è½½
    
    ä½¿ç”¨æ–¹å¼ï¼š
        @ModelRegistry.register("my_model")
        class MyModel(Base{Domain}Model):
            ...
        
        # åŠ¨æ€åˆ›å»ºæ¨¡å‹
        model_class = ModelRegistry.get("my_model")
        model = model_class(**params)
    """
    
    _registry: Dict[str, Type[Base{Domain}Model]] = {}
    
    @classmethod
    def register(cls, name: str):
        """æ³¨å†Œæ¨¡å‹è£…é¥°å™¨"""
        def decorator(model_class: Type[Base{Domain}Model]):
            if name in cls._registry:
                logger.warning(f"æ¨¡å‹ '{name}' å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–")
            cls._registry[name] = model_class
            logger.info(f"æ¨¡å‹å·²æ³¨å†Œ: {name} -> {model_class.__name__}")
            return model_class
        return decorator
    
    @classmethod
    def get(cls, name: str) -> Type[Base{Domain}Model]:
        """è·å–æ³¨å†Œçš„æ¨¡å‹ç±»"""
        if name not in cls._registry:
            available = ', '.join(cls._registry.keys())
            raise ValueError(
                f"æœªæ‰¾åˆ°æ¨¡å‹ '{name}'ã€‚å¯ç”¨æ¨¡å‹: {available}"
            )
        return cls._registry[name]
    
    @classmethod
    def list_models(cls) -> list:
        """åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„æ¨¡å‹"""
        return list(cls._registry.keys())
```

### å…·ä½“æ¨¡å‹å®ç°ç¤ºä¾‹

#### æ¨¡å‹ç±»å¿…é¡»å®ç°çš„æ–¹æ³•

- `fit()`: æ¨¡å‹è®­ç»ƒï¼ˆå¿…é¡»ï¼‰
- `predict()`: é¢„æµ‹é€»è¾‘ï¼ˆå¿…é¡»ï¼‰
- `evaluate()`: è¯„ä¼°æŒ‡æ ‡è®¡ç®—ï¼Œæ³¨æ„ä½¿ç”¨ `prefix` å‚æ•°ï¼ˆå¿…é¡»ï¼‰
- `optimize_hyperparams()`: è¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¿…é¡»ï¼‰
- `to_dict()`: æ¨¡å‹çŠ¶æ€åºåˆ—åŒ–ï¼ˆå¯é€‰ï¼Œç®€å•æ¨¡å‹å¯ç›´æ¥ä¿å­˜sklearnå¯¹è±¡ï¼‰
- `from_dict()`: ä»å­—å…¸æ¢å¤æ¨¡å‹ï¼ˆå¯é€‰ï¼Œä¸to_dicté…å¯¹ä½¿ç”¨ï¼‰

#### MLflow æ¨ç†åŒ…è£…å™¨ï¼ˆWrapperï¼‰

**å®šä¹‰**ï¼šWrapper æ˜¯ç»§æ‰¿è‡ª `mlflow.pyfunc.PythonModel` çš„ç±»ï¼Œç”¨äºå°†è®­ç»ƒå¥½çš„æ¨¡å‹å°è£…ä¸º MLflow å¯éƒ¨ç½²çš„æ¨ç†æ¥å£ã€‚

**ä½œç”¨**ï¼š
1. **ç»Ÿä¸€æ¨ç†æ¥å£**ï¼šå®ç° `predict()` æ–¹æ³•ï¼Œå¤„ç†è¾“å…¥è§£æå’Œè¾“å‡ºæ ¼å¼åŒ–
2. **å°è£…æ¨ç†é€»è¾‘**ï¼šåŒ…å«ç‰¹å¾å·¥ç¨‹ã€æ•°æ®é¢„å¤„ç†ã€åå¤„ç†ç­‰å®Œæ•´æ¨ç†æµç¨‹
3. **æ”¯æŒæ¨¡å‹æŒä¹…åŒ–**ï¼šé€šè¿‡ `mlflow.pyfunc.save_model()` ä¿å­˜ä¸º MLflow æ ¼å¼
4. **é¿å…é‡å‹ä¾èµ–**ï¼šæ¨ç†æ—¶ä¸éœ€è¦å¯¼å…¥è®­ç»ƒç›¸å…³çš„ä¾èµ–ï¼ˆå¦‚ hyperoptï¼‰

**ä½•æ—¶éœ€è¦å®ç° Wrapper**ï¼š
- âœ… æ¨¡å‹æ¨ç†éœ€è¦é¢å¤–çš„é¢„å¤„ç†æˆ–åå¤„ç†é€»è¾‘
- âœ… éœ€è¦åœ¨æ¨ç†æ—¶åŠ¨æ€ä½¿ç”¨ç‰¹å¾å·¥ç¨‹å™¨
- âœ… æ¨ç†é€»è¾‘ä¸è®­ç»ƒé€»è¾‘å·®å¼‚è¾ƒå¤§ï¼ˆå¦‚é€’å½’é¢„æµ‹ã€åœ¨çº¿å­¦ä¹ ï¼‰
- âœ… éœ€è¦æ”¯æŒå¤šç§æ¨ç†æ¨¡å¼ï¼ˆå¦‚æ‰¹é‡é¢„æµ‹ã€æµå¼é¢„æµ‹ï¼‰
- âŒ ç®€å•çš„ sklearn æ¨¡å‹å¯ç›´æ¥ä½¿ç”¨ `mlflow.sklearn.log_model()`

**å®ç°ä½ç½®**ï¼š`training/models/{algorithm}_wrapper.py`

**æ ‡å‡†ç»“æ„**ï¼š
```python
import mlflow
import pandas as pd
import numpy as np

class {Algorithm}Wrapper(mlflow.pyfunc.PythonModel):
    """æ¨¡å‹æ¨ç†åŒ…è£…å™¨"""
    
    def __init__(self, model, feature_engineer=None, **config):
        """åˆå§‹åŒ–
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹è±¡
            feature_engineer: ç‰¹å¾å·¥ç¨‹å™¨ï¼ˆå¦‚éœ€è¦ï¼‰
            **config: å…¶ä»–é…ç½®å‚æ•°
        """
        self.model = model
        self.feature_engineer = feature_engineer
        self.config = config
    
    def predict(self, context, model_input):
        """æ¨ç†æ¥å£
        
        Args:
            context: MLflow contextï¼ˆé€šå¸¸ä¸ä½¿ç”¨ï¼‰
            model_input: è¾“å…¥æ•°æ®ï¼ˆdictã€DataFrameç­‰ï¼‰
            
        Returns:
            é¢„æµ‹ç»“æœï¼ˆnumpy arrayã€listç­‰ï¼‰
        """
        # 1. è§£æè¾“å…¥
        X = self._parse_input(model_input)
        
        # 2. ç‰¹å¾å·¥ç¨‹ï¼ˆå¦‚éœ€è¦ï¼‰
        if self.feature_engineer:
            X = self.feature_engineer.transform(X)
        
        # 3. æ¨¡å‹é¢„æµ‹
        predictions = self.model.predict(X)
        
        # 4. åå¤„ç†ï¼ˆå¦‚éœ€è¦ï¼‰
        return self._postprocess(predictions)
    
    def _parse_input(self, model_input):
        """è§£æè¾“å…¥æ•°æ®ï¼ˆå­ç±»å®ç°ï¼‰"""
        raise NotImplementedError
    
    def _postprocess(self, predictions):
        """åå¤„ç†é¢„æµ‹ç»“æœï¼ˆå¯é€‰ï¼‰"""
        return predictions
```

**ä¸æ¨¡å‹ç±»çš„å…³ç³»**ï¼š
```python
# åœ¨æ¨¡å‹ç±»ä¸­åˆ›å»º Wrapper å¹¶ä¿å­˜åˆ° MLflow
class MyModel(BaseModel):
    def save_to_mlflow(self, run_id: str):
        """ä¿å­˜æ¨¡å‹åˆ° MLflow"""
        # åˆ›å»º Wrapper
        wrapper = MyModelWrapper(
            model=self.model,
            feature_engineer=self.feature_engineer,
            config=self.config
        )
        
        # ä¿å­˜ä¸º MLflow pyfunc æ ¼å¼
        mlflow.pyfunc.save_model(
            path=f"models/{run_id}",
            python_model=wrapper,
            artifacts={"model": self.model},
            conda_env=self._get_conda_env()
        )
```

**å‚è€ƒå®ç°**ï¼š
- `classify_timeseries_server/training/models/gradient_boosting_wrapper.py`
- `classify_timeseries_server/training/models/prophet_wrapper.py`

è¯¦ç»†å®ç°è¯·å‚è€ƒç°æœ‰é¡¹ç›®çš„å…·ä½“æ¨¡å‹æ–‡ä»¶ã€‚

---

## ğŸš€ BentoML æœåŠ¡è®¾è®¡

### æ ¸å¿ƒè®¾è®¡è¦ç‚¹

**æœåŠ¡ç»“æ„**ï¼š
- `@bentoml.service`: æœåŠ¡è£…é¥°å™¨ï¼Œé…ç½®è¶…æ—¶ç­‰å‚æ•°
- `@bentoml.on_deployment`: å…¨å±€åˆå§‹åŒ–ï¼ˆæ‰§è¡Œä¸€æ¬¡ï¼‰
- `__init__()`: æœåŠ¡å®ä¾‹åˆå§‹åŒ–ï¼ˆåŠ è½½é…ç½®å’Œæ¨¡å‹ï¼‰
- `@bentoml.on_shutdown`: æœåŠ¡å…³é—­æ—¶çš„æ¸…ç†
- `@bentoml.api`: API ç«¯ç‚¹å®šä¹‰

**å…³é”®åŠŸèƒ½**ï¼š
1. **æ¨¡å‹åŠ è½½**ï¼šæ”¯æŒæœ¬åœ°æ–‡ä»¶å’Œ MLflow Registry
2. **é…ç½®éªŒè¯**ï¼šå¯åŠ¨æ—¶å¿«é€Ÿå¤±è´¥ï¼ˆFast Failï¼‰
3. **ç›‘æ§æŒ‡æ ‡**ï¼šPrometheus metricsï¼ˆåŠ è½½æ¬¡æ•°ã€é¢„æµ‹æ¬¡æ•°ã€å»¶è¿Ÿï¼‰
4. **é”™è¯¯å¤„ç†**ï¼šç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
5. **DummyModel**ï¼šå½“åŠ è½½æ¨¡å‹å¤±è´¥æ—¶çš„é™çº§ç­–ç•¥(å¯é€‰ï¼Œå¯è‡ªä¸»é€‰æ‹©åŠ è½½æ¨¡å‹å¤±è´¥æ—¶æ˜¯æŠ¥é”™ï¼Œè¿˜æ˜¯ä½¿ç”¨é™çº§ç­–ç•¥)

**å¿…éœ€çš„ API ç«¯ç‚¹**ï¼š
- `predict()`: ä¸»è¦é¢„æµ‹æ¥å£ï¼ˆä½¿ç”¨ Pydantic schemasï¼‰
- `health()`: å¥åº·æ£€æŸ¥æ¥å£

è¯¦ç»†å®ç°è¯·å‚è€ƒç°æœ‰é¡¹ç›®çš„ `serving/service.py`ã€‚

---

## ğŸ“ é…ç½®æ–‡ä»¶è®¾è®¡

### é…ç½®ç»“æ„è¯´æ˜

**æ ¸å¿ƒåŸåˆ™**ï¼š
- ä½¿ç”¨æ‰å¹³åŒ–ç»“æ„ï¼Œé¿å…è¿‡åº¦åµŒå¥—
- åŒ…å«å¿…è¦çš„æ³¨é‡Šå­—æ®µï¼ˆ`_comment`ã€`_desc`ï¼‰
- æä¾›åˆç†çš„é»˜è®¤å€¼
- æ”¯æŒè¶…å‚æ•°æœç´¢ç©ºé—´å®šä¹‰

**å¿…éœ€çš„é¡¶å±‚å­—æ®µ**ï¼š
1. `model`: æ¨¡å‹é…ç½®ï¼ˆtype, nameï¼‰
2. `hyperparams`: è¶…å‚æ•°é…ç½®ï¼ˆå«æœç´¢ç©ºé—´ï¼‰
3. `preprocessing`: æ•°æ®é¢„å¤„ç†é…ç½®
4. `feature_engineering`: ç‰¹å¾å·¥ç¨‹é…ç½®ï¼ˆå¿…é€‰ï¼‰
5. `mlflow`: MLflow å®éªŒè·Ÿè¸ªé…ç½®ï¼ˆå¯é€‰ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰

### é…ç½®ç¤ºä¾‹
å¤§ä½“ç»“æ„ï¼Œå…·ä½“å‚æ•°ç”±ç±»å‹å®ç°è€Œå®š
å…·ä½“å‚è€ƒå„ç±»å‹å…·ä½“å®ç°çš„support-filesæ–‡ä»¶å¤¹ä¸­çš„ç¤ºä¾‹æ–‡ä»¶
```json
{
  "model": {
    "type": "æ¨¡å‹ç±»å‹æ ‡è¯†ç¬¦ï¼ˆå¯¹åº” ModelRegistry æ³¨å†Œåï¼‰",
    "name": "æ¨¡å‹åç§°ï¼ˆç”¨äº MLflow è®°å½•ï¼‰"
  },
  
  "hyperparams": {
    "use_feature_engineering": "æ˜¯å¦å¯ç”¨ç‰¹å¾å·¥ç¨‹ï¼ˆå¸ƒå°”å€¼ï¼‰",
    "random_state": "éšæœºç§å­ï¼ˆæ•´æ•°ï¼‰",
    "max_evals": "è¶…å‚æ•°æœç´¢æ¬¡æ•°ï¼ˆ0è¡¨ç¤ºè·³è¿‡ï¼‰",
    "metric": "ä¼˜åŒ–ç›®æ ‡æŒ‡æ ‡åç§°",
    "search_space": {
      "param_name": ["å€™é€‰å€¼åˆ—è¡¨"]
    }
    "search_space": {
      ...
    }
  },
  
  "feature_engineering": {
    ...
  },
  
  "preprocessing": {
    ...
  },
  "mlflow": {
    "experiment_name": "..."
  }
}
```

---

## ğŸ”§ CLI è®¾è®¡

### bootstrap.py æ ‡å‡†å®ç°

```python
"""å‘½ä»¤è¡Œæ¥å£ - æ ‡å‡†å®ç°"""

from dotenv import load_dotenv
import fire
from loguru import logger
from pathlib import Path
import json

load_dotenv()


class CLI:
    """å‘½ä»¤è¡Œå·¥å…·"""
    
    def train(
        self,
        dataset_path: str,
        config: str,
        run_name: str = None,
    ):
        """è®­ç»ƒæ¨¡å‹
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆç›®å½•æˆ–æ–‡ä»¶ï¼‰
            config: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
            run_name: MLflow run åç§°ï¼ˆå¯é€‰ï¼‰
        
        Environment Variables:
            MLFLOW_TRACKING_URI: MLflow æœåŠ¡åœ°å€ï¼ˆå¿…éœ€ï¼‰
        
        Example:
            # åŸºæœ¬è®­ç»ƒ
            export MLFLOW_TRACKING_URI=http://mlflow:5000
            classify_{domain}_server train \\
                --dataset-path ./data/ \\
                --config train.json
            
            # è‡ªå®šä¹‰runåç§°
            classify_{domain}_server train \\
                --dataset-path ./data/ \\
                --config custom-train.json \\
                --run-name my_experiment_v1
        """
        from ..training import UniversalTrainer, TrainingConfig
        import os
        
        try:
            # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
            if not os.getenv("MLFLOW_TRACKING_URI"):
                logger.error("âŒ MLFLOW_TRACKING_URI ç¯å¢ƒå˜é‡æœªè®¾ç½®")
                return
            
            # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            config_path = Path(config)
            if not config_path.exists():
                logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config}")
                return
            
            # åŠ è½½é…ç½®
            config_obj = TrainingConfig.from_file(config)
            
            # è¦†ç›– run_nameï¼ˆå¦‚æœæä¾›ï¼‰
            if run_name:
                config_obj.mlflow_run_name = run_name
            
            # åˆ›å»ºè®­ç»ƒå™¨å¹¶è®­ç»ƒ
            trainer = UniversalTrainer(config_obj)
            result = trainer.train(dataset_path)
            
            logger.info("âœ… è®­ç»ƒæˆåŠŸå®Œæˆ")
            logger.info(f"Run ID: {result['run_id']}")
            
        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}", exc_info=True)
            raise
    
    def version(self):
        """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
        print("classify_{domain}_server v0.1.0")


def main():
    """CLI å…¥å£"""
    fire.Fire(CLI)


if __name__ == "__main__":
    main()
```

---

## ğŸ³ Docker éƒ¨ç½²é…ç½®

### Dockerfile æ ‡å‡†å®ç°

æ‰€æœ‰ä¸‰ä¸ªæœåŠ¡ä½¿ç”¨ç»Ÿä¸€çš„ Dockerfile ç»“æ„ï¼Œç¡®ä¿æ„å»ºä¸€è‡´æ€§ï¼š

```dockerfile
FROM python:3.12
WORKDIR /apps
ARG NEXUS_PYTHON_REPOSITY

RUN sed -i 's/deb.debian.org/repo.huaweicloud.com/g' /etc/apt/sources.list.d/debian.sources

RUN apt-get update -y
RUN apt-get install -y vim supervisor unzip curl fonts-wqy-zenhei

# æ›´æ–°ç³»ç»Ÿå­—ä½“ç¼“å­˜
RUN fc-cache -fv

# é…ç½® pip é•œåƒæºï¼ˆå¦‚æœæä¾›ï¼‰
RUN if [ -n "$NEXUS_PYTHON_REPOSITY" ]; then \
    pip3 config set global.index-url "$NEXUS_PYTHON_REPOSITY" && \
    pip3 config set global.trusted-host "$(echo $NEXUS_PYTHON_REPOSITY | sed -E 's|^https?://([^/:]+).*|\1|')"; \
    fi

# å®‰è£… uv (Python åŒ…ç®¡ç†å·¥å…·)
RUN pip3 install uv

ADD . .

# è®¾ç½®è„šæœ¬å’Œ mc å¯æ‰§è¡Œæƒé™
RUN chmod +x ./support-files/release/startup.sh && \
    chmod +x ./support-files/scripts/train-model.sh && \
    chmod +x ./mc

# ä½¿ç”¨ uv å®‰è£…é¡¹ç›®ä¾èµ–å¹¶é¢„å…ˆåŒæ­¥è™šæ‹Ÿç¯å¢ƒï¼ˆé€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šé•œåƒæºï¼‰
RUN if [ -n "$NEXUS_PYTHON_REPOSITY" ]; then \
    uv pip install --system --index-url "$NEXUS_PYTHON_REPOSITY" -e ".[dev]" && \
    uv sync --index-url "$NEXUS_PYTHON_REPOSITY"; \
    else \
    uv pip install --system -e ".[dev]" && \
    uv sync; \
    fi

# æ¸…ç† matplotlib å­—ä½“ç¼“å­˜ï¼Œè®©å…¶é‡æ–°æ‰«æå­—ä½“
RUN rm -rf /root/.cache/matplotlib /root/.cache/fontconfig

RUN apt-get reinstall -y supervisor 

ENTRYPOINT ["/bin/bash","/apps/support-files/release/startup.sh"]
```

---

## ğŸ“œ è®­ç»ƒè„šæœ¬æ ‡å‡†å®ç°

### train-model.sh æ ¸å¿ƒè¦ç‚¹

ä½ç½®ï¼š`support-files/scripts/train-model.sh`

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
1. ä» MinIO ä¸‹è½½æ•°æ®é›†ï¼ˆZIPæ ¼å¼ï¼‰
2. è§£å‹åˆ°æœ¬åœ°ç›®å½•
3. ä¸‹è½½æˆ–ä½¿ç”¨æœ¬åœ°é…ç½®æ–‡ä»¶ (æœªæ¥æ”¶åˆ°ä¼ å…¥é…ç½®æ–‡ä»¶è·¯å¾„åˆ™ä½¿ç”¨é»˜è®¤é…ç½®åœ°å€ é»˜è®¤å­˜æ”¾ä½ç½® ./train.json(æœ¬åœ°è·¯å¾„ï¼Œå’Œtrain-model.shåŒä¸€ç›®å½•))
4. è°ƒç”¨ CLI è®­ç»ƒå‘½ä»¤
5. å¯é€‰çš„æ¸…ç†æ“ä½œ

**å‚æ•°æ¥å£**ï¼š
```bash
./train-model.sh [BUCKET] [DATASET] [CONFIG]

# ç¤ºä¾‹
./train-model.sh datasets my_data.zip
./train-model.sh datasets my_data.zip configs/train.json
```

**å¿…éœ€çš„ç¯å¢ƒå˜é‡**ï¼š
```bash
export MINIO_ENDPOINT=http://minio-server:9000
export MINIO_ACCESS_KEY=your-access-key
export MINIO_SECRET_KEY=your-secret-key
export MLFLOW_TRACKING_URI=http://mlflow:15000
```

**è„šæœ¬æ ¸å¿ƒé€»è¾‘**ï¼š
1. ç¯å¢ƒæ£€æŸ¥ï¼ˆuv, python, unzip, mcï¼‰
2. MinIO è¿æ¥é…ç½®
3. ä¸‹è½½å¹¶è§£å‹æ•°æ®é›†
4. å‡†å¤‡é…ç½®æ–‡ä»¶ï¼ˆMinIOæˆ–æœ¬åœ°ï¼‰
5. æ‰§è¡Œè®­ç»ƒï¼š`uv run classify_{domain}_server train --dataset-path=... --config=...`
6. é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

è¯¦ç»†å®ç°è¯·å‚è€ƒç°æœ‰é¡¹ç›®çš„ `support-files/scripts/train-model.sh`

---

## âœ… å®ç°æ£€æŸ¥æ¸…å•

### å¿…é¡»å®ç°çš„ç»„ä»¶

- [ ] é¡¹ç›®ç»“æ„æŒ‰æ ‡å‡†æ¨¡æ¿åˆ›å»º
- [ ] `Base{Domain}Model` æŠ½è±¡åŸºç±»
- [ ] `ModelRegistry` æ³¨å†Œæœºåˆ¶
- [ ] è‡³å°‘ä¸€ä¸ªå…·ä½“æ¨¡å‹å®ç°
- [ ] `UniversalTrainer` è®­ç»ƒå™¨
- [ ] æ•°æ®åŠ è½½å™¨ï¼ˆæ”¯æŒç›®å½•/æ–‡ä»¶æ¨¡å¼ï¼‰
- [ ] æ•°æ®é¢„å¤„ç†å™¨
- [ ] BentoML æœåŠ¡å®šä¹‰
- [ ] Pydantic Schema å®šä¹‰
- [ ] `DummyModel` å®ç° (å¯é€‰)
- [ ] CLI æ¥å£ï¼ˆtrain/serveå‘½ä»¤ï¼‰
- [ ] `train.json` é»˜è®¤é…ç½®
- [ ] `MLFlowUtils` å·¥å…·å‡½æ•°
- [ ] Prometheus æŒ‡æ ‡å®šä¹‰
- [ ] README.md æ–‡æ¡£
- [ ] è¶…å‚æ•°ä¼˜åŒ–ï¼ˆHyperoptï¼‰
- [ ] ç‰¹å¾å·¥ç¨‹æ¨¡å—
- [ ] æ¨¡å‹å¯è§†åŒ–


---

## ğŸ¨ ä»£ç é£æ ¼è§„èŒƒ

### å‘½åçº¦å®š

- **åŒ…å**: `classify_{domain}_server`ï¼ˆå°å†™+ä¸‹åˆ’çº¿ï¼‰
- **ç±»å**: `PascalCase`ï¼ˆå¦‚ `UniversalTrainer`ï¼‰
- **å‡½æ•°å**: `snake_case`ï¼ˆå¦‚ `load_model`ï¼‰
- **å¸¸é‡**: `UPPER_CASE`ï¼ˆå¦‚ `MAX_RETRIES`ï¼‰
- **ç§æœ‰æ–¹æ³•**: `_snake_case`ï¼ˆå¦‚ `_validate_config`ï¼‰

---

## ğŸ“š å‚è€ƒå®ç°

æŸ¥çœ‹ç°æœ‰ä¸‰ä¸ªæœåŠ¡çš„å®ç°ï¼š

- **classify_anomaly_server**: å¼‚å¸¸æ£€æµ‹ï¼ˆPyODï¼‰
- **classify_log_server**: æ—¥å¿—èšç±»ï¼ˆlogparser3ï¼‰
- **classify_timeseries_server**: æ—¶é—´åºåˆ—ï¼ˆProphet/sklearnï¼‰

**æ¨èå­¦ä¹ è·¯å¾„**ï¼š

1. å…ˆé˜…è¯» `classify_timeseries_server`ï¼ˆæœ€å®Œæ•´ï¼‰
2. å¯¹æ¯” `classify_anomaly_server`ï¼ˆäº†è§£å¼‚å¸¸æ£€æµ‹ç‰¹æ€§ï¼‰
3. å‚è€ƒ `classify_log_server`ï¼ˆäº†è§£æ–‡æœ¬å¤„ç†ï¼‰

---

## ğŸ“Œ è®¾è®¡åŸåˆ™æ€»ç»“

1. **ç»Ÿä¸€æ¶æ„**ï¼šéµå¾ªç°æœ‰ä¸‰ä¸ªæœåŠ¡çš„æ¨¡å¼
2. **æ¸è¿›å¼è®¾è®¡**ï¼šå…ˆå®ç°æ ¸å¿ƒåŠŸèƒ½ï¼Œå†æ‰©å±•
3. **é¿å…è¿‡æ—©æŠ½è±¡**ï¼šç­‰çœŸæ­£éœ€è¦æ—¶å†æå–å…¬å…±é€»è¾‘
4. **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡é…ç½®åˆ‡æ¢æ¨¡å‹å’Œå‚æ•°
5. **å®Œå–„æ–‡æ¡£**ï¼šä»£ç å³æ–‡æ¡£ï¼Œæ³¨é‡Šæ¸…æ™°
6. **å®¹é”™æœºåˆ¶**ï¼šå¯åŠ¨æ—¶é…ç½®éªŒè¯ï¼Œè¿è¡Œæ—¶å¼‚å¸¸å¤„ç†
7. **å¯è§‚æµ‹æ€§**ï¼šPrometheus æŒ‡æ ‡ + è¯¦ç»†æ—¥å¿—
---

