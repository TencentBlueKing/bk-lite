"""é€šç”¨å¼‚å¸¸æ£€æµ‹è®­ç»ƒå™¨

æ”¯æŒå¤šç§å¼‚å¸¸æ£€æµ‹æ¨¡åž‹çš„ç»Ÿä¸€è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
- åŠ¨æ€æ¨¡åž‹é€‰æ‹©
- è¶…å‚æ•°ä¼˜åŒ–
- æ¨¡åž‹è®­ç»ƒå’Œè¯„ä¼°
- MLflow é›†æˆ
"""

from typing import Dict, Any, Optional, Tuple
import pandas as pd
import numpy as np
import mlflow
from pathlib import Path
from loguru import logger

from .config.loader import TrainingConfig
from .models.base import ModelRegistry, BaseAnomalyModel
from .preprocessing import AnomalyDataPreprocessor, AnomalyFeatureEngineer
from .data_loader import load_dataset, split_train_test
from .mlflow_utils import MLFlowUtils


class UniversalTrainer:
    """é€šç”¨å¼‚å¸¸æ£€æµ‹è®­ç»ƒå™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. é…ç½®é©±åŠ¨çš„è®­ç»ƒæµç¨‹
    2. åŠ¨æ€æ¨¡åž‹åŠ è½½ï¼ˆé€šè¿‡ ModelRegistryï¼‰
    3. å®Œæ•´çš„æ•°æ®å¤„ç† Pipeline
    4. å¯é€‰çš„è¶…å‚æ•°ä¼˜åŒ–
    5. MLflow å®žéªŒè·Ÿè¸ª
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        config = TrainingConfig("train.json")
        trainer = UniversalTrainer(config)
        result = trainer.train("data.csv")
    """
    
    def __init__(self, config: TrainingConfig):
        """åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config: è®­ç»ƒé…ç½®å¯¹è±¡
        """
        self.config = config
        self.model = None
        self.preprocessor = None
        self.feature_engineer = None
        
        logger.info(f"è®­ç»ƒå™¨åˆå§‹åŒ– - æ¨¡åž‹ç±»åž‹: {config.model_type}")
    
    def train(self, dataset_path: str) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
        
        æ•°æ®åŠ è½½æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        - ç›®å½•æ¨¡å¼ï¼šdataset_path ä¸ºç›®å½•ï¼Œè‡ªåŠ¨æŸ¥æ‰¾ train_data.csv/val_data.csv/test_data.csv
        - æ–‡ä»¶æ¨¡å¼ï¼šdataset_path ä¸ºå•ä¸ªCSVæ–‡ä»¶ï¼Œè‡ªåŠ¨æŒ‰å›ºå®šæ¯”ä¾‹(0.2/0.1)åˆ’åˆ†
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆç›®å½•æˆ–å•ä¸ªæ–‡ä»¶ï¼‰
            
        Returns:
            è®­ç»ƒç»“æžœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - model: è®­ç»ƒå¥½çš„æ¨¡åž‹
            - test_metrics: æµ‹è¯•é›†è¯„ä¼°æŒ‡æ ‡
            - val_metrics: éªŒè¯é›†è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æžœæœ‰ï¼‰
            - run_id: MLflow run ID
            - best_params: æœ€ä¼˜è¶…å‚æ•°ï¼ˆå¦‚æžœè¿›è¡Œäº†ä¼˜åŒ–ï¼‰
        """
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹è®­ç»ƒ - æ¨¡åž‹: {self.config.model_type}")
        logger.info("=" * 60)
        
        # 1. è®¾ç½® MLflow
        self._setup_mlflow()
        
        # 2. åŠ è½½æ•°æ®
        train_df, val_df, test_df = self._load_data(dataset_path)
        
        # 3. æ•°æ®é¢„å¤„ç†
        train_data, val_data, test_data = self._preprocess_data(
            train_df, 
            val_df, 
            test_df
        )
        
        # 4. åˆ›å»ºæ¨¡åž‹å®žä¾‹
        self.model = self._create_model()
        
        # 5. å¼€å§‹ MLflow run
        with mlflow.start_run(run_name=self.config.mlflow_run_name) as run:
            try:
                # è®°å½•é…ç½®
                self._log_config()
                
                # 6. è¶…å‚æ•°ä¼˜åŒ–ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
                best_params = None
                if val_data is not None:
                    best_params = self._optimize_hyperparams(train_data, val_data)
                    if best_params:
                        MLFlowUtils.log_params_batch(best_params)
                
                # 7. è®­ç»ƒæ¨¡åž‹
                self._train_model(train_data, val_data)
                
                # 8. è¯„ä¼°è®­ç»ƒé›†æ‹Ÿåˆåº¦ï¼ˆæ ·æœ¬å†…è¯„ä¼°ï¼‰
                val_metrics = None
                if val_data is not None:
                    # åœ¨è®­ç»ƒ+éªŒè¯é›†ä¸Šè¯„ä¼°
                    final_train_data = pd.concat([train_data[0], val_data[0]], axis=0)
                    final_train_labels = pd.concat([train_data[1], val_data[1]], axis=0)
                    logger.info("è¯„ä¼°æœ€ç»ˆè®­ç»ƒæ•°æ®æ‹Ÿåˆåº¦ï¼ˆtrain+valæ ·æœ¬å†…è¯„ä¼°ï¼‰...")
                    final_train_metrics = self.model.evaluate(
                        final_train_data, 
                        final_train_labels,
                        prefix="final_train"
                    )
                    # ä½¿ç”¨ MLFlowUtils æ‰¹é‡è®°å½•ï¼ˆè‡ªåŠ¨è¿‡æ»¤å†…éƒ¨æ•°æ®å’Œéžæ•°å€¼ç±»åž‹ï¼‰
                    MLFlowUtils.log_metrics_batch(final_train_metrics, prefix="")
                    MLFlowUtils.log_params_batch({
                        "final_train_samples": len(final_train_data),
                        "final_train_merge_val": True
                    })
                    # åªè¾“å‡ºæ•°å€¼ç»Ÿè®¡æŒ‡æ ‡åˆ°æ—¥å¿—
                    summary = {
                        k: v for k, v in final_train_metrics.items() 
                        if not k.startswith('_') and isinstance(v, (int, float))
                    }
                    logger.info(f"æœ€ç»ˆè®­ç»ƒæ•°æ®æ‹Ÿåˆåº¦è¯„ä¼°å®Œæˆ: {summary}")
                else:
                    # æ— éªŒè¯é›†ï¼Œåªè¯„ä¼°è®­ç»ƒé›†
                    logger.info("è¯„ä¼°è®­ç»ƒé›†æ‹Ÿåˆåº¦ï¼ˆæ ·æœ¬å†…è¯„ä¼°ï¼‰...")
                    train_metrics = self.model.evaluate(
                        train_data[0],
                        train_data[1],
                        prefix="train"
                    )
                    # ä½¿ç”¨ MLFlowUtils æ‰¹é‡è®°å½•ï¼ˆè‡ªåŠ¨è¿‡æ»¤ï¼‰
                    MLFlowUtils.log_metrics_batch(train_metrics, prefix="")
                    # åªè¾“å‡ºæ•°å€¼ç»Ÿè®¡æŒ‡æ ‡åˆ°æ—¥å¿—
                    summary = {
                        k: v for k, v in train_metrics.items() 
                        if not k.startswith('_') and isinstance(v, (int, float))
                    }
                    logger.info(f"è®­ç»ƒé›†æ‹Ÿåˆåº¦è¯„ä¼°å®Œæˆ: {summary}")
                
                # 9. è¯„ä¼°æµ‹è¯•é›†
                test_metrics = self._evaluate_model_on_test(test_data)
                # ä½¿ç”¨ MLFlowUtils æ‰¹é‡è®°å½•ï¼ˆè‡ªåŠ¨è¿‡æ»¤ï¼‰
                MLFlowUtils.log_metrics_batch(test_metrics, prefix="")
                
                # 10. ä¿å­˜æ¨¡åž‹åˆ° MLflow
                model_uri = self._save_model_to_mlflow()
                
                # 11. æ³¨å†Œæ¨¡åž‹åˆ° MLflow Model Registry
                self._register_model(model_uri)
                
                result = {
                    'model': self.model,
                    'test_metrics': test_metrics,
                    'val_metrics': val_metrics,
                    'run_id': run.info.run_id,
                    'best_params': best_params
                }
                
                # è¿‡æ»¤æµ‹è¯•é›†æŒ‡æ ‡ï¼Œåªè¾“å‡ºæ•°å€¼ç»Ÿè®¡
                test_summary = {
                    k: v for k, v in test_metrics.items() 
                    if not k.startswith('_') and isinstance(v, (int, float))
                }
                
                logger.info("=" * 60)
                logger.info("è®­ç»ƒå®Œæˆ")
                logger.info(f"MLflow Run ID: {run.info.run_id}")
                logger.info(f"æµ‹è¯•é›†æŒ‡æ ‡: {test_summary}")
                logger.info("=" * 60)
                
                return result
                
            except Exception as e:
                logger.error(f"è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
                mlflow.log_param("training_failed", True)
                raise
    
    def _setup_mlflow(self):
        """è®¾ç½® MLflow å®žéªŒ"""
        tracking_uri = self.config.mlflow_tracking_uri
        experiment_name = self.config.mlflow_experiment_name
        
        # ä½¿ç”¨ MLFlowUtils ç»Ÿä¸€è®¾ç½®
        MLFlowUtils.setup_experiment(tracking_uri, experiment_name)
    
    def _load_data(self, dataset_path: str) -> Tuple[pd.DataFrame, Optional[pd.DataFrame], pd.DataFrame]:
        """åŠ è½½æ•°æ®é›†
        
        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        1. ç›®å½•æ¨¡å¼ï¼šdataset_path ä¸ºç›®å½•
           - å¿…é¡»åŒ…å« train_data.csv
           - å¯é€‰ val_data.csv å’Œ test_data.csv
        2. æ–‡ä»¶æ¨¡å¼ï¼šdataset_path ä¸ºå•ä¸ª CSV æ–‡ä»¶
           - è‡ªåŠ¨æŒ‰å›ºå®šæ¯”ä¾‹åˆ’åˆ†ï¼ˆæµ‹è¯•é›† 0.2ï¼ŒéªŒè¯é›† 0.1ï¼‰
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆç›®å½•æˆ–æ–‡ä»¶ï¼‰
            
        Returns:
            (è®­ç»ƒé›†, éªŒè¯é›†, æµ‹è¯•é›†) çš„ DataFrame å…ƒç»„
            
        Raises:
            FileNotFoundError: ç›®å½•æ¨¡å¼ä¸‹æœªæ‰¾åˆ° train_data.csv
        """
        import os
        
        if os.path.isdir(dataset_path):
            # ç›®å½•æ¨¡å¼
            logger.info(f"ðŸ“ æ£€æµ‹åˆ°ç›®å½•æ¨¡å¼: {dataset_path}")
            
            train_path = os.path.join(dataset_path, "train_data.csv")
            if not os.path.exists(train_path):
                raise FileNotFoundError(
                    f"ç›®å½•æ¨¡å¼ä¸‹æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶: {train_path}\n"
                    f"ç›®å½•ä¸­å¿…é¡»åŒ…å« train_data.csv"
                )
            
            train_df = load_dataset(train_path)
            logger.info(f"âœ“ è®­ç»ƒé›†: {len(train_df)} æ¡è®°å½• (train_data.csv)")
            
            # å¯é€‰çš„éªŒè¯é›†
            val_df = None
            val_path = os.path.join(dataset_path, "val_data.csv")
            if os.path.exists(val_path):
                val_df = load_dataset(val_path)
                logger.info(f"âœ“ éªŒè¯é›†: {len(val_df)} æ¡è®°å½• (val_data.csv)")
            else:
                logger.info("âš  æœªæ‰¾åˆ° val_data.csvï¼Œå°†ä»Žè®­ç»ƒé›†è‡ªåŠ¨åˆ’åˆ†")
            
            # å¯é€‰çš„æµ‹è¯•é›†
            test_df = None
            test_path = os.path.join(dataset_path, "test_data.csv")
            if os.path.exists(test_path):
                test_df = load_dataset(test_path)
                logger.info(f"âœ“ æµ‹è¯•é›†: {len(test_df)} æ¡è®°å½• (test_data.csv)")
            else:
                logger.info("âš  æœªæ‰¾åˆ° test_data.csvï¼Œå°†ä»Žè®­ç»ƒé›†è‡ªåŠ¨åˆ’åˆ†")
            
            return train_df, val_df, test_df
        
        elif os.path.isfile(dataset_path):
            # æ–‡ä»¶æ¨¡å¼
            logger.info(f"ðŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶æ¨¡å¼: {dataset_path}")
            df = load_dataset(dataset_path)
            logger.info(f"âœ“ åŠ è½½æ•°æ®: {len(df)} æ¡è®°å½•")
            logger.info("â„¹ å°†æŒ‰å›ºå®šæ¯”ä¾‹è‡ªåŠ¨åˆ’åˆ†ï¼ˆæµ‹è¯•é›† 0.2ï¼ŒéªŒè¯é›† 0.1ï¼‰")
            return df, None, None
        
        else:
            raise ValueError(
                f"æ— æ•ˆçš„æ•°æ®é›†è·¯å¾„: {dataset_path}\n"
                f"è·¯å¾„å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š\n"
                f"  1. åŒ…å« train_data.csv çš„ç›®å½•\n"
                f"  2. å•ä¸ª CSV æ–‡ä»¶"
            )
    
    def _preprocess_data(self,
                         train_df: pd.DataFrame,
                         val_df: Optional[pd.DataFrame],
                         test_df: Optional[pd.DataFrame]) -> Tuple[Tuple[pd.DataFrame, pd.Series], 
                                                                     Optional[Tuple[pd.DataFrame, pd.Series]], 
                                                                     Tuple[pd.DataFrame, pd.Series]]:
        """æ•°æ®é¢„å¤„ç†ï¼ˆæ¸…æ´— + ç‰¹å¾å·¥ç¨‹ + è‡ªåŠ¨åˆ’åˆ†ï¼‰
        
        å¦‚æœªæä¾›æµ‹è¯•é›†/éªŒè¯é›†ï¼Œä»Žè®­ç»ƒé›†æŒ‰å›ºå®šæ¯”ä¾‹è‡ªåŠ¨åˆ’åˆ†ï¼ˆæµ‹è¯•é›†0.2ï¼ŒéªŒè¯é›†0.1ï¼‰ã€‚
        
        Args:
            train_df: è®­ç»ƒæ•°æ®æ¡†ï¼ˆå•æ–‡ä»¶æ¨¡å¼æ—¶åŒ…å«å®Œæ•´æ•°æ®ï¼‰
            val_df: éªŒè¯æ•°æ®æ¡†ï¼ˆå¯é€‰ï¼‰
            test_df: æµ‹è¯•æ•°æ®æ¡†ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ((è®­ç»ƒç‰¹å¾, è®­ç»ƒæ ‡ç­¾), (éªŒè¯ç‰¹å¾, éªŒè¯æ ‡ç­¾), (æµ‹è¯•ç‰¹å¾, æµ‹è¯•æ ‡ç­¾))
        """
        logger.info("æ•°æ®é¢„å¤„ç†ï¼ˆæ¸…æ´— + ç‰¹å¾å·¥ç¨‹ï¼‰...")
        
        # 1. èŽ·å–é…ç½®
        preprocess_config = self.config.preprocessing_config
        fe_config = self.config.feature_engineering_config if self.config.use_feature_engineering else {}
        label_column = self.config.label_column
        
        # 2. åˆ›å»ºé¢„å¤„ç†å™¨
        self.preprocessor = AnomalyDataPreprocessor(
            max_missing_ratio=preprocess_config.get("max_missing_ratio", 0.3),
            handle_missing=preprocess_config.get("handle_missing", "interpolate")
        )
        
        logger.info(f"é¢„å¤„ç†é…ç½®: {preprocess_config}")
        
        # 3. æ¸…æ´—å¹¶æå–æ ‡ç­¾
        def clean_and_extract_labels(df):
            """æ¸…æ´—æ•°æ®å¹¶æå–æ ‡ç­¾"""
            cleaned_df, frequency = self.preprocessor.clean(df.copy(), label_column=label_column)
            if label_column in cleaned_df.columns:
                labels = cleaned_df.pop(label_column)
            else:
                labels = None
            return cleaned_df, labels
        
        # å¤„ç†è®­ç»ƒé›†
        train_data, train_labels = clean_and_extract_labels(train_df)
        logger.info(f"è®­ç»ƒé›†æ¸…æ´—å®Œæˆ: {len(train_data)} ä¸ªæ•°æ®ç‚¹")
        
        # å¤„ç†éªŒè¯é›†
        val_data, val_labels = None, None
        if val_df is not None:
            val_data, val_labels = clean_and_extract_labels(val_df)
            logger.info(f"éªŒè¯é›†æ¸…æ´—å®Œæˆ: {len(val_data)} ä¸ªæ•°æ®ç‚¹")
        
        # å¤„ç†æµ‹è¯•é›†æˆ–ä»Žè®­ç»ƒé›†åˆ†å‰²
        if test_df is not None:
            test_data, test_labels = clean_and_extract_labels(test_df)
            logger.info(f"æµ‹è¯•é›†æ¸…æ´—å®Œæˆ: {len(test_data)} ä¸ªæ•°æ®ç‚¹")
        else:
            # ä»Žè®­ç»ƒé›†åˆ†å‰²æµ‹è¯•é›†ï¼ˆ20%ï¼‰
            test_size = 0.2
            split_point = int(len(train_data) * (1 - test_size))
            test_data = train_data[split_point:].copy()
            test_labels = train_labels[split_point:].copy() if train_labels is not None else None
            train_data = train_data[:split_point].copy()
            train_labels = train_labels[:split_point].copy() if train_labels is not None else None
            logger.info(f"ä»Žè®­ç»ƒé›†åˆ†å‰²æµ‹è¯•é›†: è®­ç»ƒ={len(train_data)}, æµ‹è¯•={len(test_data)}")
            
            # å¦‚æžœéœ€è¦éªŒè¯é›†ï¼Œä»Žè®­ç»ƒé›†å†åˆ†å‰²ï¼ˆ12.5% * 80% = 10%ï¼‰
            if val_data is None:
                val_size = 0.125
                val_split = int(len(train_data) * (1 - val_size))
                val_data = train_data[val_split:].copy()
                val_labels = train_labels[val_split:].copy() if train_labels is not None else None
                train_data = train_data[:val_split].copy()
                train_labels = train_labels[:val_split].copy() if train_labels is not None else None
                logger.info(f"ä»Žè®­ç»ƒé›†åˆ†å‰²éªŒè¯é›†: è®­ç»ƒ={len(train_data)}, éªŒè¯={len(val_data)}")
        
        # 4. ç‰¹å¾å·¥ç¨‹ï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if self.config.use_feature_engineering and fe_config:
            logger.info("åº”ç”¨ç‰¹å¾å·¥ç¨‹...")
            self.feature_engineer = AnomalyFeatureEngineer(**fe_config)
            
            # åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆå¹¶è½¬æ¢ï¼ˆå°† DataFrame['value'] è½¬ä¸º Seriesï¼‰
            train_data = self.feature_engineer.fit_transform(train_data['value'])
            # å¯¹é½æ ‡ç­¾ç´¢å¼•ï¼ˆç‰¹å¾å·¥ç¨‹å¯èƒ½åˆ é™¤äº†NaNè¡Œï¼‰
            train_labels = train_labels.loc[train_data.index] if train_labels is not None else None
            logger.info(f"è®­ç»ƒé›†ç‰¹å¾å·¥ç¨‹å®Œæˆ: {train_data.shape[1]} ä¸ªç‰¹å¾, {len(train_data)} æ ·æœ¬")
            
            # è½¬æ¢éªŒè¯é›†å’Œæµ‹è¯•é›†
            if val_data is not None:
                val_data = self.feature_engineer.transform(val_data['value'])
                # å¯¹é½éªŒè¯é›†æ ‡ç­¾ç´¢å¼•
                val_labels = val_labels.loc[val_data.index] if val_labels is not None else None
                logger.info(f"éªŒè¯é›†ç‰¹å¾å·¥ç¨‹å®Œæˆ: {val_data.shape[1]} ä¸ªç‰¹å¾, {len(val_data)} æ ·æœ¬")
            
            test_data = self.feature_engineer.transform(test_data['value'])
            # å¯¹é½æµ‹è¯•é›†æ ‡ç­¾ç´¢å¼•
            test_labels = test_labels.loc[test_data.index] if test_labels is not None else None
            logger.info(f"æµ‹è¯•é›†ç‰¹å¾å·¥ç¨‹å®Œæˆ: {test_data.shape[1]} ä¸ªç‰¹å¾, {len(test_data)} æ ·æœ¬")
        
        # 5. è®°å½•æ•°æ®ä¿¡æ¯åˆ° MLflow
        if mlflow.active_run():
            self._log_data_info(train_data, val_data, test_data, train_labels, val_labels, test_labels)
        
        logger.info("æ•°æ®é¢„å¤„ç†å®Œæˆ")
        
        return (train_data, train_labels), (val_data, val_labels) if val_data is not None else None, (test_data, test_labels)
    
    def _log_data_info(self, train_data, val_data, test_data, train_labels, val_labels, test_labels):
        """è®°å½•æ•°æ®ä¿¡æ¯åˆ° MLflow"""
        # æ•°æ®åŸºæœ¬ä¿¡æ¯
        if isinstance(train_data.index, pd.DatetimeIndex):
            mlflow.log_param("train_start_date", str(train_data.index[0]))
            mlflow.log_param("train_end_date", str(train_data.index[-1]))
            if val_data is not None and isinstance(val_data.index, pd.DatetimeIndex):
                mlflow.log_param("val_start_date", str(val_data.index[0]))
                mlflow.log_param("val_end_date", str(val_data.index[-1]))
            if test_data is not None and isinstance(test_data.index, pd.DatetimeIndex):
                mlflow.log_param("test_start_date", str(test_data.index[0]))
                mlflow.log_param("test_end_date", str(test_data.index[-1]))
        
        mlflow.log_param("train_samples", len(train_data))
        if val_data is not None:
            mlflow.log_param("val_samples", len(val_data))
        if test_data is not None:
            mlflow.log_param("test_samples", len(test_data))
        
        mlflow.log_param("num_features", train_data.shape[1])
        
        # æ ‡ç­¾åˆ†å¸ƒ
        if train_labels is not None:
            anomaly_count = train_labels.sum()
            anomaly_ratio = anomaly_count / len(train_labels)
            mlflow.log_metric("train_anomaly_count", int(anomaly_count))
            mlflow.log_metric("train_anomaly_ratio", float(anomaly_ratio))
        
        if val_labels is not None:
            anomaly_count = val_labels.sum()
            anomaly_ratio = anomaly_count / len(val_labels)
            mlflow.log_metric("val_anomaly_count", int(anomaly_count))
            mlflow.log_metric("val_anomaly_ratio", float(anomaly_ratio))
        
        if test_labels is not None:
            anomaly_count = test_labels.sum()
            anomaly_ratio = anomaly_count / len(test_labels)
            mlflow.log_metric("test_anomaly_count", int(anomaly_count))
            mlflow.log_metric("test_anomaly_ratio", float(anomaly_ratio))
        
        logger.info("æ•°æ®ä¿¡æ¯å·²è®°å½•åˆ° MLflow")
    
    def _create_model(self) -> BaseAnomalyModel:
        """åˆ›å»ºæ¨¡åž‹å®žä¾‹
        
        Returns:
            æ¨¡åž‹å®žä¾‹
            
        Raises:
            ValueError: æ¨¡åž‹ç±»åž‹æœªæ³¨å†Œ
        """
        model_type = self.config.model_type
        
        # ä»Žæ³¨å†Œè¡¨èŽ·å–æ¨¡åž‹ç±»
        model_class = ModelRegistry.get(model_type)
        
        # èŽ·å–æ¨¡åž‹å‚æ•°
        random_state = self.config.random_state
        
        logger.info(f"åˆ›å»ºæ¨¡åž‹: {model_type}")
        logger.debug(f"éšæœºç§å­: {random_state}")
        
        # å®žä¾‹åŒ–æ¨¡åž‹
        model = model_class(random_state=random_state)
        
        return model
    
    def _optimize_hyperparams(self,
                              train_data: Tuple[pd.DataFrame, pd.Series],
                              val_data: Tuple[pd.DataFrame, pd.Series]) -> Dict[str, Any]:
        """è¶…å‚æ•°ä¼˜åŒ–
        
        Args:
            train_data: (è®­ç»ƒç‰¹å¾, è®­ç»ƒæ ‡ç­¾)
            val_data: (éªŒè¯ç‰¹å¾, éªŒè¯æ ‡ç­¾)
            
        Returns:
            æœ€ä¼˜è¶…å‚æ•°å­—å…¸
        """
        logger.info("å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–...")
        
        # æ£€æŸ¥æ¨¡åž‹æ˜¯å¦æ”¯æŒè¶…å‚æ•°ä¼˜åŒ–
        if not hasattr(self.model, 'optimize_hyperparams'):
            logger.warning(f"{self.config.model_type} æ¨¡åž‹ä¸æ”¯æŒè¶…å‚æ•°ä¼˜åŒ–ï¼Œè·³è¿‡")
            return {}
        
        # è§£åŒ…ç‰¹å¾å’Œæ ‡ç­¾
        train_X, train_y = train_data
        val_X, val_y = val_data
        
        # æ£€æŸ¥éªŒè¯é›†æ˜¯å¦æœ‰æ ‡ç­¾
        if val_y is None:
            logger.warning("éªŒè¯é›†æ²¡æœ‰æ ‡ç­¾ï¼Œæ— æ³•è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–ï¼Œè·³è¿‡")
            return {}
        
        # æ‰§è¡Œä¼˜åŒ–ï¼ˆä¼ é€’è§£åŒ…åŽçš„å‚æ•°ï¼‰
        best_params = self.model.optimize_hyperparams(train_X, val_X, train_y, val_y, self.config)
        
        logger.info(f"è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ: {best_params}")
        
        return best_params
    
    def _train_model(self,
                     train_data: Tuple[pd.DataFrame, pd.Series],
                     val_data: Optional[Tuple[pd.DataFrame, pd.Series]]):
        """è®­ç»ƒæ¨¡åž‹
        
        Args:
            train_data: (è®­ç»ƒç‰¹å¾, è®­ç»ƒæ ‡ç­¾)
            val_data: (éªŒè¯ç‰¹å¾, éªŒè¯æ ‡ç­¾)ï¼ˆå¯é€‰ï¼‰
        """
        logger.info("å¼€å§‹è®­ç»ƒæ¨¡åž‹...")
        
        # åˆå¹¶è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆå¼‚å¸¸æ£€æµ‹é€šå¸¸ä½¿ç”¨æ‰€æœ‰æ­£å¸¸æ•°æ®è®­ç»ƒï¼‰
        if val_data is not None and val_data[0] is not None:
            X_train = pd.concat([train_data[0], val_data[0]], axis=0)
            y_train = pd.concat([train_data[1], val_data[1]], axis=0) if train_data[1] is not None else None
            logger.info(f"åˆå¹¶è®­ç»ƒé›†å’ŒéªŒè¯é›†: {len(X_train)} ä¸ªæ ·æœ¬")
        else:
            X_train = train_data[0]
            y_train = train_data[1]
        
        self.model.fit(X_train, y_train)
        
        logger.info("æ¨¡åž‹è®­ç»ƒå®Œæˆ")
    
    def _evaluate_model_on_test(self, test_data: Tuple[pd.DataFrame, pd.Series]) -> Dict[str, float]:
        """è¯„ä¼°æµ‹è¯•é›†
        
        Args:
            test_data: (æµ‹è¯•ç‰¹å¾, æµ‹è¯•æ ‡ç­¾)
            
        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        logger.info("è¯„ä¼°æµ‹è¯•é›†...")
        
        X_test, y_test = test_data
        
        # ä½¿ç”¨æ¨¡åž‹çš„ evaluate() æ–¹æ³•è¿›è¡Œè¯„ä¼°
        metrics = self.model.evaluate(X_test, y_test, prefix="test")
        
        # åªè¾“å‡ºæ•°å€¼ç»Ÿè®¡æŒ‡æ ‡åˆ°æ—¥å¿—ï¼ˆè¿‡æ»¤åˆ—è¡¨å’Œå†…éƒ¨æ•°æ®ï¼‰
        summary = {
            k: v for k, v in metrics.items() 
            if not k.startswith('_') and isinstance(v, (int, float))
        }
        logger.info(f"æµ‹è¯•é›†è¯„ä¼°å®Œæˆ: {summary}")
        
        # ç»˜åˆ¶å¯è§†åŒ–å›¾è¡¨
        if mlflow.active_run():
            y_pred = self.model.predict(X_test)
            y_scores = self.model.predict_proba(X_test)
            y_true = y_test.values if hasattr(y_test, 'values') else y_test
            
            # 1. å¼‚å¸¸æ£€æµ‹ç»“æžœå›¾ï¼ˆæ—¶åºå¯è§†åŒ–ï¼‰
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾æˆ–ç´¢å¼•ä½œä¸ºæ—¶é—´åºåˆ—å€¼
            values = X_test.iloc[:, 0].values if X_test.shape[1] > 0 else np.arange(len(X_test))
            MLFlowUtils.plot_anomaly_detection_results(
                timestamps=X_test.index,
                values=values,
                predictions=y_pred,
                scores=y_scores,
                true_labels=y_true,
                threshold=self.model.threshold_,
                title=f"{self.config.model_type} å¼‚å¸¸æ£€æµ‹ç»“æžœ",
                artifact_name=f"{self.config.model_type}_detection",
                metrics=metrics
            )
            
            # 2. æ··æ·†çŸ©é˜µï¼ˆä»Ž metrics ä¸­æå–ï¼‰
            if 'test_confusion_matrix' in metrics:
                cm = np.array(metrics['test_confusion_matrix'])
                MLFlowUtils.plot_confusion_matrix(
                    confusion_matrix=cm,
                    title=f"{self.config.model_type} æ··æ·†çŸ©é˜µ",
                    artifact_name=f"{self.config.model_type}_confusion_matrix"
                )
            
            # 3. å¼‚å¸¸åˆ†æ•°åˆ†å¸ƒï¼ˆåˆ†ç¦»æ­£å¸¸å’Œå¼‚å¸¸æ ·æœ¬ï¼‰
            normal_mask = y_true == 0
            anomaly_mask = y_true == 1
            if normal_mask.any() and anomaly_mask.any():
                MLFlowUtils.plot_score_distribution(
                    normal_scores=y_scores[normal_mask],
                    anomaly_scores=y_scores[anomaly_mask],
                    threshold=self.model.threshold_,
                    title=f"{self.config.model_type} å¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ",
                    artifact_name=f"{self.config.model_type}_score_distribution"
                )
            
            # 4. ROC æ›²çº¿ï¼ˆæ•´ä½“æ€§èƒ½è¯„ä¼°ï¼‰
            try:
                MLFlowUtils.plot_roc_curve(
                    y_true=y_true,
                    y_scores=y_scores,
                    title=f"{self.config.model_type} ROC æ›²çº¿",
                    artifact_name=f"{self.config.model_type}_roc"
                )
            except Exception as e:
                logger.warning(f"ROC æ›²çº¿ç»˜åˆ¶å¤±è´¥: {e}")
            
            # 5. Precision-Recall æ›²çº¿ï¼ˆæŽ¨èç”¨äºŽä¸å¹³è¡¡æ•°æ®ï¼‰
            try:
                MLFlowUtils.plot_precision_recall_curve(
                    y_true=y_true,
                    y_scores=y_scores,
                    title=f"{self.config.model_type} Precision-Recall æ›²çº¿",
                    artifact_name=f"{self.config.model_type}_pr"
                )
            except Exception as e:
                logger.warning(f"PR æ›²çº¿ç»˜åˆ¶å¤±è´¥: {e}")
            
            # 6. ECOD å¼‚å¸¸åˆ†æ•°åˆ†è§£å›¾ï¼ˆä»…å¯¹ECODæ¨¡åž‹ï¼‰
            if self.config.model_type.upper() == "ECOD":
                try:
                    # èŽ·å–PyOD ECODæ¨¡åž‹å®žä¾‹
                    pyod_model = self.model.model if hasattr(self.model, 'model') else None
                    if pyod_model is not None:
                        MLFlowUtils.plot_ecod_decomposition(
                            model=pyod_model,
                            X=X_test,
                            feature_names=X_test.columns.tolist(),
                            top_n=10,  # å±•ç¤ºå¼‚å¸¸åˆ†æ•°æœ€é«˜çš„10ä¸ªæ ·æœ¬
                            title=f"{self.config.model_type} å¼‚å¸¸åˆ†æ•°åˆ†è§£",
                            artifact_name=f"{self.config.model_type}_decomposition"
                        )
                        logger.info("âœ“ ECODåˆ†è§£å›¾å·²ç”Ÿæˆ")
                    else:
                        logger.warning("æ— æ³•èŽ·å–ECODæ¨¡åž‹å®žä¾‹ï¼Œè·³è¿‡åˆ†è§£å¯è§†åŒ–")
                except Exception as e:
                    logger.warning(f"ECODåˆ†è§£å›¾ç»˜åˆ¶å¤±è´¥: {e}")
            
            logger.info("âœ“ å¯è§†åŒ–å›¾è¡¨å·²å…¨éƒ¨ä¸Šä¼ åˆ° MLflow")
        
        return metrics
    
    def _log_config(self):
        """è®°å½•é…ç½®åˆ° MLflow"""
        # è®°å½•æ¨¡åž‹é…ç½®
        logger.info(f"è®°å½•åˆ°mlflowçš„æ¨¡åž‹é…ç½®: ")
        mlflow.log_param("model_type", self.config.model_type)
        mlflow.log_param("model_name", self.config.model_name)
        logger.info(f"æ¨¡åž‹é…ç½®: model_type: {self.config.model_type} model_name: {self.config.model_name}")
        
        # è®°å½•è¶…å‚æ•°é…ç½®
        mlflow.log_param("use_feature_engineering", self.config.use_feature_engineering)
        mlflow.log_param("random_state", self.config.random_state)
        mlflow.log_param("max_evals", self.config.max_evals)
        mlflow.log_param("metric", self.config.metric)
        logger.info(f"è¶…å‚æ•°é…ç½®: use_fe={self.config.use_feature_engineering}, random_state={self.config.random_state}, max_evals={self.config.max_evals}, metric={self.config.metric}")
        
        # è®°å½•é¢„å¤„ç†é…ç½®
        preprocess_config = self.config.preprocessing_config
        logger.info(f"é¢„å¤„ç†é…ç½®: {preprocess_config}")
        for key, value in preprocess_config.items():
            mlflow.log_param(f"preprocessing_{key}", value)
        
        # è®°å½•ç‰¹å¾å·¥ç¨‹é…ç½®
        if self.config.use_feature_engineering:
            fe_config = self.config.feature_engineering_config
            logger.info(f"ç‰¹å¾å·¥ç¨‹é…ç½®: {fe_config}")
            for key, value in fe_config.items():
                if isinstance(value, (list, dict)):
                    mlflow.log_param(f"fe_{key}", str(value))
                else:
                    mlflow.log_param(f"fe_{key}", value)
    
    def _save_model_to_mlflow(self) -> str:
        """ä¿å­˜æ¨¡åž‹åˆ° MLflow
        
        Returns:
            æ¨¡åž‹ URI
        """
        logger.info("ä¿å­˜æ¨¡åž‹åˆ° MLflow...")
        
        model_type = self.config.model_type
        
        # æ£€æŸ¥æ¨¡åž‹æ˜¯å¦æœ‰ save_mlflow æ–¹æ³•
        if hasattr(self.model, 'save_mlflow') and callable(getattr(self.model, 'save_mlflow')):
            try:
                self.model.save_mlflow(artifact_path="model")
                logger.info(f"{model_type} æ¨¡åž‹å·²ä¿å­˜")
            except Exception as e:
                logger.error(f"æ¨¡åž‹ä¿å­˜å¤±è´¥: {e}")
                raise
        else:
            logger.warning(f"æ¨¡åž‹ç±»åž‹ {model_type} æ²¡æœ‰å®žçŽ° save_mlflow æ–¹æ³•")
        
        model_uri = f"runs:/{mlflow.active_run().info.run_id}/model"
        return model_uri
    
    def _register_model(self, model_uri: Optional[str]):
        """æ³¨å†Œæ¨¡åž‹åˆ° MLflow Model Registry
        
        Args:
            model_uri: æ¨¡åž‹ URI
        """
        if not model_uri:
            logger.warning("æ¨¡åž‹ URI ä¸ºç©ºï¼Œè·³è¿‡æ³¨å†Œ")
            return
        
        model_name = self.config.model_name
        
        try:
            logger.info(f"æ³¨å†Œæ¨¡åž‹åˆ° Model Registry: {model_name}")
            model_version = mlflow.register_model(model_uri, model_name)
            logger.info(f"æ¨¡åž‹æ³¨å†ŒæˆåŠŸ: {model_name}, ç‰ˆæœ¬: {model_version.version}")
        except Exception as e:
            logger.warning(f"æ¨¡åž‹æ³¨å†Œå¤±è´¥: {e}")
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹è¿›è¡Œé¢„æµ‹
        
        Args:
            X: ç‰¹å¾æ•°æ®
            
        Returns:
            é¢„æµ‹ç»“æžœæ•°ç»„ï¼ˆ0=æ­£å¸¸ï¼Œ1=å¼‚å¸¸ï¼‰
            
        Raises:
            RuntimeError: æ¨¡åž‹æœªè®­ç»ƒ
        """
        if self.model is None:
            raise RuntimeError("æ¨¡åž‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ train() æ–¹æ³•")
        
        return self.model.predict(X)
    
    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹é¢„æµ‹å¼‚å¸¸å¾—åˆ†
        
        Args:
            X: ç‰¹å¾æ•°æ®
            
        Returns:
            å¼‚å¸¸å¾—åˆ†æ•°ç»„
            
        Raises:
            RuntimeError: æ¨¡åž‹æœªè®­ç»ƒ
        """
        if self.model is None:
            raise RuntimeError("æ¨¡åž‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ train() æ–¹æ³•")
        
        return self.model.predict_proba(X)
    
    def __repr__(self) -> str:
        model_info = f"model={self.model}" if self.model else "model=None"
        return f"UniversalTrainer(model_type={self.config.model_type}, {model_info})"
