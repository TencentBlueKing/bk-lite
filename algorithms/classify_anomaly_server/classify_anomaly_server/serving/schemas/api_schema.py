"""Pydantic schemas for request/response validation."""

from typing import Optional
from pydantic import BaseModel, Field
import pandas as pd


class TimeSeriesPoint(BaseModel):
    """æ—¶é—´åºåˆ—æ•°æ®ç‚¹."""
    
    timestamp: int = Field(
        ...,
        description="Unixæ—¶é—´æˆ³ï¼ˆç§’çº§ï¼‰"
    )
    value: float = Field(
        ...,
        description="è§‚æµ‹å€¼"
    )


class DetectionConfig(BaseModel):
    """å¼‚å¸¸æ£€æµ‹é…ç½®."""
    
    threshold: Optional[float] = Field(
        None,
        description="å¼‚å¸¸é˜ˆå€¼ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨æ¨¡å‹é»˜è®¤é˜ˆå€¼ï¼‰",
        gt=0.0,
        le=1.0
    )


class PredictRequest(BaseModel):
    """å¼‚å¸¸æ£€æµ‹è¯·æ±‚."""

    data: list[TimeSeriesPoint] = Field(
        ...,
        description="å¾…æ£€æµ‹çš„æ—¶é—´åºåˆ—æ•°æ®"
    )
    config: Optional[DetectionConfig] = Field(
        None,
        description="æ£€æµ‹é…ç½®ï¼ˆå¯é€‰ï¼‰"
    )
    
    def to_series(self) -> pd.Series:
        """è½¬æ¢ä¸º pandas Seriesï¼Œè‡ªåŠ¨å¤„ç†æ’åºå’Œå»é‡."""
        from loguru import logger
        
        # ä»Unixæ—¶é—´æˆ³ï¼ˆç§’çº§ï¼‰è½¬æ¢ä¸ºpd.Timestampï¼Œä¸å¸¦æ—¶åŒºï¼ˆnaive datetimeï¼‰
        timestamps = pd.to_datetime([point.timestamp for point in self.data], unit='s')
        values = [point.value for point in self.data]
        series = pd.Series(values, index=timestamps)
        
        original_count = len(series)
        
        # è‡ªåŠ¨æ’åºï¼ˆå¦‚æœæœªæ’åºï¼‰
        if not series.index.is_monotonic_increasing:
            logger.warning(f"âš ï¸  æ—¶é—´æˆ³æœªæŒ‰å‡åºæ’åˆ—ï¼Œè‡ªåŠ¨æ’åº")
            series = series.sort_index()
        
        # å»é‡ï¼ˆå¦‚æœæœ‰é‡å¤æ—¶é—´æˆ³ï¼Œä¿ç•™æœ€åä¸€ä¸ªå€¼ï¼‰
        if series.index.has_duplicates:
            duplicate_count = series.index.duplicated().sum()
            logger.warning(f"âš ï¸  å‘ç° {duplicate_count} ä¸ªé‡å¤æ—¶é—´æˆ³ï¼Œä¿ç•™æœ€åå‡ºç°çš„å€¼")
            series = series[~series.index.duplicated(keep='last')]
        
        # è®°å½•å¤„ç†ç»“æœ
        if len(series) != original_count:
            logger.info(f"ğŸ“Š æ•°æ®å¤„ç†: è¾“å…¥ {original_count} ä¸ªç‚¹ -> è¾“å‡º {len(series)} ä¸ªç‚¹")
        
        return series


class AnomalyPoint(BaseModel):
    """å¼‚å¸¸æ£€æµ‹ç»“æœç‚¹."""
    
    timestamp: int = Field(..., description="Unixæ—¶é—´æˆ³ï¼ˆç§’çº§ï¼‰")
    value: float = Field(..., description="åŸå§‹è§‚æµ‹å€¼")
    label: int = Field(..., description="æ ‡ç­¾: 0=æ­£å¸¸, 1=å¼‚å¸¸")
    anomaly_score: float = Field(..., description="å¼‚å¸¸åˆ†æ•°ï¼ˆè¶Šé«˜è¶Šå¼‚å¸¸ï¼‰")
    anomaly_probability: float = Field(..., description="å½’ä¸€åŒ–çš„å¼‚å¸¸æ¦‚ç‡ [0,1]ï¼ŒåŸºäºé˜ˆå€¼çº¿æ€§æ˜ å°„")


class ResponseMetadata(BaseModel):
    """å“åº”å…ƒæ•°æ®."""
    
    model_uri: Optional[str] = Field(None, description="æ¨¡å‹URI")
    input_data_points: int = Field(..., description="è¾“å…¥æ•°æ®ç‚¹æ•°")
    detected_anomalies: int = Field(..., description="æ£€æµ‹åˆ°çš„å¼‚å¸¸ç‚¹æ•°")
    anomaly_rate: float = Field(..., description="å¼‚å¸¸ç‡")
    input_frequency: Optional[str] = Field(None, description="æ£€æµ‹åˆ°çš„è¾“å…¥é¢‘ç‡")
    execution_time_ms: float = Field(..., description="æ‰§è¡Œè€—æ—¶ï¼ˆæ¯«ç§’ï¼‰")


class ErrorDetail(BaseModel):
    """é”™è¯¯è¯¦æƒ…."""
    
    code: str = Field(..., description="é”™è¯¯ä»£ç ")
    message: str = Field(..., description="é”™è¯¯æ¶ˆæ¯")
    details: Optional[dict] = Field(None, description="è¯¦ç»†ä¿¡æ¯")


class PredictResponse(BaseModel):
    """å¼‚å¸¸æ£€æµ‹å“åº”."""
    
    success: bool = Field(default=True, description="æ˜¯å¦æˆåŠŸ")
    results: Optional[list[AnomalyPoint]] = Field(None, description="æ£€æµ‹ç»“æœåˆ—è¡¨")
    metadata: ResponseMetadata = Field(..., description="å“åº”å…ƒæ•°æ®")
    error: Optional[ErrorDetail] = Field(None, description="é”™è¯¯ä¿¡æ¯")
