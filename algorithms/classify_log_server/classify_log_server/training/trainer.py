"""æ—¥å¿—èšç±»æ¨¡å‹é€šç”¨è®­ç»ƒå™¨"""

from pathlib import Path
from typing import Any, Dict, Optional, Tuple, List
import datetime

from loguru import logger
import mlflow

from .config.loader import TrainingConfig
from .data_loader import LogDataLoader
from .mlflow_utils import MLFlowUtils
from .models.base import ModelRegistry
from .models import SpellModel  # å¯¼å…¥å…·ä½“æ¨¡å‹ä»¥è§¦å‘æ³¨å†Œ
from .preprocessing.log_preprocessor import LogPreprocessor, LogParser
from .preprocessing.feature_engineering import LogFeatureEngineer, prepare_log_dataframe


class UniversalTrainer:
    """æ—¥å¿—èšç±»æ¨¡å‹é€šç”¨è®­ç»ƒå™¨
    
    å¤„ç†å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼š
    1. åŠ è½½é…ç½®
    2. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    3. è®­ç»ƒæ¨¡å‹ï¼ˆå¯é€‰è¶…å‚æ•°ä¼˜åŒ–ï¼‰
    4. è¯„ä¼°æ¨¡å‹
    5. ä¿å­˜æ¨¡å‹å¹¶è®°å½•åˆ° MLflow
    """

    def __init__(self, config: TrainingConfig):
        """åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            config: è®­ç»ƒé…ç½®
        """
        self.config = config
        self.output_dir = Path("outputs")
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        self.data_loader = LogDataLoader(encoding="utf-8")
        
        # é¢„å¤„ç†ç»„ä»¶ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.log_parser = None
        self.preprocessor = None
        self.feature_engineer = None
        self.model = None

        logger.info(f"è®­ç»ƒå™¨åˆå§‹åŒ– - æ¨¡å‹ç±»å‹: {config.model_type}")

    def train(self, dataset_path: str) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆç›®å½•æˆ–å•ä¸ªTXTæ–‡ä»¶ï¼‰
                         - ç›®å½•æ¨¡å¼ï¼šåŒ…å« train.txt/val.txt/test.txt
                         - æ–‡ä»¶æ¨¡å¼ï¼šå•ä¸ªTXTæ–‡ä»¶

        Returns:
            è®­ç»ƒç»“æœå­—å…¸ï¼ˆæŒ‡æ ‡ã€æ¨¡å‹è·¯å¾„ç­‰ï¼‰
        """
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹è®­ç»ƒ - æ¨¡å‹: {self.config.model_type}")
        logger.info("=" * 60)

        # 1. è®¾ç½® MLflow
        self._setup_mlflow()
        
        # 2. åŠ è½½æ•°æ®
        train_logs, val_logs, test_logs = self._load_data(dataset_path)
        
        # 3. æ•°æ®é¢„å¤„ç†
        train_data, val_data, test_data = self._preprocess_data(
            train_logs,
            val_logs,
            test_logs
        )
        
        # 4. åˆ›å»ºæ¨¡å‹å®ä¾‹
        self.model = self._create_model()
        
        # 5. å¼€å§‹ MLflow run
        with mlflow.start_run(run_name=self.config.mlflow_run_name) as run:
            try:
                # è®°å½•é…ç½®
                self._log_config()
                
                # è®°å½•æ•°æ®ä¿¡æ¯
                self._log_data_info(train_logs, val_logs, test_logs)

                # 6. è¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
                best_params = None
                if val_data:
                    best_params = self._optimize_hyperparams(train_data, val_data)
                    if best_params:
                        MLFlowUtils.log_params_batch({f"best_{k}": v for k, v in best_params.items()})
                        logger.info(f"æœ€ä¼˜å‚æ•°: {best_params}")
                        
                        # ç”¨æœ€ä¼˜å‚æ•°é‡æ–°åˆ›å»ºæ¨¡å‹
                        logger.info("ä½¿ç”¨æœ€ä¼˜å‚æ•°é‡æ–°åˆ›å»ºæ¨¡å‹...")
                        self.model = ModelRegistry.create_model(self.config.model_type, **best_params)
                
                # 7. è®­ç»ƒæ¨¡å‹
                self._train_model(train_data, val_data)
                
                # 8. è¯„ä¼°è®­ç»ƒé›†æ‹Ÿåˆåº¦ï¼ˆæ ·æœ¬å†…è¯„ä¼°ï¼‰
                if val_data:
                    # åˆå¹¶train+valè¯„ä¼°æœ€ç»ˆè®­ç»ƒæ•°æ®
                    final_train_data = train_data + val_data
                    logger.info("è¯„ä¼°æœ€ç»ˆè®­ç»ƒæ•°æ®æ‹Ÿåˆåº¦ï¼ˆtrain+valæ ·æœ¬å†…è¯„ä¼°ï¼‰...")
                    final_train_metrics = self.model.evaluate(final_train_data, ground_truth=None)
                    # ä½¿ç”¨ MLFlowUtils æ‰¹é‡è®°å½•ï¼ˆè‡ªåŠ¨è¿‡æ»¤ï¼‰
                    MLFlowUtils.log_metrics_batch(final_train_metrics, prefix="final_train_")
                    MLFlowUtils.log_params_batch({
                        "final_train_samples": len(final_train_data),
                        "final_train_merge_val": True
                    })
                    # åªè¾“å‡ºæ•°å€¼ç»Ÿè®¡æŒ‡æ ‡åˆ°æ—¥å¿—
                    summary = {
                        k: v for k, v in final_train_metrics.items() 
                        if not k.startswith('_') and isinstance(v, (int, float))
                    }
                    logger.info(f"æœ€ç»ˆè®­ç»ƒæ•°æ®æ‹Ÿåˆåº¦è¯„ä¼°å®Œæˆ: {summary}")
                else:
                    # æ— éªŒè¯é›†ï¼Œåªè¯„ä¼°è®­ç»ƒé›†
                    logger.info("è¯„ä¼°è®­ç»ƒé›†æ‹Ÿåˆåº¦ï¼ˆæ ·æœ¬å†…è¯„ä¼°ï¼‰...")
                    train_metrics = self.model.evaluate(train_data, ground_truth=None)
                    # ä½¿ç”¨ MLFlowUtils æ‰¹é‡è®°å½•
                    MLFlowUtils.log_metrics_batch(train_metrics, prefix="train_")
                    # åªè¾“å‡ºæ•°å€¼ç»Ÿè®¡æŒ‡æ ‡åˆ°æ—¥å¿—
                    summary = {
                        k: v for k, v in train_metrics.items() 
                        if not k.startswith('_') and isinstance(v, (int, float))
                    }
                    logger.info(f"è®­ç»ƒé›†æ‹Ÿåˆåº¦è¯„ä¼°å®Œæˆ: {summary}")

                # 9. è¯„ä¼°æµ‹è¯•é›†
                test_metrics = {}
                if test_data:
                    logger.info("è¯„ä¼°æµ‹è¯•é›†...")
                    test_metrics = self.model.evaluate(test_data, ground_truth=None)
                    # ä½¿ç”¨ MLFlowUtils æ‰¹é‡è®°å½•
                    MLFlowUtils.log_metrics_batch(test_metrics, prefix="test_")
                    # åªè¾“å‡ºæ•°å€¼ç»Ÿè®¡æŒ‡æ ‡åˆ°æ—¥å¿—
                    test_summary = {
                        k: v for k, v in test_metrics.items() 
                        if not k.startswith('_') and isinstance(v, (int, float))
                    }
                    logger.info(f"æµ‹è¯•é›†è¯„ä¼°å®Œæˆ: {test_summary}")
                    
                    # ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–
                    try:
                        # ä½¿ç”¨final_train_metricsæˆ–train_metrics
                        train_cmp_metrics = final_train_metrics if val_data else train_metrics
                        MLFlowUtils.plot_clustering_metrics_comparison(
                            train_metrics=train_cmp_metrics,
                            test_metrics=test_metrics
                        )
                    except Exception as e:
                        logger.warning(f"ç”ŸæˆæŒ‡æ ‡å¯¹æ¯”å›¾å¤±è´¥: {e}")
                else:
                    logger.info("âš  æœªæ‰¾åˆ° test.txtï¼Œä½¿ç”¨è®­ç»ƒé›†æŒ‡æ ‡ä½œä¸ºæµ‹è¯•é›†è¯„ä¼°")
                    if val_data:
                        test_metrics = {k.replace('final_train_', 'test_'): v for k, v in final_train_metrics.items()}
                    else:
                        test_metrics = {k.replace('train_', 'test_'): v for k, v in train_metrics.items()}
                
                # 10. ä¿å­˜æ¨¡å‹åˆ° MLflow
                model_uri = self._save_model_to_mlflow()
                
                # ç”Ÿæˆç»“æœ
                result = {
                    "model": self.model,
                    "model_type": self.config.model_type,
                    "test_metrics": test_metrics,
                    "num_train_logs": len(train_logs),
                    "num_val_logs": len(val_logs) if val_logs else 0,
                    "num_test_logs": len(test_logs) if test_logs else 0,
                    "num_templates": self.model.get_num_templates(),
                    "run_id": run.info.run_id,
                    "best_params": best_params
                }
                
                # è¿‡æ»¤æµ‹è¯•é›†æŒ‡æ ‡ï¼Œåªè¾“å‡ºæ•°å€¼ç»Ÿè®¡
                test_summary = {
                    k: v for k, v in test_metrics.items() 
                    if not k.startswith('_') and isinstance(v, (int, float))
                }
                
                logger.info("=" * 60)
                logger.info("è®­ç»ƒå®Œæˆ")
                logger.info(f"MLflow Run ID: {run.info.run_id}")
                logger.info(f"æµ‹è¯•é›†æŒ‡æ ‡: {test_summary}")
                logger.info("=" * 60)
                
                return result
                
            except Exception as e:
                logger.error(f"è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
                mlflow.log_param("training_failed", True)
                raise

    def _load_data(self, dataset_path: str) -> Tuple[List[str], Optional[List[str]], Optional[List[str]]]:
        """åŠ è½½è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®
        
        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        1. ç›®å½•æ¨¡å¼ï¼šdataset_path ä¸ºç›®å½•
           - å¿…é¡»åŒ…å« train.txt
           - å¯é€‰ val.txt å’Œ test.txt
        2. æ–‡ä»¶æ¨¡å¼ï¼šdataset_path ä¸ºå•ä¸ªTXTæ–‡ä»¶
           - ä½œä¸ºè®­ç»ƒæ•°æ®
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆç›®å½•æˆ–æ–‡ä»¶ï¼‰
            
        Returns:
            å…ƒç»„ (train_logs, val_logs, test_logs)
        """
        import os
        from pathlib import Path
        
        logger.info("åŠ è½½æ•°æ®...")
        
        dataset_path = Path(dataset_path)
        
        if dataset_path.is_dir():
            # ç›®å½•æ¨¡å¼
            logger.info(f"ğŸ“ æ£€æµ‹åˆ°ç›®å½•æ¨¡å¼: {dataset_path}")
            
            train_file = dataset_path / "train_data.txt"
            if not train_file.exists():
                raise FileNotFoundError(
                    f"ç›®å½•æ¨¡å¼ä¸‹æœªæ‰¾åˆ°è®­ç»ƒæ–‡ä»¶: {train_file}\n"
                    f"ç›®å½•ä¸­å¿…é¡»åŒ…å« train_data.txt"
                )
            
            train_logs = self.data_loader.load_txt(str(train_file))
            logger.info(f"âœ“ è®­ç»ƒé›†: {len(train_logs)} æ¡æ—¥å¿— (train_data.txt)")
            
            # å¯é€‰çš„éªŒè¯é›†
            val_logs = None
            val_file = dataset_path / "val_data.txt"
            if val_file.exists():
                val_logs = self.data_loader.load_txt(str(val_file))
                logger.info(f"âœ“ éªŒè¯é›†: {len(val_logs)} æ¡æ—¥å¿— (val_data.txt)")
            else:
                logger.info("âš  æœªæ‰¾åˆ° val_data.txtï¼Œå°†è·³è¿‡éªŒè¯")
            
            # å¯é€‰çš„æµ‹è¯•é›†
            test_logs = None
            test_file = dataset_path / "test_data.txt"
            if test_file.exists():
                test_logs = self.data_loader.load_txt(str(test_file))
                logger.info(f"âœ“ æµ‹è¯•é›†: {len(test_logs)} æ¡æ—¥å¿— (test_data.txt)")
            else:
                logger.info("âš  æœªæ‰¾åˆ° test_data.txtï¼Œå°†ä½¿ç”¨è®­ç»ƒé›†è¿›è¡Œè¯„ä¼°")
            
            return train_logs, val_logs, test_logs
        
        elif dataset_path.is_file():
            # æ–‡ä»¶æ¨¡å¼ - å•ä¸ªæ–‡ä»¶ä½œä¸ºè®­ç»ƒæ•°æ®
            logger.info(f"ğŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶æ¨¡å¼: {dataset_path}")
            train_logs = self.data_loader.load_txt(str(dataset_path))
            logger.info(f"âœ“ åŠ è½½ {len(train_logs)} æ¡æ—¥å¿—ä»å•ä¸ªæ–‡ä»¶")
            
            return train_logs, None, None
        
        else:
            raise FileNotFoundError(f"æ•°æ®é›†è·¯å¾„æœªæ‰¾åˆ°: {dataset_path}")

    def _preprocess_data(
        self,
        train_logs: List[str],
        val_logs: Optional[List[str]],
        test_logs: Optional[List[str]]
    ) -> Tuple[List[str], Optional[List[str]], Optional[List[str]]]:
        """æ•°æ®é¢„å¤„ç†ï¼ˆè§£æ + æ¸…æ´—ï¼‰
        
        ä¸€æ¬¡æ€§åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶å¹¶å¤„ç†æ‰€æœ‰æ•°æ®é›†ã€‚
        
        Args:
            train_logs: è®­ç»ƒé›†åŸå§‹æ—¥å¿—
            val_logs: éªŒè¯é›†åŸå§‹æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
            test_logs: æµ‹è¯•é›†åŸå§‹æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            (train_logs_processed, val_logs_processed, test_logs_processed)
        """
        logger.info("æ•°æ®é¢„å¤„ç†ï¼ˆè§£æ + æ¸…æ´—ï¼‰...")
        
        # 1. åˆå§‹åŒ–ç»„ä»¶ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰
        self.log_parser = LogParser(log_format="<Content>")
        preprocessing_config = self.config.config.get("preprocessing", {})
        self.preprocessor = LogPreprocessor(preprocessing_config)
        
        logger.info(f"é¢„å¤„ç†é…ç½®: {preprocessing_config}")
        
        # 2. å¤„ç†è®­ç»ƒé›†
        train_logs_processed = self._preprocess_single(train_logs)
        logger.info(f"è®­ç»ƒé›†é¢„å¤„ç†å®Œæˆ: {len(train_logs_processed)} æ¡æ—¥å¿—")
        
        # 3. å¤„ç†éªŒè¯é›†
        val_logs_processed = None
        if val_logs:
            val_logs_processed = self._preprocess_single(val_logs)
            logger.info(f"éªŒè¯é›†é¢„å¤„ç†å®Œæˆ: {len(val_logs_processed)} æ¡æ—¥å¿—")
        
        # 4. å¤„ç†æµ‹è¯•é›†
        test_logs_processed = None
        if test_logs:
            test_logs_processed = self._preprocess_single(test_logs)
            logger.info(f"æµ‹è¯•é›†é¢„å¤„ç†å®Œæˆ: {len(test_logs_processed)} æ¡æ—¥å¿—")
        
        return train_logs_processed, val_logs_processed, test_logs_processed
    
    def _preprocess_single(self, logs: List[str]) -> List[str]:
        """å¤„ç†å•ä¸ªæ•°æ®é›†
        
        Args:
            logs: åŸå§‹æ—¥å¿—åˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„æ—¥å¿—åˆ—è¡¨
        """
        # è§£ææ—¥å¿—æå–å†…å®¹
        contents = self.log_parser.extract_content(logs)
        
        # åº”ç”¨é¢„å¤„ç†
        processed = self.preprocessor.preprocess(contents)
        
        return processed

    def _setup_mlflow(self):
        """è®¾ç½® MLflow å®éªŒ"""
        tracking_uri = self.config.mlflow_tracking_uri
        experiment_name = self.config.mlflow_experiment_name
        
        # ä½¿ç”¨ MLFlowUtils ç»Ÿä¸€è®¾ç½®
        MLFlowUtils.setup_experiment(tracking_uri, experiment_name)
    
    def _log_config(self):
        """è®°å½•é…ç½®åˆ° MLflow"""
        config_dict = self.config.to_dict()
        
        # å±•å¼€åµŒå¥—çš„é…ç½®
        flat_config = {}
        for key, value in config_dict.items():
            if isinstance(value, dict):
                for sub_key, sub_value in value.items():
                    flat_config[f"{key}.{sub_key}"] = sub_value
            else:
                flat_config[key] = value
        
        MLFlowUtils.log_params_batch(flat_config)
        logger.debug(f"é…ç½®å·²è®°å½•åˆ° MLflow")
    
    def _create_model(self):
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        logger.info(f"åˆ›å»ºæ¨¡å‹: {self.config.model_type}")

        # ä»search_spaceä¸­è·å–tauï¼ˆç¬¬ä¸€ä¸ªå€¼ï¼‰
        search_space = self.config.get("hyperparams", "search_space", default={})
        tau_values = search_space.get("tau", [0.5])
        tau = tau_values[0] if isinstance(tau_values, list) else tau_values
        
        # ä½¿ç”¨ **kwargs æ–¹å¼åˆ›å»ºæ¨¡å‹
        model = ModelRegistry.create_model(self.config.model_type, tau=tau)
        logger.info(f"æ¨¡å‹å·²åˆ›å»º: {model.__class__.__name__} (tau={tau})")

        return model
    
    def _optimize_hyperparams(
        self, 
        train_data: List[str], 
        val_data: List[str]
    ) -> Dict[str, Any]:
        """ç»Ÿä¸€çš„è¶…å‚æ•°ä¼˜åŒ–å…¥å£
        
        Args:
            train_data: è®­ç»ƒæ•°æ®
            val_data: éªŒè¯æ•°æ®
        
        Returns:
            æœ€ä¼˜è¶…å‚æ•°å­—å…¸ï¼Œå¦‚æœä¸æ”¯æŒæˆ–é…ç½®ä¸º0åˆ™è¿”å› {}
        """
        logger.info("æ£€æŸ¥è¶…å‚æ•°ä¼˜åŒ–é…ç½®...")
        
        # 1. æ£€æŸ¥é…ç½®
        max_evals = self.config.get("hyperparams", "max_evals", default=0)
        
        if max_evals == 0:
            logger.info("max_evals=0ï¼Œè·³è¿‡è¶…å‚æ•°ä¼˜åŒ–")
            return {}
        
        # 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒè¶…å‚æ•°ä¼˜åŒ–
        if not hasattr(self.model, 'optimize_hyperparams'):
            logger.warning(
                f"{self.config.model_type} æ¨¡å‹ä¸æ”¯æŒè¶…å‚æ•°ä¼˜åŒ–ï¼Œè·³è¿‡"
            )
            return {}
        
        # 3. æ‰§è¡Œä¼˜åŒ–
        logger.info(f"å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–: max_evals={max_evals}")
        try:
            best_params = self.model.optimize_hyperparams(
                train_data=train_data,
                val_data=val_data,
                config=self.config
            )
            logger.info(f"è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ: {best_params}")
            return best_params
        except Exception as e:
            logger.error(f"è¶…å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}", exc_info=True)
            return {}
    
    def _train_model(self, train_data: List[str], val_data: Optional[List[str]]):
        """è®­ç»ƒæ¨¡å‹
        
        Args:
            train_data: è®­ç»ƒæ•°æ®
            val_data: éªŒè¯æ•°æ®ï¼ˆå¯é€‰ï¼‰
        """
        logger.info("è®­ç»ƒæ¨¡å‹...")
        
        # å°†é¢„å¤„ç†å™¨é™„åŠ åˆ°æ¨¡å‹ï¼ˆç”¨äºæ¨ç†æ—¶ä½¿ç”¨ï¼‰
        if self.preprocessor:
            self.model.preprocessor = self.preprocessor
            logger.info("âœ“ é¢„å¤„ç†å™¨å·²é™„åŠ åˆ°æ¨¡å‹")
        else:
            logger.warning("âš  æœªæ‰¾åˆ°é¢„å¤„ç†å™¨ï¼Œæ¨ç†æ—¶å¯èƒ½éœ€è¦æ‰‹åŠ¨é¢„å¤„ç†")
        
        # å¦‚æœæœ‰éªŒè¯é›†ï¼Œåˆå¹¶åè®­ç»ƒ
        if val_data:
            final_train_data = train_data + val_data
            logger.info(f"åˆå¹¶è®­ç»ƒé›†å’ŒéªŒè¯é›†: {len(final_train_data)} æ¡æ—¥å¿—")
            self.model.fit(final_train_data, verbose=True, log_to_mlflow=True)
        else:
            self.model.fit(train_data, verbose=True, log_to_mlflow=True)
        
        logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆ")

    def _save_model_to_mlflow(self) -> str:
        """ä¿å­˜æ¨¡å‹åˆ° MLflow
        
        Returns:
            æ¨¡å‹ URI
        """
        logger.info("ä¿å­˜æ¨¡å‹åˆ° MLflow...")
        
        model_type = self.config.model_type
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰ save_mlflow æ–¹æ³•
        if hasattr(self.model, 'save_mlflow') and callable(getattr(self.model, 'save_mlflow')):
            try:
                self.model.save_mlflow(artifact_path="model")
                logger.info(f"{model_type} æ¨¡å‹å·²ä¿å­˜")
            except Exception as e:
                logger.error(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
                raise
        else:
            logger.warning(f"{model_type} æ¨¡å‹ä¸æ”¯æŒ save_mlflow æ–¹æ³•")
        
        # è¿”å›æ¨¡å‹ URI
        run = mlflow.active_run()
        model_uri = f"runs:/{run.info.run_id}/model"
        
        return model_uri

    def _generate_run_name(self):
        """ç”ŸæˆåŸºäºæ¨¡å‹ç±»å‹å’Œæ—¶é—´æˆ³çš„ run åç§°ã€‚"""
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{self.config.model_type}_{timestamp}"
    
    def _log_data_info(
        self, 
        train_logs: List[str], 
        val_logs: Optional[List[str]], 
        test_logs: Optional[List[str]]
    ):
        """è®°å½•æ•°æ®é›†ä¿¡æ¯åˆ° MLflow
        
        Args:
            train_logs: è®­ç»ƒé›†æ—¥å¿—
            val_logs: éªŒè¯é›†æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
            test_logs: æµ‹è¯•é›†æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
        """
        # æ•°æ®åŸºæœ¬ä¿¡æ¯
        params = {
            "train_logs_count": len(train_logs),
        }
        
        if val_logs:
            params["val_logs_count"] = len(val_logs)
        
        if test_logs:
            params["test_logs_count"] = len(test_logs)
        
        # æ‰¹é‡è®°å½•å‚æ•°
        MLFlowUtils.log_params_batch(params)
        logger.debug(f"æ•°æ®ä¿¡æ¯å·²è®°å½•åˆ° MLflow: {params}")
