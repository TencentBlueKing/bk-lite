"""YOLOç›®æ ‡æ£€æµ‹æ¨¡å‹å°è£…."""

from typing import Dict, Any, Optional, List
from pathlib import Path
import mlflow
from loguru import logger
from ultralytics import YOLO, settings
import uuid
import time
import logging

from classify_object_detection_server import PROJECT_ROOT
from .base import BaseObjectDetectionModel, ModelRegistry

# ç¦ç”¨YOLOçš„MLflowè‡ªåŠ¨é›†æˆï¼Œé¿å…ä¸è‡ªå®šä¹‰MLflowç®¡ç†å†²çª
settings.update({"mlflow": False})

# ç¦ç”¨YOLOçš„è¯¦ç»†æ—¥å¿—è¾“å‡º
logging.getLogger("ultralytics").setLevel(logging.WARNING)

logger.info("å·²ç¦ç”¨YOLOçš„MLflowè‡ªåŠ¨é›†æˆå’Œè¯¦ç»†æ—¥å¿—")


@ModelRegistry.register("YOLODetection")
class YOLODetectionModel(BaseObjectDetectionModel):
    """YOLOç›®æ ‡æ£€æµ‹æ¨¡å‹.

    å°è£…ultralytics YOLOæ£€æµ‹æ¨¡å‹ï¼Œå®ç°ç»Ÿä¸€çš„è®­ç»ƒå’Œæ¨ç†æ¥å£ã€‚
    """

    def __init__(self, model_name: str = "yolo11n.pt", **hyperparams):
        """
        åˆå§‹åŒ–YOLOæ£€æµ‹æ¨¡å‹.

        Args:
            model_name: YOLOæ¨¡å‹åç§°ï¼ˆå¦‚ 'yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt' ç­‰ï¼‰
            **hyperparams: å…¶ä»–è¶…å‚æ•°
        """
        self.model_name = model_name
        self.hyperparams = hyperparams
        self.yolo = None
        self.class_names = None
        self._results = None

        logger.info(f"YOLODetectionModelåˆå§‹åŒ–: {self.model_name}")

    def _get_param_value(self, param_name: str, default_value):
        """
        æ™ºèƒ½è·å–å‚æ•°å€¼ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç©ºé—´ä¸­çš„é»˜è®¤å€¼ï¼Œå…¶æ¬¡ä½¿ç”¨å›ºå®šå€¼ï¼Œæœ€åä½¿ç”¨ä»£ç é»˜è®¤å€¼.

        å¦‚æœå‚æ•°åœ¨ search_space ä¸­å®šä¹‰ï¼Œåˆ™ä½¿ç”¨æœç´¢ç©ºé—´çš„ç¬¬ä¸€ä¸ªå€¼ä½œä¸ºé»˜è®¤å€¼ï¼Œ
        å¿½ç•¥ hyperparams ä¸­çš„å›ºå®šå€¼ï¼Œé¿å…é…ç½®æ··æ·†ã€‚

        Args:
            param_name: å‚æ•°åç§°
            default_value: ä»£ç ä¸­çš„é»˜è®¤å€¼ï¼ˆæœ€ç»ˆå›é€€å€¼ï¼‰

        Returns:
            å‚æ•°å€¼
        """
        search_space = self.hyperparams.get("search_space", {})

        # å¦‚æœå‚æ•°åœ¨æœç´¢ç©ºé—´ä¸­å®šä¹‰ï¼Œä½¿ç”¨æœç´¢ç©ºé—´çš„ç¬¬ä¸€ä¸ªå€¼
        if param_name in search_space:
            space_config = search_space[param_name]
            if isinstance(space_config, list) and len(space_config) > 0:
                # æœç´¢ç©ºé—´æ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå€¼ä½œä¸ºé»˜è®¤å€¼
                return space_config[0]
            elif isinstance(space_config, dict):
                # æœç´¢ç©ºé—´æ˜¯å­—å…¸é…ç½®
                if space_config.get("type") == "choice":
                    options = space_config.get("options", [])
                    if options:
                        return options[0]
                # å…¶ä»–ç±»å‹ï¼ˆuniform, loguniformç­‰ï¼‰ä½¿ç”¨ low ä½œä¸ºé»˜è®¤å€¼
                return space_config.get("low", default_value)

        # å¦åˆ™ä½¿ç”¨ hyperparams ä¸­çš„å›ºå®šå€¼
        return self.hyperparams.get(param_name, default_value)

    def fit(
        self,
        dataset_yaml: str,
        val_data: Optional[str] = None,
        device: str = "auto",
        log_artifacts: bool = True,
        **kwargs,
    ) -> "YOLODetectionModel":
        """
        è®­ç»ƒYOLOæ£€æµ‹æ¨¡å‹.

        Args:
            dataset_yaml: YOLOæ ¼å¼æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆdata.yaml æˆ– dataset.yamlï¼‰
            val_data: éªŒè¯é›†é…ç½®ï¼ˆå¯é€‰ï¼Œé€šå¸¸å·²åŒ…å«åœ¨dataset_yamlä¸­ï¼‰
            device: è®¾å¤‡é…ç½®
            log_artifacts: æ˜¯å¦ä¸Šä¼ è®­ç»ƒäº§ç”Ÿçš„artifactsåˆ°MLflowï¼Œé»˜è®¤True
            **kwargs: é¢å¤–è®­ç»ƒå‚æ•°

        Returns:
            self
        """
        logger.info(f"å¼€å§‹è®­ç»ƒYOLOæ£€æµ‹æ¨¡å‹ï¼Œè®¾å¤‡: {device}")
        logger.info(f"æ•°æ®é›†é…ç½®: {dataset_yaml}")

        # åˆå§‹åŒ–YOLOæ£€æµ‹æ¨¡å‹
        self.yolo = YOLO(self.model_name)

        # æ„å»ºè®­ç»ƒå‚æ•°
        train_kwargs = {
            "data": dataset_yaml,
            "epochs": self.hyperparams.get("epochs", 100),
            "imgsz": self._get_param_value("imgsz", 640),
            "batch": self._get_param_value("batch", 16),
            "lr0": self._get_param_value("lr0", 0.01),
            "lrf": self.hyperparams.get("lrf", 0.01),
            "momentum": self.hyperparams.get("momentum", 0.937),
            "weight_decay": self.hyperparams.get("weight_decay", 0.0005),
            "warmup_epochs": self.hyperparams.get("warmup_epochs", 3.0),
            "optimizer": self.hyperparams.get("optimizer", "SGD"),
            "amp": self.hyperparams.get("amp", True),
            "patience": self.hyperparams.get("patience", 50),
            "device": device,
            "project": PROJECT_ROOT / ".yolo_runs" / "detection_training",
            "name": f"train_{int(time.time())}_{uuid.uuid4().hex[:8]}",
            "save": True,
            "plots": True,
            "verbose": False,
        }

        # æ·»åŠ æ•°æ®å¢å¼ºå‚æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.hyperparams.get("augment") is False:
            train_kwargs["augment"] = False
        else:
            # å‡ ä½•å˜æ¢å‚æ•°
            for aug_param in [
                "degrees",
                "translate",
                "scale",
                "shear",
                "perspective",
                "fliplr",
                "flipud",
            ]:
                if aug_param in self.hyperparams:
                    train_kwargs[aug_param] = self.hyperparams[aug_param]

            # é¢œè‰²å¢å¼ºå‚æ•°
            for aug_param in ["hsv_h", "hsv_s", "hsv_v"]:
                if aug_param in self.hyperparams:
                    train_kwargs[aug_param] = self.hyperparams[aug_param]

            # æ£€æµ‹ä¸“ç”¨é«˜çº§å¢å¼º
            for aug_param in ["mosaic", "mixup", "copy_paste"]:
                if aug_param in self.hyperparams:
                    train_kwargs[aug_param] = self.hyperparams[aug_param]

        if device != "cpu" and self.hyperparams.get("amp", True):
            train_kwargs["amp"] = True
            logger.info("âš¡ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰")

        # ç¦ç”¨YOLOçš„è¯¦ç»†è¾“å‡º(æ¨¡å‹æ¶æ„ç­‰)
        # train_kwargs["verbose"] = False

        # æ‰§è¡Œè®­ç»ƒ
        logger.info(
            f"ğŸš€ å¼€å§‹è®­ç»ƒ - epochs={train_kwargs['epochs']}, batch={train_kwargs['batch']}, imgsz={train_kwargs['imgsz']}"
        )
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {train_kwargs['project']}/{train_kwargs['name']}")

        train_start_time = time.time()
        results = self.yolo.train(**train_kwargs)
        train_duration = time.time() - train_start_time

        self._results = results

        # è®°å½•è®­ç»ƒç»“æœ - å¢å¼ºæ—¥å¿—è¾“å‡º
        logger.info("=" * 70)
        logger.info(f"âœ“ è®­ç»ƒå®Œæˆ - è€—æ—¶: {train_duration / 60:.1f}åˆ†é’Ÿ")
        logger.info("=" * 70)

        # 1. å°è¯•ä» results_dict è·å–æŒ‡æ ‡
        try:
            if hasattr(results, "results_dict") and results.results_dict:
                results_dict = results.results_dict

                # è®­ç»ƒé›†æŸå¤±
                box_loss = results_dict.get("train/box_loss")
                cls_loss = results_dict.get("train/cls_loss")
                dfl_loss = results_dict.get("train/dfl_loss")

                if box_loss is not None:
                    logger.info("ğŸ“Š æœ€ç»ˆè®­ç»ƒæŸå¤±:")
                    logger.info(f"   Box Loss (å®šä½æŸå¤±):     {box_loss:.4f}")
                    if cls_loss is not None:
                        logger.info(f"   Class Loss (åˆ†ç±»æŸå¤±):   {cls_loss:.4f}")
                    if dfl_loss is not None:
                        logger.info(f"   DFL Loss (åˆ†å¸ƒæŸå¤±):     {dfl_loss:.4f}")

                # éªŒè¯é›†æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
                val_map = results_dict.get("metrics/mAP50(B)")
                val_map50_95 = results_dict.get("metrics/mAP50-95(B)")

                if val_map is not None or val_map50_95 is not None:
                    logger.info("")
                    logger.info("ğŸ“ˆ éªŒè¯é›†æ€§èƒ½æŒ‡æ ‡:")
                    if val_map50_95 is not None:
                        logger.info(
                            f"   mAP@0.5:0.95:  {val_map50_95:.4f}  â­ (ä¸»è¦æŒ‡æ ‡)"
                        )
                    if val_map is not None:
                        logger.info(f"   mAP@0.5:       {val_map:.4f}")

                    precision = results_dict.get("metrics/precision(B)")
                    recall = results_dict.get("metrics/recall(B)")
                    if precision is not None:
                        logger.info(f"   Precision:     {precision:.4f}")
                    if recall is not None:
                        logger.info(f"   Recall:        {recall:.4f}")

        except Exception as e:
            logger.debug(f"ä» results_dict è·å–æŒ‡æ ‡å¤±è´¥: {e}")

        # 2. å°è¯•ä» results å¯¹è±¡ç›´æ¥è·å–æŒ‡æ ‡
        try:
            if hasattr(results, "box"):
                logger.info("")
                logger.info("ğŸ“ˆ æœ€ä½³éªŒè¯é›†æ€§èƒ½ (è®­ç»ƒæœŸé—´):")
                logger.info(f"   mAP@0.5:0.95:  {float(results.box.map):.4f}  â­")
                logger.info(f"   mAP@0.5:       {float(results.box.map50):.4f}")
                logger.info(f"   Precision:     {float(results.box.mp):.4f}")
                logger.info(f"   Recall:        {float(results.box.mr):.4f}")
        except Exception as e:
            logger.debug(f"ä» results.box è·å–æŒ‡æ ‡å¤±è´¥: {e}")

        # 3. è®°å½•è®­ç»ƒå‚æ•°æ‘˜è¦
        logger.info("")
        logger.info("âš™ï¸  è®­ç»ƒé…ç½®:")
        logger.info(f"   Epochs:        {train_kwargs['epochs']}")
        logger.info(f"   Batch Size:    {train_kwargs['batch']}")
        logger.info(f"   Image Size:    {train_kwargs['imgsz']}")
        logger.info(f"   Learning Rate: {train_kwargs['lr0']}")
        logger.info(f"   Optimizer:     {train_kwargs['optimizer']}")
        logger.info(f"   Patience:      {train_kwargs['patience']}")

        logger.info("=" * 70)

        # æ‰‹åŠ¨ä¸Šä¼ YOLOè®­ç»ƒäº§ç”Ÿçš„artifactsåˆ°MLflow
        if log_artifacts:
            self._log_yolo_artifacts_to_mlflow(train_kwargs)
        else:
            # è¶…å‚æ•°ä¼˜åŒ–æ—¶ä¹Ÿè¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_yolo_output(train_kwargs)

        return self

    def predict(self, X: Any) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡é¢„æµ‹.

        Args:
            X: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ã€PIL Imageåˆ—è¡¨æˆ–numpyæ•°ç»„

        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ ¼å¼:
            {
                'boxes': [[x1, y1, x2, y2], ...],  # å½’ä¸€åŒ–åæ ‡
                'classes': [class_id, ...],
                'confidences': [conf, ...],
                'labels': [label_name, ...]
            }
        """
        if self.yolo is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()æ–¹æ³•")

        results = self.yolo.predict(
            X,
            imgsz=self.hyperparams.get("imgsz", 640),
            conf=self.hyperparams.get("conf", 0.25),
            iou=self.hyperparams.get("iou", 0.45),
            verbose=False,
        )

        # è§£æé¢„æµ‹ç»“æœ
        predictions = []
        for result in results:
            if result.boxes is None or len(result.boxes) == 0:
                predictions.append(
                    {"boxes": [], "classes": [], "confidences": [], "labels": []}
                )
                continue

            boxes = (
                result.boxes.xyxyn.cpu().numpy().tolist()
            )  # å½’ä¸€åŒ–åæ ‡ [x1, y1, x2, y2]
            classes = result.boxes.cls.cpu().numpy().astype(int).tolist()
            confidences = result.boxes.conf.cpu().numpy().tolist()
            labels = [result.names[cls_id] for cls_id in classes]

            predictions.append(
                {
                    "boxes": boxes,
                    "classes": classes,
                    "confidences": confidences,
                    "labels": labels,
                }
            )

        return predictions

    def evaluate(
        self, test_data: str, prefix: str = "test", log_artifacts: bool = False
    ) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½.

        Args:
            test_data: æµ‹è¯•æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆYOLOæ ¼å¼ï¼‰
            prefix: æŒ‡æ ‡å‰ç¼€
            log_artifacts: æ˜¯å¦ä¸Šä¼ è¯„ä¼°äº§ç”Ÿçš„artifactsåˆ°MLflowï¼Œé»˜è®¤False

        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸ï¼ŒåŒ…å«mAPã€precisionã€recallç­‰
        """
        if self.yolo is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒ")

        logger.info(f"åœ¨{prefix}é›†ä¸Šè¯„ä¼°æ¨¡å‹: {test_data}")

        eval_kwargs = {
            "data": test_data,
            "split": prefix,
            "verbose": False,
            "save_json": True,  # ä¿å­˜COCOæ ¼å¼çš„ç»“æœ
            "save": True,
            "plots": True,
            "project": PROJECT_ROOT / ".yolo_runs" / "detection_validation",
            "name": f"eval_{prefix}_{int(time.time())}_{uuid.uuid4().hex[:8]}",
        }

        metrics = self.yolo.val(**eval_kwargs)

        # æå–æ£€æµ‹æŒ‡æ ‡
        eval_results = {
            f"{prefix}_map50": float(metrics.box.map50),  # mAP@0.5
            f"{prefix}_map": float(metrics.box.map),  # mAP@0.5:0.95
            f"{prefix}_precision": float(metrics.box.mp),  # mean precision
            f"{prefix}_recall": float(metrics.box.mr),  # mean recall
        }

        # å¯é€‰ï¼šè®°å½•æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡ï¼ˆä¸ä¸Šä¼ åˆ°MLflowï¼‰
        if hasattr(metrics.box, "ap_class_index") and hasattr(metrics.box, "ap"):
            eval_results["_per_class_metrics"] = {
                "class_indices": metrics.box.ap_class_index.tolist(),
                "ap_per_class": metrics.box.ap.tolist(),
            }

        logger.info(
            f"è¯„ä¼°å®Œæˆ: mAP50={eval_results[f'{prefix}_map50']:.4f}, "
            f"mAP={eval_results[f'{prefix}_map']:.4f}, "
            f"precision={eval_results[f'{prefix}_precision']:.4f}, "
            f"recall={eval_results[f'{prefix}_recall']:.4f}"
        )

        if log_artifacts:
            self._log_yolo_eval_artifacts_to_mlflow(eval_kwargs, prefix)
        else:
            self._cleanup_yolo_output(eval_kwargs)

        return eval_results

    def _log_yolo_artifacts_to_mlflow(self, train_kwargs: Dict[str, Any]):
        """
        æ‰‹åŠ¨ä¸Šä¼ YOLOè®­ç»ƒäº§ç”Ÿçš„artifactsåˆ°MLflow.

        Args:
            train_kwargs: è®­ç»ƒå‚æ•°ï¼ŒåŒ…å«projectå’Œname
        """
        import shutil

        save_dir = Path(train_kwargs["project"]) / train_kwargs["name"]

        if not save_dir.exists():
            logger.warning(f"YOLOè¾“å‡ºç›®å½•ä¸å­˜åœ¨: {save_dir}")
            return

        logger.info(f"å¼€å§‹ä¸Šä¼ YOLOè®­ç»ƒartifactsåˆ°MLflow: {save_dir}")

        try:
            # ä¸Šä¼ æƒé‡æ–‡ä»¶
            weights_dir = save_dir / "weights"
            if weights_dir.exists():
                logger.info("ä¸Šä¼ æ¨¡å‹æƒé‡...")
                mlflow.log_artifacts(str(weights_dir), artifact_path="weights")

            # ä¸Šä¼ è®­ç»ƒç»“æœæ–‡ä»¶
            files_to_upload = [
                "args.yaml",  # è®­ç»ƒå‚æ•°
                "results.csv",  # è®­ç»ƒæŒ‡æ ‡
                "results.png",  # è®­ç»ƒæ›²çº¿
                "confusion_matrix.png",  # æ··æ·†çŸ©é˜µ
                "confusion_matrix_normalized.png",
            ]

            for filename in files_to_upload:
                file_path = save_dir / filename
                if file_path.exists():
                    logger.debug(f"ä¸Šä¼ æ–‡ä»¶: {filename}")
                    mlflow.log_artifact(str(file_path))

            # ä¸Šä¼ è®­ç»ƒè¿‡ç¨‹çš„å¯è§†åŒ–å›¾ç‰‡
            for img_file in save_dir.glob("*.jpg"):
                logger.debug(f"ä¸Šä¼ å›¾ç‰‡: {img_file.name}")
                mlflow.log_artifact(str(img_file))

            for img_file in save_dir.glob("*.png"):
                if img_file.name not in files_to_upload:
                    logger.debug(f"ä¸Šä¼ å›¾ç‰‡: {img_file.name}")
                    mlflow.log_artifact(str(img_file))

            logger.info("âœ“ YOLOè®­ç»ƒartifactsä¸Šä¼ å®Œæˆ")

            # æ¸…ç†è¾“å‡ºç›®å½•
            self._cleanup_yolo_output(train_kwargs)

        except Exception as e:
            logger.error(f"ä¸Šä¼ artifactsåˆ°MLflowå¤±è´¥: {e}")

    def _log_yolo_eval_artifacts_to_mlflow(
        self, eval_kwargs: Dict[str, Any], prefix: str = "test"
    ):
        """
        æ‰‹åŠ¨ä¸Šä¼ YOLOè¯„ä¼°äº§ç”Ÿçš„artifactsåˆ°MLflow.

        Args:
            eval_kwargs: è¯„ä¼°å‚æ•°
            prefix: è¯„ä¼°å‰ç¼€
        """
        import shutil

        save_dir = Path(eval_kwargs["project"]) / eval_kwargs["name"]

        if not save_dir.exists():
            logger.warning(f"YOLOè¯„ä¼°è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {save_dir}")
            return

        logger.info(f"å¼€å§‹ä¸Šä¼ YOLOè¯„ä¼°artifactsåˆ°MLflow: {save_dir}")

        try:
            artifact_path = f"{prefix}_evaluation"

            files_to_upload = [
                "confusion_matrix.png",
                "confusion_matrix_normalized.png",
                "PR_curve.png",  # Precision-Recallæ›²çº¿
                "F1_curve.png",  # F1æ›²çº¿
            ]

            for filename in files_to_upload:
                file_path = save_dir / filename
                if file_path.exists():
                    logger.debug(f"ä¸Šä¼ æ–‡ä»¶: {filename}")
                    mlflow.log_artifact(str(file_path), artifact_path=artifact_path)

            # ä¸Šä¼ é¢„æµ‹æ ·ä¾‹å›¾ç‰‡
            for img_file in save_dir.glob("*.jpg"):
                logger.debug(f"ä¸Šä¼ å›¾ç‰‡: {img_file.name}")
                mlflow.log_artifact(str(img_file), artifact_path=artifact_path)

            for img_file in save_dir.glob("*.png"):
                if img_file.name not in files_to_upload:
                    logger.debug(f"ä¸Šä¼ å›¾ç‰‡: {img_file.name}")
                    mlflow.log_artifact(str(img_file), artifact_path=artifact_path)

            logger.info(f"âœ“ YOLOè¯„ä¼°artifactsä¸Šä¼ å®Œæˆï¼ˆç›®å½•: {artifact_path}ï¼‰")

            self._cleanup_yolo_output(eval_kwargs)

        except Exception as e:
            logger.error(f"ä¸Šä¼ è¯„ä¼°artifactsåˆ°MLflowå¤±è´¥: {e}")

    def _cleanup_yolo_output(self, train_kwargs: Dict[str, Any]):
        """æ¸…ç†YOLOè®­ç»ƒ/è¯„ä¼°è¾“å‡ºç›®å½•."""
        import shutil

        save_dir = Path(train_kwargs["project"]) / train_kwargs["name"]

        if save_dir.exists():
            logger.debug(f"æ¸…ç†YOLOè¾“å‡ºç›®å½•: {save_dir}")
            try:
                shutil.rmtree(save_dir, ignore_errors=True)
                logger.debug("âœ“ è¾“å‡ºç›®å½•å·²æ¸…ç†")
            except Exception as e:
                logger.warning(f"æ¸…ç†è¾“å‡ºç›®å½•å¤±è´¥: {e}")

    def optimize_hyperparams(
        self, train_data: str, val_data: str, max_evals: int
    ) -> Dict[str, Any]:
        """
        è¶…å‚æ•°ä¼˜åŒ–ï¼ˆä½¿ç”¨Hyperoptï¼‰.

        Args:
            train_data: è®­ç»ƒæ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
            val_data: éªŒè¯æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
            max_evals: æœ€å¤§è¯„ä¼°æ¬¡æ•°

        Returns:
            æœ€ä¼˜è¶…å‚æ•°å­—å…¸
        """
        from hyperopt import hp, fmin, tpe, Trials
        import numpy as np

        if max_evals <= 0:
            logger.info("è·³è¿‡è¶…å‚æ•°ä¼˜åŒ–ï¼ˆmax_evals=0ï¼‰")
            return {}

        logger.info(f"ğŸ” å¼€å§‹è¶…å‚æ•°ä¼˜åŒ– - æœ€å¤§è¯„ä¼°æ¬¡æ•°: {max_evals}")

        search_space_config = self.hyperparams.get("search_space", {})
        space = self._build_search_space(search_space_config)
        device = self.hyperparams.get("_device", "auto")

        early_stopping_config = self.hyperparams.get("early_stopping", {})
        early_stop_enabled = early_stopping_config.get("enabled", True)
        patience = early_stopping_config.get("patience", 10)

        if early_stop_enabled:
            logger.info(f"æ—©åœæœºåˆ¶: å¯ç”¨ (patience={patience})")

        optimization_start = time.time()
        trial_count = [0]
        best_score = [float("inf")]

        def objective(params):
            """ä¼˜åŒ–ç›®æ ‡å‡½æ•°."""
            temp_model = None
            try:
                trial_count[0] += 1
                logger.info(f"  Trial {trial_count[0]}/{max_evals} - å‚æ•°: {params}")

                temp_hyperparams = {**self.hyperparams, **params}
                # trialä½¿ç”¨è¾ƒå°‘çš„epochsè¿›è¡Œå¿«é€Ÿè¯„ä¼°
                trial_epochs = max(10, self.hyperparams.get("epochs", 100) // 10)
                temp_hyperparams["epochs"] = trial_epochs
                temp_hyperparams["patience"] = 5
                temp_hyperparams["_device"] = device

                logger.info(f"  Trial {trial_count[0]} ä½¿ç”¨ {trial_epochs} epochs")

                temp_model = YOLODetectionModel(
                    model_name=self.model_name, **temp_hyperparams
                )

                temp_model.fit(train_data, val_data, device=device, log_artifacts=False)

                # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
                val_metrics = temp_model.evaluate(val_data, prefix="val")
                # ä½¿ç”¨mAP@0.5:0.95ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼ˆå–è´Ÿæ•°ç”¨äºæœ€å°åŒ–ï¼‰
                score = -val_metrics["val_map"]

                # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä¼˜ç»“æœ
                is_best = score < best_score[0]
                best_indicator = " ğŸ¯ NEW BEST!" if is_best else ""

                logger.info(
                    f"  Trial {trial_count[0]} ç»“æœ{best_indicator}: "
                    f"mAP@0.5:0.95={val_metrics['val_map']:.4f}, "
                    f"mAP@0.5={val_metrics['val_map50']:.4f}, "
                    f"precision={val_metrics['val_precision']:.4f}, "
                    f"recall={val_metrics['val_recall']:.4f}"
                )

                if mlflow.active_run():
                    mlflow.log_metric(
                        f"hyperopt/val_map", val_metrics["val_map"], step=trial_count[0]
                    )
                    mlflow.log_metric(
                        f"hyperopt/val_map50",
                        val_metrics["val_map50"],
                        step=trial_count[0],
                    )
                    mlflow.log_metric(
                        f"hyperopt/val_precision",
                        val_metrics["val_precision"],
                        step=trial_count[0],
                    )
                    mlflow.log_metric(
                        f"hyperopt/val_recall",
                        val_metrics["val_recall"],
                        step=trial_count[0],
                    )

                    for k, v in params.items():
                        mlflow.log_param(f"trial_{trial_count[0]}_{k}", str(v))

                    if score < best_score[0]:
                        best_score[0] = score
                        mlflow.log_metric(
                            "hyperopt/best_map", -best_score[0], step=trial_count[0]
                        )

                return score

            except Exception as e:
                logger.error(f"  Trial {trial_count[0]} å¤±è´¥: {type(e).__name__}: {e}")
                import traceback

                logger.debug(f"å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
                return 1.0

            finally:
                if temp_model is not None:
                    if hasattr(temp_model, "yolo") and temp_model.yolo is not None:
                        del temp_model.yolo
                    del temp_model

                # Force garbage collection for both CPU and GPU
                import gc

                gc.collect()

                # Clear CUDA cache if available
                if device != "cpu":
                    import torch

                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()

        # æ‰§è¡Œä¼˜åŒ–
        from hyperopt.early_stop import no_progress_loss

        trials = Trials()
        early_stop_fn = no_progress_loss(patience) if early_stop_enabled else None

        best_params = fmin(
            objective,
            space,
            algo=tpe.suggest,
            max_evals=max_evals,
            trials=trials,
            early_stop_fn=early_stop_fn,
            show_progressbar=False,
        )

        best_params = self._decode_hyperopt_params(best_params, search_space_config)

        optimization_duration = time.time() - optimization_start
        actual_evals = len(trials.trials)
        is_early_stopped = actual_evals < max_evals

        # å¢å¼ºçš„è¶…å‚æ•°ä¼˜åŒ–æ€»ç»“æ—¥å¿—
        logger.info("")
        logger.info("=" * 70)
        logger.info("âœ“ è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ")
        logger.info("=" * 70)
        logger.info(f"â±ï¸  æ€»è€—æ—¶: {optimization_duration / 60:.1f} åˆ†é’Ÿ")
        logger.info(f"ğŸ”¢ Trial è¯„ä¼°:")
        logger.info(f"   è®¡åˆ’: {max_evals} æ¬¡")
        logger.info(f"   å®é™…: {actual_evals} æ¬¡")
        if is_early_stopped:
            logger.info(f"   çŠ¶æ€: âš ï¸  æ—©åœè§¦å‘ (patience={patience})")
        else:
            logger.info(f"   çŠ¶æ€: âœ“ å®Œæ•´è¿è¡Œ")

        logger.info("")
        logger.info(f"ğŸ† æœ€ä¼˜ç»“æœ:")
        logger.info(f"   mAP@0.5:0.95: {-trials.best_trial['result']['loss']:.4f}")

        logger.info("")
        logger.info(f"ğŸ¯ æœ€ä¼˜è¶…å‚æ•°:")
        for key, value in best_params.items():
            logger.info(f"   {key:15s}: {value}")

        logger.info("=" * 70)

        if mlflow.active_run():
            success_trials = [
                t
                for t in trials.trials
                if t["result"]["status"] == "ok" and t["result"]["loss"] != 1.0
            ]
            failed_trials = [
                t
                for t in trials.trials
                if t["result"]["status"] != "ok" or t["result"]["loss"] == 1.0
            ]

            mlflow.log_metrics(
                {
                    "hyperopt_summary/total_evals": max_evals,
                    "hyperopt_summary/actual_evals": actual_evals,
                    "hyperopt_summary/successful_evals": len(success_trials),
                    "hyperopt_summary/failed_evals": len(failed_trials),
                    "hyperopt_summary/best_map": -best_score[0],
                    "hyperopt_summary/optimization_duration_min": optimization_duration
                    / 60,
                }
            )

            if early_stop_enabled:
                mlflow.log_metrics(
                    {
                        "hyperopt_summary/early_stop_enabled": 1.0,
                        "hyperopt_summary/early_stopped": 1.0
                        if is_early_stopped
                        else 0.0,
                        "hyperopt_summary/patience": patience,
                    }
                )

        # å°†numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
        import numpy as np

        converted_params = {}
        for key, value in best_params.items():
            if isinstance(value, np.integer):
                converted_params[key] = int(value)
            elif isinstance(value, np.floating):
                converted_params[key] = float(value)
            elif isinstance(value, np.ndarray):
                converted_params[key] = value.tolist()
            else:
                converted_params[key] = value

        # æ›´æ–°æ¨¡å‹è¶…å‚æ•°
        self.hyperparams.update(converted_params)

        return converted_params

    def _build_search_space(
        self, search_space_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ ¹æ®é…ç½®æ„å»ºHyperoptæœç´¢ç©ºé—´."""
        from hyperopt import hp
        import numpy as np

        if not search_space_config:
            # ä½¿ç”¨é»˜è®¤æœç´¢ç©ºé—´ï¼ˆæ£€æµ‹ä»»åŠ¡å¸¸ç”¨å‚æ•°ï¼‰
            logger.info("æœªå®šä¹‰æœç´¢ç©ºé—´ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {
                "lr0": hp.choice("lr0", [0.001, 0.01, 0.05]),
                "batch": hp.choice("batch", [8, 16, 32]),
                "imgsz": hp.choice("imgsz", [416, 512, 640]),
            }

        # ä»é…ç½®æ„å»ºæœç´¢ç©ºé—´
        space = {}

        for param_name, param_values in search_space_config.items():
            if isinstance(param_values, list) and len(param_values) > 0:
                space[param_name] = hp.choice(param_name, param_values)
            elif isinstance(param_values, dict):
                param_type = param_values.get("type", "uniform")

                if param_type == "loguniform":
                    low = param_values.get("low", 0.0001)
                    high = param_values.get("high", 0.1)
                    space[param_name] = hp.loguniform(
                        param_name, np.log(low), np.log(high)
                    )
                elif param_type == "uniform":
                    low = param_values.get("low", 0.0)
                    high = param_values.get("high", 1.0)
                    space[param_name] = hp.uniform(param_name, low, high)
                elif param_type == "quniform":
                    low = param_values.get("low", 0.0)
                    high = param_values.get("high", 1.0)
                    q = param_values.get("q", 1.0)
                    space[param_name] = hp.quniform(param_name, low, high, q)
                elif param_type == "choice":
                    options = param_values.get("options", [])
                    if options:
                        space[param_name] = hp.choice(param_name, options)

        logger.info(f"æœç´¢ç©ºé—´å‚æ•°: {list(space.keys())}")
        return space

    def _decode_hyperopt_params(
        self, params: Dict[str, Any], search_space_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è§£ç Hyperoptè¿”å›çš„å‚æ•°."""
        default_space = {
            "lr0": [0.001, 0.01, 0.05],
            "batch": [8, 16, 32],
            "imgsz": [416, 512, 640],
        }

        import numpy as np

        decoded = {}

        for param_name, value in params.items():
            param_config = search_space_config.get(param_name) or default_space.get(
                param_name
            )

            if isinstance(param_config, list):
                if isinstance(value, (int, np.integer)) and 0 <= value < len(
                    param_config
                ):
                    decoded[param_name] = param_config[value]
                else:
                    decoded[param_name] = value
            elif (
                isinstance(param_config, dict) and param_config.get("type") == "choice"
            ):
                options = param_config.get("options", [])
                if options and isinstance(value, int) and 0 <= value < len(options):
                    decoded[param_name] = options[value]
                else:
                    decoded[param_name] = value
            else:
                decoded[param_name] = value

        return decoded

    def save_mlflow(self, artifact_path: str = "model"):
        """
        ä¿å­˜æ¨¡å‹åˆ°MLflow.

        Args:
            artifact_path: MLflow artifactè·¯å¾„
        """
        if self.yolo is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•ä¿å­˜")

        logger.info("ä¿å­˜YOLOæ£€æµ‹æ¨¡å‹åˆ°MLflow...")

        # ä¿å­˜YOLOæƒé‡æ–‡ä»¶
        weights_path = "yolo_detection_best.pt"
        self.yolo.save(weights_path)
        logger.info(f"YOLOæƒé‡å·²ä¿å­˜: {weights_path}")

        # åˆ›å»ºMLflow pyfuncåŒ…è£…å™¨
        from .yolo_wrapper import YOLODetectionWrapper

        wrapper = YOLODetectionWrapper()

        # ä¿å­˜ç±»åˆ«åç§°åˆ°æ–‡ä»¶
        import json

        class_names_path = "class_names.json"
        # ä»æ¨¡å‹ä¸­æå–ç±»åˆ«åç§°
        class_names = self.yolo.names if hasattr(self.yolo, "names") else None
        if class_names:
            # YOLOçš„namesæ˜¯å­—å…¸æ ¼å¼ {0: 'person', 1: 'car', ...}
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            if isinstance(class_names, dict):
                class_names_list = [class_names[i] for i in sorted(class_names.keys())]
            else:
                class_names_list = list(class_names)

            with open(class_names_path, "w", encoding="utf-8") as f:
                json.dump(class_names_list, f, ensure_ascii=False, indent=2)

        # è®°å½•åˆ°MLflow
        mlflow.pyfunc.log_model(
            artifact_path=artifact_path,
            python_model=wrapper,
            artifacts={"weights": weights_path, "class_names": class_names_path},
            pip_requirements=[
                "ultralytics>=8.3.0",
                "torch>=2.0.0",
                "torchvision>=0.15.0",
                "Pillow>=10.0.0",
            ],
        )

        logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°MLflow: {artifact_path}")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os

        try:
            os.remove(weights_path)
            os.remove(class_names_path)
            logger.debug("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

    def get_params(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹å‚æ•°."""
        return {
            "model_name": self.model_name,
            **self.hyperparams,
        }

    def _check_fitted(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ."""
        if self.yolo is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()æ–¹æ³•")
