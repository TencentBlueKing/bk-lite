"""YOLOå›¾ç‰‡åˆ†ç±»æ¨¡å‹å°è£…."""

from typing import Dict, Any, Optional, Tuple, List
from pathlib import Path
import mlflow
from loguru import logger
from ultralytics import YOLO, settings
import uuid
import time
import logging

from classify_image_classification_server import PROJECT_ROOT
from .base import BaseImageClassificationModel, ModelRegistry

# ç¦ç”¨YOLOçš„MLflowè‡ªåŠ¨é›†æˆï¼Œé¿å…ä¸è‡ªå®šä¹‰MLflowç®¡ç†å†²çª
settings.update({"mlflow": False})

# ç¦ç”¨YOLOçš„è¯¦ç»†æ—¥å¿—è¾“å‡º
logging.getLogger("ultralytics").setLevel(logging.WARNING)

logger.info("å·²ç¦ç”¨YOLOçš„MLflowè‡ªåŠ¨é›†æˆå’Œè¯¦ç»†æ—¥å¿—")


@ModelRegistry.register("YOLOClassification")
class YOLOClassificationModel(BaseImageClassificationModel):
    """YOLOå›¾ç‰‡åˆ†ç±»æ¨¡å‹.

    å°è£…ultralytics YOLOï¼Œå®ç°ç»Ÿä¸€çš„è®­ç»ƒå’Œæ¨ç†æ¥å£ã€‚
    """

    def __init__(self, model_name: str = "yolo11n-cls.pt", **hyperparams):
        """
        åˆå§‹åŒ–YOLOæ¨¡å‹.

        Args:
            model_name: YOLOæ¨¡å‹åç§°ï¼ˆå¦‚yolo11n-cls.pt, yolo11s-cls.ptç­‰ï¼‰
            **hyperparams: å…¶ä»–è¶…å‚æ•°
        """
        self.model_name = model_name
        self.hyperparams = hyperparams
        self.yolo = None
        self.class_names = None
        self._results = None

        logger.info(f"YOLOClassificationModelåˆå§‹åŒ–: {model_name}")

    def _get_param_value(self, param_name: str, default_value):
        """
        æ™ºèƒ½è·å–å‚æ•°å€¼ï¼šä¼˜å…ˆä½¿ç”¨æœç´¢ç©ºé—´ä¸­çš„é»˜è®¤å€¼ï¼Œå…¶æ¬¡ä½¿ç”¨å›ºå®šå€¼ï¼Œæœ€åä½¿ç”¨ä»£ç é»˜è®¤å€¼.

        å¦‚æœå‚æ•°åœ¨ search_space ä¸­å®šä¹‰ï¼Œåˆ™ä½¿ç”¨æœç´¢ç©ºé—´çš„ç¬¬ä¸€ä¸ªå€¼ä½œä¸ºé»˜è®¤å€¼ï¼Œ
        å¿½ç•¥ hyperparams ä¸­çš„å›ºå®šå€¼ï¼Œé¿å…é…ç½®æ··æ·†ã€‚

        Args:
            param_name: å‚æ•°åç§°
            default_value: ä»£ç ä¸­çš„é»˜è®¤å€¼ï¼ˆæœ€ç»ˆå›é€€å€¼ï¼‰

        Returns:
            å‚æ•°å€¼
        """
        search_space = self.hyperparams.get("search_space", {})

        # å¦‚æœå‚æ•°åœ¨æœç´¢ç©ºé—´ä¸­å®šä¹‰ï¼Œä½¿ç”¨æœç´¢ç©ºé—´çš„ç¬¬ä¸€ä¸ªå€¼
        if param_name in search_space:
            space_config = search_space[param_name]
            if isinstance(space_config, list) and len(space_config) > 0:
                # æœç´¢ç©ºé—´æ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå€¼ä½œä¸ºé»˜è®¤å€¼
                return space_config[0]
            elif isinstance(space_config, dict):
                # æœç´¢ç©ºé—´æ˜¯å­—å…¸é…ç½®
                if space_config.get("type") == "choice":
                    options = space_config.get("options", [])
                    if options:
                        return options[0]
                # å…¶ä»–ç±»å‹ï¼ˆuniform, loguniformç­‰ï¼‰ä½¿ç”¨ low ä½œä¸ºé»˜è®¤å€¼
                return space_config.get("low", default_value)

        # å¦åˆ™ä½¿ç”¨ hyperparams ä¸­çš„å›ºå®šå€¼
        return self.hyperparams.get(param_name, default_value)

    def fit(
        self,
        train_data: Tuple[str, List[str]],
        val_data: Optional[Tuple[str, List[str]]] = None,
        device: str = "auto",
        log_artifacts: bool = True,
        **kwargs,
    ) -> "YOLOClassificationModel":
        """
        è®­ç»ƒYOLOæ¨¡å‹.

        Args:
            train_data: (train_path, class_names)
            val_data: (val_path, class_names) å¯é€‰
            device: è®¾å¤‡é…ç½®
            log_artifacts: æ˜¯å¦ä¸Šä¼ è®­ç»ƒäº§ç”Ÿçš„artifactsåˆ°MLflowï¼Œé»˜è®¤True
            **kwargs: é¢å¤–è®­ç»ƒå‚æ•°

        Returns:
            self
        """
        train_path, class_names = train_data
        self.class_names = class_names

        logger.info(f"å¼€å§‹è®­ç»ƒYOLOæ¨¡å‹ï¼Œè®¾å¤‡: {device}")
        logger.info(f"è®­ç»ƒé›†: {train_path}, ç±»åˆ«æ•°: {len(class_names)}")

        # åˆå§‹åŒ–YOLOæ¨¡å‹
        self.yolo = YOLO(self.model_name)

        # YOLOéœ€è¦æ•°æ®é›†æ ¹ç›®å½•ï¼Œä¸æ˜¯trainå­ç›®å½•
        # ä»train_pathæå–æ ¹ç›®å½•: /path/to/dataset/train -> /path/to/dataset
        from pathlib import Path

        dataset_root = str(Path(train_path).parent)
        logger.info(f"æ•°æ®é›†æ ¹ç›®å½•: {dataset_root}")

        # æ„å»ºè®­ç»ƒå‚æ•°
        train_kwargs = {
            "data": dataset_root,
            "epochs": self.hyperparams.get("epochs", 100),
            "imgsz": self._get_param_value("imgsz", 224),
            "batch": self._get_param_value("batch", 16),
            "lr0": self._get_param_value("lr0", 0.01),
            "lrf": self.hyperparams.get("lrf", 0.01),
            "momentum": self.hyperparams.get("momentum", 0.937),
            "weight_decay": self.hyperparams.get("weight_decay", 0.0005),
            "warmup_epochs": self.hyperparams.get("warmup_epochs", 3.0),
            "optimizer": self.hyperparams.get("optimizer", "AdamW"),
            "amp": self.hyperparams.get("amp", True),
            "patience": self.hyperparams.get("patience", 50),
            "device": device,
            "project": PROJECT_ROOT / ".yolo_runs" / "training",
            "name": f"train_{int(time.time())}_{uuid.uuid4().hex[:8]}",
            "save": True,
            "plots": True,
            "verbose": False,
        }

        if self.hyperparams.get("augment") is False:
            train_kwargs["augment"] = False
        else:
            for aug_param in [
                "degrees",
                "translate",
                "scale",
                "fliplr",
                "flipud",
                "hsv_h",
                "hsv_s",
                "hsv_v",
            ]:
                if aug_param in self.hyperparams:
                    train_kwargs[aug_param] = self.hyperparams[aug_param]

        if val_data:
            val_path, _ = val_data
            train_kwargs["val"] = True
            logger.info(f"ä½¿ç”¨éªŒè¯é›†: {val_path}")

        if device != "cpu" and self.hyperparams.get("amp", True):
            train_kwargs["amp"] = True
            logger.info("âš¡ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰")

        # ç¦ç”¨YOLOçš„è¯¦ç»†è¾“å‡º(æ¨¡å‹æ¶æ„ç­‰)
        train_kwargs["verbose"] = False

        # æ‰§è¡Œè®­ç»ƒ
        logger.info(
            f"ğŸš€ å¼€å§‹è®­ç»ƒ - epochs={train_kwargs['epochs']}, batch={train_kwargs['batch']}, imgsz={train_kwargs['imgsz']}"
        )
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {train_kwargs['project']}/{train_kwargs['name']}")

        train_start_time = time.time()
        results = self.yolo.train(**train_kwargs)
        train_duration = time.time() - train_start_time

        self._results = results

        # è®°å½•è®­ç»ƒlosså˜åŒ–ä¿¡æ¯
        loss_info = ""
        try:
            if hasattr(results, "results_dict") and results.results_dict:
                results_dict = results.results_dict
                if "train/loss" in results_dict:
                    final_loss = results_dict["train/loss"]
                    loss_info = f", æœ€ç»ˆloss={final_loss:.4f}"
                    logger.info(f"ğŸ“Š è®­ç»ƒloss: {final_loss:.4f}")
        except Exception as e:
            logger.debug(f"æ— æ³•è·å–lossä¿¡æ¯: {e}")

        logger.info(f"âœ“ è®­ç»ƒå®Œæˆ - è€—æ—¶: {train_duration / 60:.1f}åˆ†é’Ÿ{loss_info}")

        # æ‰‹åŠ¨ä¸Šä¼ YOLOè®­ç»ƒäº§ç”Ÿçš„artifactsåˆ°MLflowï¼ˆä»…åœ¨æœ€ç»ˆè®­ç»ƒæ—¶ï¼‰
        if log_artifacts:
            self._log_yolo_artifacts_to_mlflow(train_kwargs)
        else:
            # è¶…å‚æ•°ä¼˜åŒ–æ—¶ä¹Ÿè¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_yolo_output(train_kwargs)

        return self

    def predict(self, X: Any) -> List[int]:
        """
        æ‰¹é‡é¢„æµ‹.

        Args:
            X: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ã€PIL Imageåˆ—è¡¨æˆ–numpyæ•°ç»„

        Returns:
            é¢„æµ‹çš„ç±»åˆ«ç´¢å¼•åˆ—è¡¨
        """
        if self.yolo is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()æ–¹æ³•")

        results = self.yolo.predict(
            X, imgsz=self.hyperparams.get("imgsz", 224), verbose=False
        )

        # æå–é¢„æµ‹ç±»åˆ«
        predictions = [r.probs.top1 for r in results]
        return predictions

    def evaluate(
        self,
        test_data: Tuple[str, List[str]],
        prefix: str = "test",
        log_artifacts: bool = False,
    ) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½.

        Args:
            test_data: (test_path, class_names)
            prefix: æŒ‡æ ‡å‰ç¼€
            log_artifacts: æ˜¯å¦ä¸Šä¼ è¯„ä¼°äº§ç”Ÿçš„artifactsåˆ°MLflowï¼Œé»˜è®¤False

        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        if self.yolo is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒ")

        test_path, class_names = test_data
        logger.info(f"åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹: {test_path}")

        from pathlib import Path

        dataset_root = str(Path(test_path).parent)
        logger.info(f"æ•°æ®é›†æ ¹ç›®å½•: {dataset_root}")

        eval_kwargs = {
            "data": dataset_root,
            "split": prefix,
            "verbose": False,
            "save": True,
            "plots": True,
            "project": PROJECT_ROOT / ".yolo_runs" / "validation",
            "name": f"eval_{prefix}_{int(time.time())}_{uuid.uuid4().hex[:8]}",
        }

        metrics = self.yolo.val(**eval_kwargs)

        eval_results = {
            f"{prefix}_acc_top1": float(metrics.top1),
            f"{prefix}_acc_top5": float(metrics.top5),
        }

        if (
            hasattr(metrics, "confusion_matrix")
            and metrics.confusion_matrix is not None
        ):
            eval_results["_confusion_matrix"] = metrics.confusion_matrix.matrix

        logger.info(
            f"è¯„ä¼°å®Œæˆ: top1_acc={eval_results[f'{prefix}_acc_top1']:.4f}, top5_acc={eval_results[f'{prefix}_acc_top5']:.4f}"
        )

        if log_artifacts:
            self._log_yolo_eval_artifacts_to_mlflow(eval_kwargs, prefix)
        else:
            self._cleanup_yolo_output(eval_kwargs)

        return eval_results

    def _log_yolo_artifacts_to_mlflow(self, train_kwargs: Dict[str, Any]):
        """
        æ‰‹åŠ¨ä¸Šä¼ YOLOè®­ç»ƒäº§ç”Ÿçš„artifactsåˆ°MLflow.

        ç”±äºç¦ç”¨äº†YOLOçš„MLflowè‡ªåŠ¨é›†æˆï¼Œéœ€è¦æ‰‹åŠ¨ä¸Šä¼ è®­ç»ƒäº§ç”Ÿçš„æ–‡ä»¶ã€‚

        Args:
            train_kwargs: è®­ç»ƒå‚æ•°ï¼ŒåŒ…å«projectå’Œname
        """
        import shutil

        # è·å–YOLOè¾“å‡ºç›®å½•
        save_dir = Path(train_kwargs["project"]) / train_kwargs["name"]

        if not save_dir.exists():
            logger.warning(f"YOLOè¾“å‡ºç›®å½•ä¸å­˜åœ¨: {save_dir}")
            return

        logger.info(f"å¼€å§‹ä¸Šä¼ YOLOè®­ç»ƒartifactsåˆ°MLflow: {save_dir}")

        try:
            # ä¸Šä¼ æƒé‡æ–‡ä»¶
            weights_dir = save_dir / "weights"
            if weights_dir.exists():
                logger.info("ä¸Šä¼ æ¨¡å‹æƒé‡...")
                mlflow.log_artifacts(str(weights_dir), artifact_path="weights")

            # ä¸Šä¼ è®­ç»ƒç»“æœæ–‡ä»¶
            files_to_upload = [
                "args.yaml",  # è®­ç»ƒå‚æ•°
                "results.csv",  # è®­ç»ƒæŒ‡æ ‡
                "results.png",  # è®­ç»ƒæ›²çº¿
                "confusion_matrix.png",  # æ··æ·†çŸ©é˜µ
                "confusion_matrix_normalized.png",  # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ
            ]

            for filename in files_to_upload:
                file_path = save_dir / filename
                if file_path.exists():
                    logger.debug(f"ä¸Šä¼ æ–‡ä»¶: {filename}")
                    mlflow.log_artifact(str(file_path))

            # ä¸Šä¼ è®­ç»ƒè¿‡ç¨‹çš„å¯è§†åŒ–å›¾ç‰‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            for img_file in save_dir.glob("*.jpg"):
                logger.debug(f"ä¸Šä¼ å›¾ç‰‡: {img_file.name}")
                mlflow.log_artifact(str(img_file))

            for img_file in save_dir.glob("*.png"):
                if img_file.name not in files_to_upload:
                    logger.debug(f"ä¸Šä¼ å›¾ç‰‡: {img_file.name}")
                    mlflow.log_artifact(str(img_file))

            logger.info("âœ“ YOLOè®­ç»ƒartifactsä¸Šä¼ å®Œæˆ")

            # æ¸…ç†è¾“å‡ºç›®å½•
            self._cleanup_yolo_output(train_kwargs)

        except Exception as e:
            logger.error(f"ä¸Šä¼ artifactsåˆ°MLflowå¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è®­ç»ƒæµç¨‹

    def _log_yolo_eval_artifacts_to_mlflow(
        self, eval_kwargs: Dict[str, Any], prefix: str = "test"
    ):
        """
        æ‰‹åŠ¨ä¸Šä¼ YOLOè¯„ä¼°äº§ç”Ÿçš„artifactsåˆ°MLflow.

        Args:
            eval_kwargs: è¯„ä¼°å‚æ•°ï¼ŒåŒ…å«projectå’Œname
            prefix: è¯„ä¼°å‰ç¼€ï¼ˆtest/valç­‰ï¼‰ï¼Œç”¨äºç»„ç»‡artifactsç›®å½•ç»“æ„
        """
        import shutil

        # è·å–YOLOè¾“å‡ºç›®å½•
        save_dir = Path(eval_kwargs["project"]) / eval_kwargs["name"]

        if not save_dir.exists():
            logger.warning(f"YOLOè¯„ä¼°è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {save_dir}")
            return

        logger.info(f"å¼€å§‹ä¸Šä¼ YOLOè¯„ä¼°artifactsåˆ°MLflow: {save_dir}")

        try:
            # è¯„ä¼°artifactsä¸Šä¼ åˆ°å­ç›®å½•ï¼Œé¿å…ä¸è®­ç»ƒartifactså†²çª
            artifact_path = f"{prefix}_evaluation"

            # ä¸Šä¼ è¯„ä¼°ç»“æœæ–‡ä»¶
            files_to_upload = [
                "confusion_matrix.png",  # æ··æ·†çŸ©é˜µ
                "confusion_matrix_normalized.png",  # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ
            ]

            for filename in files_to_upload:
                file_path = save_dir / filename
                if file_path.exists():
                    logger.debug(f"ä¸Šä¼ æ–‡ä»¶: {filename}")
                    mlflow.log_artifact(str(file_path), artifact_path=artifact_path)

            # ä¸Šä¼ è¯„ä¼°è¿‡ç¨‹çš„å¯è§†åŒ–å›¾ç‰‡ï¼ˆbatché¢„æµ‹æ ·ä¾‹ï¼‰
            for img_file in save_dir.glob("*.jpg"):
                logger.debug(f"ä¸Šä¼ å›¾ç‰‡: {img_file.name}")
                mlflow.log_artifact(str(img_file), artifact_path=artifact_path)

            # ä¸Šä¼ å…¶ä»–PNGå›¾ç‰‡ï¼ˆæ’é™¤å·²ä¸Šä¼ çš„ï¼‰
            for img_file in save_dir.glob("*.png"):
                if img_file.name not in files_to_upload:
                    logger.debug(f"ä¸Šä¼ å›¾ç‰‡: {img_file.name}")
                    mlflow.log_artifact(str(img_file), artifact_path=artifact_path)

            logger.info(f"âœ“ YOLOè¯„ä¼°artifactsä¸Šä¼ å®Œæˆï¼ˆç›®å½•: {artifact_path}ï¼‰")

            # æ¸…ç†è¾“å‡ºç›®å½•
            self._cleanup_yolo_output(eval_kwargs)

        except Exception as e:
            logger.error(f"ä¸Šä¼ è¯„ä¼°artifactsåˆ°MLflowå¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“è¯„ä¼°æµç¨‹

    def _cleanup_yolo_output(self, train_kwargs: Dict[str, Any]):
        """
        æ¸…ç†YOLOè®­ç»ƒ/è¯„ä¼°è¾“å‡ºç›®å½•.

        Args:
            train_kwargs: è®­ç»ƒ/è¯„ä¼°å‚æ•°ï¼ŒåŒ…å«projectå’Œname
        """
        import shutil

        save_dir = Path(train_kwargs["project"]) / train_kwargs["name"]

        if save_dir.exists():
            logger.debug(f"æ¸…ç†YOLOè¾“å‡ºç›®å½•: {save_dir}")
            try:
                shutil.rmtree(save_dir, ignore_errors=True)
                logger.debug("âœ“ è¾“å‡ºç›®å½•å·²æ¸…ç†")
            except Exception as e:
                logger.warning(f"æ¸…ç†è¾“å‡ºç›®å½•å¤±è´¥: {e}")

    def optimize_hyperparams(
        self,
        train_data: Tuple[str, List[str]],
        val_data: Tuple[str, List[str]],
        max_evals: int,
    ) -> Dict[str, Any]:
        """
        è¶…å‚æ•°ä¼˜åŒ–ï¼ˆä½¿ç”¨Hyperoptï¼‰.

        Args:
            train_data: è®­ç»ƒæ•°æ®
            val_data: éªŒè¯æ•°æ®
            max_evals: æœ€å¤§è¯„ä¼°æ¬¡æ•°

        Returns:
            æœ€ä¼˜è¶…å‚æ•°å­—å…¸
        """
        from hyperopt import hp, fmin, tpe, Trials
        import numpy as np

        if max_evals <= 0:
            logger.info("è·³è¿‡è¶…å‚æ•°ä¼˜åŒ–ï¼ˆmax_evals=0ï¼‰")
            return {}

        logger.info(f"ğŸ” å¼€å§‹è¶…å‚æ•°ä¼˜åŒ– - æœ€å¤§è¯„ä¼°æ¬¡æ•°: {max_evals}")

        search_space_config = self.hyperparams.get("search_space", {})
        space = self._build_search_space(search_space_config)
        device = self.hyperparams.get("_device", "auto")

        early_stopping_config = self.hyperparams.get("early_stopping", {})
        early_stop_enabled = early_stopping_config.get("enabled", True)
        patience = early_stopping_config.get("patience", 10)

        if early_stop_enabled:
            logger.info(f"æ—©åœæœºåˆ¶: å¯ç”¨ (patience={patience})")

        optimization_start = time.time()
        trial_count = [0]
        best_score = [float("inf")]

        def objective(params):
            """ä¼˜åŒ–ç›®æ ‡å‡½æ•°."""
            temp_model = None
            try:
                trial_count[0] += 1
                logger.info(f"  Trial {trial_count[0]}/{max_evals} - å‚æ•°: {params}")

                temp_hyperparams = {**self.hyperparams, **params}
                # ç¡®ä¿trial epochsæœ€å°ä¸º10ï¼Œè®¡ç®—å…¬å¼ï¼šmax(10, é…ç½®epochs // 10)
                trial_epochs = max(10, self.hyperparams.get("epochs", 100) // 10)
                temp_hyperparams["epochs"] = trial_epochs
                temp_hyperparams["patience"] = 5
                temp_hyperparams["_device"] = device

                logger.info(
                    f"  Trial {trial_count[0]} ä½¿ç”¨ {trial_epochs} epochsï¼ˆå®Œæ•´è®­ç»ƒä¸º {self.hyperparams.get('epochs', 100)} epochsï¼‰"
                )

                temp_model = YOLOClassificationModel(
                    model_name=self.model_name, **temp_hyperparams
                )

                temp_model.fit(train_data, val_data, device=device, log_artifacts=False)

                # è·å–è®­ç»ƒlossä¿¡æ¯
                final_loss = None
                if hasattr(temp_model, "_results") and temp_model._results is not None:
                    try:
                        # YOLO resultså¯¹è±¡åŒ…å«è®­ç»ƒæŒ‡æ ‡
                        results_dict = (
                            temp_model._results.results_dict
                            if hasattr(temp_model._results, "results_dict")
                            else {}
                        )
                        if "train/loss" in results_dict:
                            final_loss = results_dict["train/loss"]
                        elif hasattr(temp_model._results, "box") and hasattr(
                            temp_model._results.box, "loss"
                        ):
                            final_loss = temp_model._results.box.loss
                    except Exception as e:
                        logger.debug(f"æ— æ³•è·å–lossä¿¡æ¯: {e}")

                if val_data:
                    val_metrics = temp_model.evaluate(val_data, prefix="val")
                    score = -val_metrics["val_acc_top1"]
                    val_acc_top1 = val_metrics["val_acc_top1"]
                    val_acc_top5 = val_metrics["val_acc_top5"]

                    # è®°å½•ç»“æœï¼ŒåŒ…å«lossä¿¡æ¯
                    loss_info = (
                        f", loss={final_loss:.4f}" if final_loss is not None else ""
                    )
                    logger.info(
                        f"  Trial {trial_count[0]} ç»“æœ: top1={val_acc_top1:.4f}, top5={val_acc_top5:.4f}{loss_info}"
                    )

                    if mlflow.active_run():
                        mlflow.log_metric(
                            f"hyperopt/val_acc_top1", val_acc_top1, step=trial_count[0]
                        )
                        mlflow.log_metric(
                            f"hyperopt/val_acc_top5", val_acc_top5, step=trial_count[0]
                        )
                        if final_loss is not None:
                            mlflow.log_metric(
                                f"hyperopt/final_loss", final_loss, step=trial_count[0]
                            )

                        for k, v in params.items():
                            mlflow.log_param(f"trial_{trial_count[0]}_{k}", str(v))

                        if score < best_score[0]:
                            best_score[0] = score
                            mlflow.log_metric(
                                "hyperopt/best_acc_top1",
                                -best_score[0],
                                step=trial_count[0],
                            )

                    return score
                else:
                    train_metrics = temp_model.evaluate(train_data, prefix="train")
                    score = -train_metrics["train_acc_top1"]
                    logger.info(
                        f"  Trial {trial_count[0]} ç»“æœ: acc={train_metrics['train_acc_top1']:.4f}"
                    )
                    return score

            except Exception as e:
                logger.error(f"  Trial {trial_count[0]} å¤±è´¥: {type(e).__name__}: {e}")
                import traceback

                logger.debug(f"å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
                return 1.0

            finally:
                if temp_model is not None:
                    if hasattr(temp_model, "yolo") and temp_model.yolo is not None:
                        del temp_model.yolo
                    del temp_model

                # Force garbage collection for both CPU and GPU
                import gc

                gc.collect()

                # Clear CUDA cache if available
                if device != "cpu":
                    import torch

                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()

        # æ‰§è¡Œä¼˜åŒ–
        from hyperopt.early_stop import no_progress_loss

        trials = Trials()
        early_stop_fn = no_progress_loss(patience) if early_stop_enabled else None

        best_params = fmin(
            objective,
            space,
            algo=tpe.suggest,
            max_evals=max_evals,
            trials=trials,
            early_stop_fn=early_stop_fn,
            show_progressbar=False,
        )

        best_params = self._decode_hyperopt_params(best_params, search_space_config)

        optimization_duration = time.time() - optimization_start
        actual_evals = len(trials.trials)
        is_early_stopped = actual_evals < max_evals

        logger.info(f"âœ“ è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ - è€—æ—¶: {optimization_duration / 60:.1f}åˆ†é’Ÿ")
        logger.info(f"  æœ€ä¼˜å‚æ•°: {best_params}")
        logger.info(f"  æœ€ä¼˜å¾—åˆ†: {-trials.best_trial['result']['loss']:.4f}")
        logger.info(f"  å®é™…è¯„ä¼°æ¬¡æ•°: {actual_evals}/{max_evals}")

        if mlflow.active_run():
            success_trials = [
                t
                for t in trials.trials
                if t["result"]["status"] == "ok" and t["result"]["loss"] != 1.0
            ]
            failed_trials = [
                t
                for t in trials.trials
                if t["result"]["status"] != "ok" or t["result"]["loss"] == 1.0
            ]

            mlflow.log_metrics(
                {
                    "hyperopt_summary/total_evals": max_evals,
                    "hyperopt_summary/actual_evals": actual_evals,
                    "hyperopt_summary/successful_evals": len(success_trials),
                    "hyperopt_summary/failed_evals": len(failed_trials),
                    "hyperopt_summary/best_acc": -best_score[0],
                    "hyperopt_summary/optimization_duration_min": optimization_duration
                    / 60,
                }
            )

            if early_stop_enabled:
                mlflow.log_metrics(
                    {
                        "hyperopt_summary/early_stop_enabled": 1.0,
                        "hyperopt_summary/early_stopped": 1.0
                        if is_early_stopped
                        else 0.0,
                        "hyperopt_summary/patience": patience,
                    }
                )

        # å°†numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹ï¼ˆYOLOä¸æ¥å—numpyç±»å‹ï¼‰
        import numpy as np

        converted_params = {}
        for key, value in best_params.items():
            if isinstance(value, np.integer):
                converted_params[key] = int(value)
            elif isinstance(value, np.floating):
                converted_params[key] = float(value)
            elif isinstance(value, np.ndarray):
                converted_params[key] = value.tolist()
            else:
                converted_params[key] = value

        logger.info(
            f"è½¬æ¢åçš„å‚æ•°ç±»å‹: {[(k, type(v).__name__) for k, v in converted_params.items()]}"
        )

        # æ›´æ–°æ¨¡å‹è¶…å‚æ•°
        self.hyperparams.update(converted_params)

        return converted_params

    def _build_search_space(
        self, search_space_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ ¹æ®é…ç½®æ„å»ºHyperoptæœç´¢ç©ºé—´.

        Args:
            search_space_config: æœç´¢ç©ºé—´é…ç½®å­—å…¸ï¼ˆæ ¼å¼: {param_name: [value1, value2, ...]}ï¼‰

        Returns:
            Hyperoptæœç´¢ç©ºé—´
        """
        from hyperopt import hp
        import numpy as np

        if not search_space_config:
            # ä½¿ç”¨é»˜è®¤æœç´¢ç©ºé—´
            logger.info("æœªå®šä¹‰æœç´¢ç©ºé—´ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {
                "lr0": hp.choice("lr0", [0.0001, 0.001, 0.01, 0.05, 0.1]),
                "batch": hp.choice("batch", [8, 16, 32, 64]),
                "imgsz": hp.choice("imgsz", [224, 256, 320]),
            }

        # ä»é…ç½®æ„å»ºæœç´¢ç©ºé—´ï¼ˆç®€åŒ–æ ¼å¼ï¼šç›´æ¥ç”¨åˆ—è¡¨ï¼‰
        space = {}

        for param_name, param_values in search_space_config.items():
            if isinstance(param_values, list) and len(param_values) > 0:
                # hp.choiceç›´æ¥è¿”å›åˆ—è¡¨ä¸­çš„å€¼ï¼ˆä¸æ˜¯ç´¢å¼•ï¼‰
                space[param_name] = hp.choice(param_name, param_values)
            elif isinstance(param_values, dict):
                # å…¼å®¹æ—§æ ¼å¼ï¼ˆå¸¦typeçš„é…ç½®ï¼‰
                param_type = param_values.get("type", "uniform")

                if param_type == "loguniform":
                    low = param_values.get("low", 0.0001)
                    high = param_values.get("high", 0.1)
                    space[param_name] = hp.loguniform(
                        param_name, np.log(low), np.log(high)
                    )
                elif param_type == "uniform":
                    low = param_values.get("low", 0.0)
                    high = param_values.get("high", 1.0)
                    space[param_name] = hp.uniform(param_name, low, high)
                elif param_type == "quniform":
                    low = param_values.get("low", 0.0)
                    high = param_values.get("high", 1.0)
                    q = param_values.get("q", 1.0)
                    space[param_name] = hp.quniform(param_name, low, high, q)
                elif param_type == "choice":
                    options = param_values.get("options", [])
                    if options:
                        space[param_name] = hp.choice(param_name, options)

        logger.info(f"æœç´¢ç©ºé—´å‚æ•°: {list(space.keys())}")
        return space

    def _decode_hyperopt_params(
        self, params: Dict[str, Any], search_space_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        è§£ç Hyperoptè¿”å›çš„å‚æ•°ï¼ˆhp.choiceè¿”å›ç´¢å¼•ï¼Œéœ€è½¬æ¢ä¸ºå®é™…å€¼ï¼‰.

        Args:
            params: Hyperoptè¿”å›çš„å‚æ•°å­—å…¸ï¼ˆå¯èƒ½åŒ…å«ç´¢å¼•ï¼‰
            search_space_config: æœç´¢ç©ºé—´é…ç½®

        Returns:
            è§£ç åçš„å‚æ•°å­—å…¸
        """
        # é»˜è®¤æœç´¢ç©ºé—´ï¼ˆä¸_build_search_spaceä¿æŒä¸€è‡´ï¼‰
        default_space = {
            "lr0": [0.0001, 0.001, 0.01, 0.05, 0.1],
            "batch": [8, 16, 32, 64],
            "imgsz": [224, 256, 320],
        }

        import numpy as np

        decoded = {}

        for param_name, value in params.items():
            # ä¼˜å…ˆä½¿ç”¨é…ç½®çš„æœç´¢ç©ºé—´ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤æœç´¢ç©ºé—´
            param_config = search_space_config.get(param_name) or default_space.get(
                param_name
            )

            # å¦‚æœé…ç½®æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œä¸”valueæ˜¯ç´¢å¼•ï¼Œè½¬æ¢ä¸ºå®é™…å€¼
            if isinstance(param_config, list):
                # æ”¯æŒPython intå’Œnumpyæ•´æ•°ç±»å‹ï¼ˆnp.int64, np.int32ç­‰ï¼‰
                if isinstance(value, (int, np.integer)) and 0 <= value < len(
                    param_config
                ):
                    decoded[param_name] = param_config[value]
                else:
                    decoded[param_name] = value
            # å…¼å®¹æ—§çš„dictæ ¼å¼
            elif (
                isinstance(param_config, dict) and param_config.get("type") == "choice"
            ):
                options = param_config.get("options", [])
                if options and isinstance(value, int) and 0 <= value < len(options):
                    decoded[param_name] = options[value]
                else:
                    decoded[param_name] = value
            else:
                decoded[param_name] = value

        return decoded

    def save_mlflow(self, artifact_path: str = "model"):
        """
        ä¿å­˜æ¨¡å‹åˆ°MLflow.

        Args:
            artifact_path: MLflow artifactè·¯å¾„
        """
        if self.yolo is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•ä¿å­˜")

        logger.info("ä¿å­˜YOLOæ¨¡å‹åˆ°MLflow...")

        # ä¿å­˜YOLOæƒé‡æ–‡ä»¶
        weights_path = "yolo_best.pt"
        self.yolo.save(weights_path)
        logger.info(f"YOLOæƒé‡å·²ä¿å­˜: {weights_path}")

        # åˆ›å»ºMLflow pyfuncåŒ…è£…å™¨
        from .yolo_wrapper import YOLOClassificationWrapper

        wrapper = YOLOClassificationWrapper()

        # ä¿å­˜ç±»åˆ«åç§°åˆ°æ–‡ä»¶
        import json

        class_names_path = "class_names.json"
        with open(class_names_path, "w", encoding="utf-8") as f:
            json.dump(self.class_names, f, ensure_ascii=False, indent=2)

        # è®°å½•åˆ°MLflow
        mlflow.pyfunc.log_model(
            artifact_path=artifact_path,
            python_model=wrapper,
            artifacts={"weights": weights_path, "class_names": class_names_path},
            pip_requirements=[
                "ultralytics>=8.3.0",
                "torch>=2.0.0",
                "torchvision>=0.15.0",
                "Pillow>=10.0.0",
            ],
        )

        logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°MLflow: {artifact_path}")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os

        try:
            os.remove(weights_path)
            os.remove(class_names_path)
            logger.debug("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

    def get_params(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹å‚æ•°."""
        return {"model_name": self.model_name, **self.hyperparams}

    def _check_fitted(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ."""
        if self.yolo is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()æ–¹æ³•")
