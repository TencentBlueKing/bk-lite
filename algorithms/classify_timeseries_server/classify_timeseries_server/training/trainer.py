"""é€šç”¨æ—¶é—´åºåˆ—è®­ç»ƒå™¨

æ”¯æŒå¤šç§æ¨¡åž‹çš„ç»Ÿä¸€è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
- åŠ¨æ€æ¨¡åž‹é€‰æ‹©
- è¶…å‚æ•°ä¼˜åŒ–
- æ¨¡åž‹è®­ç»ƒå’Œè¯„ä¼°
- MLflow é›†æˆ
"""

from typing import Dict, Any, Optional, Tuple
import pandas as pd
import numpy as np
import mlflow
from pathlib import Path
from loguru import logger

from .config.loader import TrainingConfig
from .models.base import ModelRegistry, BaseTimeSeriesModel
from .preprocessing import TimeSeriesPreprocessor
from .data_loader import load_dataset
from .mlflow_utils import MLFlowUtils


class UniversalTrainer:
    """é€šç”¨æ—¶é—´åºåˆ—è®­ç»ƒå™¨

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. é…ç½®é©±åŠ¨çš„è®­ç»ƒæµç¨‹
    2. åŠ¨æ€æ¨¡åž‹åŠ è½½ï¼ˆé€šè¿‡ ModelRegistryï¼‰
    3. å®Œæ•´çš„æ•°æ®å¤„ç† Pipeline
    4. å¯é€‰çš„è¶…å‚æ•°ä¼˜åŒ–
    5. MLflow å®žéªŒè·Ÿè¸ª

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        config = TrainingConfig("train.json")
        trainer = UniversalTrainer(config)
        result = trainer.train("data.csv")
    """

    def __init__(self, config: TrainingConfig):
        """åˆå§‹åŒ–è®­ç»ƒå™¨

        Args:
            config: è®­ç»ƒé…ç½®å¯¹è±¡
        """
        self.config = config
        self.model = None
        self.preprocessor = None
        self.frequency = None

        logger.info(f"è®­ç»ƒå™¨åˆå§‹åŒ– - æ¨¡åž‹ç±»åž‹: {config.model_type}")

    def train(self, dataset_path: str) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹

        æ•°æ®åŠ è½½æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        - ç›®å½•æ¨¡å¼ï¼šdataset_path ä¸ºç›®å½•ï¼Œè‡ªåŠ¨æŸ¥æ‰¾ train_data.csv/val_data.csv/test_data.csv
        - æ–‡ä»¶æ¨¡å¼ï¼šdataset_path ä¸ºå•ä¸ªCSVæ–‡ä»¶ï¼Œè‡ªåŠ¨æŒ‰å›ºå®šæ¯”ä¾‹(0.2/0.1)åˆ’åˆ†

        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆç›®å½•æˆ–å•ä¸ªæ–‡ä»¶ï¼‰

        Returns:
            è®­ç»ƒç»“æžœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - model: è®­ç»ƒå¥½çš„æ¨¡åž‹
            - test_metrics: æµ‹è¯•é›†è¯„ä¼°æŒ‡æ ‡
            - val_metrics: éªŒè¯é›†è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æžœæœ‰ï¼‰
            - run_id: MLflow run ID
            - frequency: æŽ¨æ–­çš„æ—¶é—´é¢‘çŽ‡
            - best_params: æœ€ä¼˜è¶…å‚æ•°ï¼ˆå¦‚æžœè¿›è¡Œäº†ä¼˜åŒ–ï¼‰
        """
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹è®­ç»ƒ - æ¨¡åž‹: {self.config.model_type}")
        logger.info("=" * 60)

        # 1. è®¾ç½® MLflow
        self._setup_mlflow()

        # 2. åŠ è½½æ•°æ®
        train_df, val_df, test_df = self._load_data(dataset_path)

        # 3. æ•°æ®é¢„å¤„ç†
        train_data, val_data, test_data = self._preprocess_data(
            train_df, val_df, test_df
        )

        # 4. åˆ›å»ºæ¨¡åž‹å®žä¾‹
        self.model = self._create_model()

        # 5. å¼€å§‹ MLflow run
        with mlflow.start_run(run_name=self.config.mlflow_run_name) as run:
            try:
                # è®°å½•é…ç½®
                self._log_config()

                # 6. è¶…å‚æ•°ä¼˜åŒ–ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
                best_params = None
                if val_data is not None:
                    best_params = self._optimize_hyperparams(train_data, val_data)
                    mlflow.log_params(best_params)

                # 7. è®­ç»ƒæ¨¡åž‹
                self._train_model(train_data, val_data)

                # 7.5. è¯„ä¼°è®­ç»ƒæ•°æ®æ‹Ÿåˆåº¦ï¼ˆæ ·æœ¬å†…è¯„ä¼°ï¼‰
                # æ³¨æ„: fit()é»˜è®¤ä½¿ç”¨merge_val=True,å³train+valä¸€èµ·è®­ç»ƒ
                # å› æ­¤è¿™é‡Œè¯„ä¼°çš„æ˜¯æ•´ä¸ªè®­ç»ƒæ•°æ®(train+val)çš„æ‹Ÿåˆåº¦
                val_metrics = None
                if val_data is not None:
                    final_train_data = pd.concat([train_data, val_data])
                    logger.info("è¯„ä¼°æœ€ç»ˆè®­ç»ƒæ•°æ®æ‹Ÿåˆåº¦ï¼ˆtrain+valæ ·æœ¬å†…è¯„ä¼°ï¼‰...")
                    final_train_metrics = self.model.evaluate(
                        final_train_data, is_in_sample=True
                    )
                    # è¿‡æ»¤æŽ‰å†…éƒ¨æ•°æ®ï¼ˆ_å¼€å¤´çš„é”®ï¼Œå¦‚ _predictions, _y_trueï¼‰
                    metrics_to_log = {
                        k: v
                        for k, v in final_train_metrics.items()
                        if not k.startswith("_")
                    }
                    mlflow.log_metrics(
                        {f"final_train_{k}": v for k, v in metrics_to_log.items()}
                    )
                    MLFlowUtils.log_params_batch(
                        {
                            "final_train_samples": len(final_train_data),
                            "final_train_merge_val": True,
                            "final_train_eval_mode": "in_sample",
                        }
                    )
                    logger.info(f"æœ€ç»ˆè®­ç»ƒæ•°æ®æ‹Ÿåˆåº¦è¯„ä¼°å®Œæˆ: {final_train_metrics}")
                else:
                    # æ— éªŒè¯é›†,åªè¯„ä¼°è®­ç»ƒé›†
                    logger.info("è¯„ä¼°è®­ç»ƒé›†æ‹Ÿåˆåº¦ï¼ˆæ ·æœ¬å†…è¯„ä¼°ï¼‰...")
                    train_metrics = self.model.evaluate(train_data, is_in_sample=True)
                    # è¿‡æ»¤æŽ‰å†…éƒ¨æ•°æ®ï¼ˆ_å¼€å¤´çš„é”®ï¼Œå¦‚ _predictions, _y_trueï¼‰
                    metrics_to_log = {
                        k: v for k, v in train_metrics.items() if not k.startswith("_")
                    }
                    mlflow.log_metrics(
                        {f"train_{k}": v for k, v in metrics_to_log.items()}
                    )
                    logger.info(f"è®­ç»ƒé›†æ‹Ÿåˆåº¦è¯„ä¼°å®Œæˆ: {train_metrics}")

                # 9. è¯„ä¼°æµ‹è¯•é›†ï¼ˆä»Žè®­ç»ƒ+éªŒè¯é›†æœ«å°¾é¢„æµ‹ï¼‰
                test_metrics = self._evaluate_model_on_test(
                    train_data=train_data, val_data=val_data, test_data=test_data
                )
                mlflow.log_metrics({f"test_{k}": v for k, v in test_metrics.items()})

                # 10. ä¿å­˜æ¨¡åž‹åˆ° MLflow
                model_uri = self._save_model_to_mlflow()

                # 11. æ³¨å†Œæ¨¡åž‹åˆ° MLflow Model Registry
                self._register_model(model_uri)

                result = {
                    "model": self.model,
                    "test_metrics": test_metrics,
                    "val_metrics": val_metrics,
                    "run_id": run.info.run_id,
                    "frequency": self.frequency,
                    "best_params": best_params,
                }

                logger.info("=" * 60)
                logger.info("è®­ç»ƒå®Œæˆ")
                logger.info(f"æµ‹è¯•é›†æŒ‡æ ‡: {test_metrics}")
                logger.info(f"MLflow Run ID: {run.info.run_id}")
                logger.info("=" * 60)

                return result

            except Exception as e:
                logger.error(f"è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
                MLFlowUtils.log_params_batch({"status": "failed", "error": str(e)})
                raise

    def _setup_mlflow(self):
        """è®¾ç½® MLflow å®žéªŒ"""
        tracking_uri = self.config.mlflow_tracking_uri
        experiment_name = self.config.mlflow_experiment_name

        MLFlowUtils.setup_experiment(tracking_uri, experiment_name)

        logger.info(f"MLflow å®žéªŒ: {experiment_name}")
        if tracking_uri:
            logger.info(f"MLflow URI: {tracking_uri}")

    def _load_data(
        self, dataset_path: str
    ) -> Tuple[pd.DataFrame, Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """åŠ è½½æ•°æ®é›†ï¼ˆæ”¯æŒç›®å½•æ¨¡å¼å’Œæ–‡ä»¶æ¨¡å¼ï¼‰

        ç›®å½•æ¨¡å¼ï¼š
            - å¿…é¡»åŒ…å«ï¼štrain_data.csv
            - å¯é€‰åŒ…å«ï¼šval_data.csv, test_data.csv
            - å®½æ¾æ¨¡å¼ï¼šå¦‚ç¼ºå¤±éªŒè¯é›†/æµ‹è¯•é›†ï¼ŒåŽç»­è‡ªåŠ¨åˆ’åˆ†

        æ–‡ä»¶æ¨¡å¼ï¼š
            - åŠ è½½å•ä¸ªCSVæ–‡ä»¶
            - è¿”å›ž (df, None, None)ï¼ŒåŽç»­è‡ªåŠ¨åˆ’åˆ†

        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆç›®å½•æˆ–æ–‡ä»¶ï¼‰

        Returns:
            (è®­ç»ƒé›†, éªŒè¯é›†, æµ‹è¯•é›†)

        Raises:
            ValueError: è·¯å¾„æ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯ç›®å½•
            FileNotFoundError: ç›®å½•æ¨¡å¼ä¸‹æœªæ‰¾åˆ° train_data.csv
        """
        import os

        if os.path.isdir(dataset_path):
            # ç›®å½•æ¨¡å¼
            logger.info(f"ðŸ“ æ£€æµ‹åˆ°ç›®å½•æ¨¡å¼: {dataset_path}")

            train_path = os.path.join(dataset_path, "train_data.csv")
            if not os.path.exists(train_path):
                raise FileNotFoundError(
                    f"ç›®å½•æ¨¡å¼ä¸‹æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶: {train_path}\n"
                    f"ç›®å½•ä¸­å¿…é¡»åŒ…å« train_data.csv"
                )

            train_df = load_dataset(train_path)
            logger.info(f"âœ“ è®­ç»ƒé›†: {len(train_df)} æ¡è®°å½• (train_data.csv)")

            # å¯é€‰çš„éªŒè¯é›†
            val_df = None
            val_path = os.path.join(dataset_path, "val_data.csv")
            if os.path.exists(val_path):
                val_df = load_dataset(val_path)
                logger.info(f"âœ“ éªŒè¯é›†: {len(val_df)} æ¡è®°å½• (val_data.csv)")
            else:
                logger.info("âš  æœªæ‰¾åˆ° val_data.csvï¼Œå°†ä»Žè®­ç»ƒé›†è‡ªåŠ¨åˆ’åˆ†")

            # å¯é€‰çš„æµ‹è¯•é›†
            test_df = None
            test_path = os.path.join(dataset_path, "test_data.csv")
            if os.path.exists(test_path):
                test_df = load_dataset(test_path)
                logger.info(f"âœ“ æµ‹è¯•é›†: {len(test_df)} æ¡è®°å½• (test_data.csv)")
            else:
                logger.info("âš  æœªæ‰¾åˆ° test_data.csvï¼Œå°†ä»Žè®­ç»ƒé›†è‡ªåŠ¨åˆ’åˆ†")

            return train_df, val_df, test_df

        elif os.path.isfile(dataset_path):
            # æ–‡ä»¶æ¨¡å¼
            logger.info(f"ðŸ“„ æ£€æµ‹åˆ°æ–‡ä»¶æ¨¡å¼: {dataset_path}")
            df = load_dataset(dataset_path)
            logger.info(f"âœ“ åŠ è½½æ•°æ®: {len(df)} æ¡è®°å½•")
            logger.info("â„¹ å°†æŒ‰å›ºå®šæ¯”ä¾‹è‡ªåŠ¨åˆ’åˆ†ï¼ˆæµ‹è¯•é›† 0.2ï¼ŒéªŒè¯é›† 0.1ï¼‰")
            return df, None, None

        else:
            raise ValueError(
                f"æ— æ•ˆçš„æ•°æ®é›†è·¯å¾„: {dataset_path}\n"
                f"è·¯å¾„å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š\n"
                f"  1. åŒ…å« train_data.csv çš„ç›®å½•\n"
                f"  2. å•ä¸ª CSV æ–‡ä»¶"
            )

    def _preprocess_data(
        self,
        train_df: pd.DataFrame,
        val_df: Optional[pd.DataFrame],
        test_df: Optional[pd.DataFrame],
    ) -> Tuple[pd.Series, Optional[pd.Series], pd.Series]:
        """æ•°æ®é¢„å¤„ç†ï¼ˆæ¸…æ´— + è‡ªåŠ¨åˆ’åˆ†ï¼‰

        å¦‚æœªæä¾›æµ‹è¯•é›†/éªŒè¯é›†ï¼Œä»Žè®­ç»ƒé›†æŒ‰å›ºå®šæ¯”ä¾‹è‡ªåŠ¨åˆ’åˆ†ï¼ˆæµ‹è¯•é›†0.2ï¼ŒéªŒè¯é›†0.1ï¼‰ã€‚

        Args:
            train_df: è®­ç»ƒæ•°æ®æ¡†ï¼ˆå•æ–‡ä»¶æ¨¡å¼æ—¶åŒ…å«å®Œæ•´æ•°æ®ï¼‰
            val_df: éªŒè¯æ•°æ®æ¡†ï¼ˆå¯é€‰ï¼‰
            test_df: æµ‹è¯•æ•°æ®æ¡†ï¼ˆå¯é€‰ï¼‰

        Returns:
            (è®­ç»ƒåºåˆ—, éªŒè¯åºåˆ—, æµ‹è¯•åºåˆ—)
        """
        logger.info("æ•°æ®é¢„å¤„ç†ï¼ˆæ¸…æ´—ï¼‰...")

        # 1. èŽ·å–é¢„å¤„ç†é…ç½®ï¼ˆåªæœ‰æ¸…æ´—ç›¸å…³å‚æ•°ï¼‰
        preprocess_config = self.config.get("preprocessing", default={})

        # 2. åˆ›å»ºé¢„å¤„ç†å™¨ï¼ˆç®€åŒ–ï¼šåªéœ€æ¸…æ´—å‚æ•°ï¼‰
        self.preprocessor = TimeSeriesPreprocessor(
            max_missing_ratio=preprocess_config.get("max_missing_ratio", 0.3),
            interpolation_limit=preprocess_config.get("interpolation_limit", 3),
            handle_missing=preprocess_config.get("handle_missing", "interpolate"),
        )

        logger.info(f"é¢„å¤„ç†é…ç½®: {preprocess_config}")

        # 3. æ¸…æ´—æ‰€æœ‰æ•°æ®é›†ï¼ˆæ— çŠ¶æ€ï¼Œç›´æŽ¥è°ƒç”¨ï¼‰
        train_data, frequency = self.preprocessor.clean(train_df.copy())
        self.frequency = frequency
        logger.info(
            f"è®­ç»ƒé›†æ¸…æ´—å®Œæˆ: {len(train_data)} ä¸ªæ•°æ®ç‚¹, é¢‘çŽ‡: {frequency or 'æœªçŸ¥'}"
        )

        # éªŒè¯é›†
        val_data = None
        if val_df is not None:
            val_data, _ = self.preprocessor.clean(val_df.copy(), frequency)
            logger.info(f"éªŒè¯é›†æ¸…æ´—å®Œæˆ: {len(val_data)} ä¸ªæ•°æ®ç‚¹")

        # æµ‹è¯•é›†æˆ–ä»Žè®­ç»ƒé›†åˆ†å‰²
        if test_df is not None:
            test_data, _ = self.preprocessor.clean(test_df.copy(), frequency)
            logger.info(f"æµ‹è¯•é›†æ¸…æ´—å®Œæˆ: {len(test_data)} ä¸ªæ•°æ®ç‚¹")
        else:
            # ä»Žè®­ç»ƒé›†åˆ†å‰²æµ‹è¯•é›†
            test_size = self.config.test_size
            split_point = int(len(train_data) * (1 - test_size))
            test_data = train_data[split_point:]
            train_data = train_data[:split_point]
            logger.info(
                f"ä»Žè®­ç»ƒé›†åˆ†å‰²æµ‹è¯•é›†: è®­ç»ƒ={len(train_data)}, æµ‹è¯•={len(test_data)}"
            )

            # å¦‚æžœéœ€è¦éªŒè¯é›†ï¼Œä»Žè®­ç»ƒé›†å†åˆ†å‰²
            if val_data is None and self.config.validation_size > 0:
                val_size = self.config.validation_size
                val_split = int(len(train_data) * (1 - val_size))
                val_data = train_data[val_split:]
                train_data = train_data[:val_split]
                logger.info(
                    f"ä»Žè®­ç»ƒé›†åˆ†å‰²éªŒè¯é›†: è®­ç»ƒ={len(train_data)}, éªŒè¯={len(val_data)}"
                )

        # è®°å½•æ•°æ®åŸºæœ¬ä¿¡æ¯å’Œç»Ÿè®¡ç‰¹å¾åˆ° MLflow
        if mlflow.active_run():
            # æ”¶é›†æ‰€æœ‰å‚æ•°åˆ°å­—å…¸
            data_params = {}

            # æ•°æ®åŸºæœ¬ä¿¡æ¯
            if isinstance(train_data.index, pd.DatetimeIndex):
                data_params["train_start_date"] = str(train_data.index[0])
                data_params["train_end_date"] = str(train_data.index[-1])
                if val_data is not None and isinstance(
                    val_data.index, pd.DatetimeIndex
                ):
                    data_params["val_start_date"] = str(val_data.index[0])
                    data_params["val_end_date"] = str(val_data.index[-1])
                if test_data is not None and isinstance(
                    test_data.index, pd.DatetimeIndex
                ):
                    data_params["test_start_date"] = str(test_data.index[0])
                    data_params["test_end_date"] = str(test_data.index[-1])

            data_params["train_samples"] = len(train_data)
            if val_data is not None:
                data_params["val_samples"] = len(val_data)
            if test_data is not None:
                data_params["test_samples"] = len(test_data)

            try:
                freq = (
                    pd.infer_freq(train_data.index)
                    if isinstance(train_data.index, pd.DatetimeIndex)
                    else None
                )
                data_params["data_frequency"] = str(freq) if freq else "unknown"
            except:
                data_params["data_frequency"] = "unknown"

            # æ‰¹é‡è®°å½•å‚æ•°
            MLFlowUtils.log_params_batch(data_params)

            # æ•°æ®ç»Ÿè®¡ç‰¹å¾
            mlflow.log_metric("data_mean", float(train_data.mean()))
            mlflow.log_metric("data_std", float(train_data.std()))
            mlflow.log_metric("data_min", float(train_data.min()))
            mlflow.log_metric("data_max", float(train_data.max()))
            mlflow.log_metric("data_median", float(train_data.median()))
            mlflow.log_metric("data_range", float(train_data.max() - train_data.min()))

            logger.info("æ•°æ®ä¿¡æ¯å·²è®°å½•åˆ° MLflow")

        logger.info("æ•°æ®é¢„å¤„ç†å®Œæˆ")

        return train_data, val_data, test_data

    def _create_model(self) -> BaseTimeSeriesModel:
        """åˆ›å»ºæ¨¡åž‹å®žä¾‹

        Returns:
            æ¨¡åž‹å®žä¾‹

        Raises:
            ValueError: æ¨¡åž‹ç±»åž‹æœªæ³¨å†Œ
        """
        model_type = self.config.model_type

        # ä»Žæ³¨å†Œè¡¨èŽ·å–æ¨¡åž‹ç±»
        model_class = ModelRegistry.get(model_type)

        # èŽ·å–æ¨¡åž‹å‚æ•°
        model_params = self.config.get_model_params()

        # èŽ·å–ç‰¹å¾å·¥ç¨‹é…ç½®
        fe_config = self.config.get_feature_engineering_config()

        logger.info(f"åˆ›å»ºæ¨¡åž‹: {model_type}")
        logger.debug(f"æ¨¡åž‹å‚æ•°: {model_params}")
        if fe_config:
            logger.debug(f"ç‰¹å¾å·¥ç¨‹é…ç½®: {fe_config}")

        # å®žä¾‹åŒ–æ¨¡åž‹
        model = model_class(**model_params, feature_engineering_config=fe_config)

        return model

    def _optimize_hyperparams(
        self, train_data: pd.Series, val_data: pd.Series
    ) -> Dict[str, Any]:
        """è¶…å‚æ•°ä¼˜åŒ–

        Args:
            train_data: è®­ç»ƒæ•°æ®
            val_data: éªŒè¯æ•°æ®

        Returns:
            æœ€ä¼˜è¶…å‚æ•°å­—å…¸
        """
        logger.info("å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–...")

        # æ£€æŸ¥æ¨¡åž‹æ˜¯å¦æ”¯æŒè¶…å‚æ•°ä¼˜åŒ–
        if not hasattr(self.model, "optimize_hyperparams"):
            logger.warning(f"{self.config.model_type} æ¨¡åž‹ä¸æ”¯æŒè¶…å‚æ•°ä¼˜åŒ–ï¼Œè·³è¿‡")
            return {}

        # æ‰§è¡Œä¼˜åŒ–
        best_params = self.model.optimize_hyperparams(train_data, val_data, self.config)

        logger.info(f"è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ: {best_params}")

        return best_params

    def _train_model(self, train_data: pd.Series, val_data: Optional[pd.Series]):
        """è®­ç»ƒæ¨¡åž‹

        Args:
            train_data: è®­ç»ƒæ•°æ®
            val_data: éªŒè¯æ•°æ®ï¼ˆå¯é€‰ï¼‰
        """
        logger.info("å¼€å§‹è®­ç»ƒæ¨¡åž‹...")

        self.model.fit(train_data, val_data)

        logger.info("æ¨¡åž‹è®­ç»ƒå®Œæˆ")

    def _evaluate_model_on_test(
        self, train_data: pd.Series, val_data: Optional[pd.Series], test_data: pd.Series
    ) -> Dict[str, float]:
        """è¯„ä¼°æµ‹è¯•é›†ï¼ˆä»Žè®­ç»ƒ+éªŒè¯æ•°æ®æœ«å°¾é¢„æµ‹ï¼‰

        Args:
            train_data: è®­ç»ƒæ•°æ®ï¼ˆåŽŸå§‹å°ºåº¦ï¼‰
            val_data: éªŒè¯æ•°æ®ï¼ˆåŽŸå§‹å°ºåº¦ï¼Œå¯é€‰ï¼‰
            test_data: æµ‹è¯•æ•°æ®ï¼ˆåŽŸå§‹å°ºåº¦ï¼‰

        Returns:
            è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        logger.info("è¯„ä¼°æµ‹è¯•é›†ï¼ˆä»Žè®­ç»ƒ+éªŒè¯é›†æœ«å°¾é¢„æµ‹ï¼‰...")

        # å¦‚æžœæœ‰éªŒè¯é›†ï¼Œéœ€è¦åœ¨è®­ç»ƒ+éªŒè¯æ•°æ®ä¸Šæ›´æ–°æ¨¡åž‹é¢„æµ‹èµ·ç‚¹
        if val_data is not None:
            logger.info("åœ¨è®­ç»ƒ+éªŒè¯é›†ä¸Šæ›´æ–°æ¨¡åž‹é¢„æµ‹èµ·ç‚¹...")

            # åˆå¹¶è®­ç»ƒå’ŒéªŒè¯æ•°æ®
            combined_data = pd.concat([train_data, val_data])
            logger.info(
                f"åˆå¹¶æ•°æ®: è®­ç»ƒ({len(train_data)}) + éªŒè¯({len(val_data)}) = {len(combined_data)}"
            )

            # æ›´æ–°æ¨¡åž‹çš„é¢„æµ‹èµ·ç‚¹ï¼ˆä¸é‡æ–°è®­ç»ƒå‚æ•°ï¼Œåªæ›´æ–°èµ·ç‚¹ï¼‰
            self._update_model_for_prediction(combined_data)

            # ä½¿ç”¨åˆå¹¶æ•°æ®è¿›è¡Œå¯è§†åŒ–
            history_data = combined_data
        else:
            history_data = train_data

        # ä½¿ç”¨æ¨¡åž‹çš„ evaluate() æ–¹æ³•è¿›è¡Œè¯„ä¼°ï¼ˆè®©æ¨¡åž‹è‡ªå·±å†³å®šè¯„ä¼°ç­–ç•¥ï¼‰
        metrics = self.model.evaluate(test_data, mode="auto", is_in_sample=False)

        # æå–é¢„æµ‹å€¼ç”¨äºŽå¯è§†åŒ–ï¼ˆä½¿ç”¨ pop é¿å…æ±¡æŸ“æŒ‡æ ‡å­—å…¸ï¼‰
        predictions = metrics.pop("_predictions")
        y_true = metrics.pop("_y_true", test_data.values)
        # æ¸…ç†å…¶ä»–å†…éƒ¨æ•°æ®
        metrics.pop("_mode", None)
        metrics.pop("_is_in_sample", None)

        logger.info(f"æµ‹è¯•é›†è¯„ä¼°å®Œæˆ: {metrics}")

        # ç»˜åˆ¶å¯è§†åŒ–å›¾è¡¨
        if mlflow.active_run():
            from .mlflow_utils import MLFlowUtils

            # 1. é¢„æµ‹ç»“æžœå¯¹æ¯”å›¾
            MLFlowUtils.plot_prediction_results(
                train_data=history_data,
                test_data=test_data,
                predictions=predictions,
                title=f"{self.config.model_type.upper()} é¢„æµ‹ç»“æžœ",
                artifact_name=f"{self.config.model_type}_prediction",
                metrics=metrics,
            )

            # 2. æ®‹å·®åˆ†æžå›¾
            residuals = y_true - predictions
            MLFlowUtils.plot_residuals_analysis(
                residuals=residuals,
                title=f"{self.config.model_type.upper()} æ®‹å·®åˆ†æž",
                artifact_name=f"{self.config.model_type}_residuals",
            )

            logger.info("é¢„æµ‹å¯è§†åŒ–å›¾è¡¨å·²ä¸Šä¼ åˆ° MLflow")

        return metrics

    def _update_model_for_prediction(self, data: pd.Series):
        """æ›´æ–°æ¨¡åž‹çš„é¢„æµ‹èµ·ç‚¹ï¼ˆä¸é‡æ–°è®­ç»ƒå‚æ•°ï¼‰

        GradientBoosting: æ›´æ–°åŽ†å²æ•°æ®ï¼Œç¡®ä¿æœ‰å®Œæ•´ä¸Šä¸‹æ–‡æå–ç‰¹å¾

        Args:
            data: ç”¨ä½œé¢„æµ‹èµ·ç‚¹çš„åŽ†å²æ•°æ®ï¼ˆè®­ç»ƒé›†+éªŒè¯é›†çš„åˆå¹¶ï¼‰
        """
        model_type = self.config.model_type

        if model_type == "GradientBoosting":
            # GradientBoosting: æ›´æ–°åŽ†å²ä¸Šä¸‹æ–‡
            # ç†ç”±ï¼š
            # 1. GB ä½¿ç”¨é€’å½’é¢„æµ‹ï¼Œéœ€è¦å®Œæ•´çš„åŽ†å²åºåˆ—
            # 2. ç‰¹å¾å·¥ç¨‹éœ€è¦ä»ŽåŽ†å²ä¸­æå–æ»žåŽç‰¹å¾ã€æ»šåŠ¨ç‰¹å¾ç­‰
            # 3. æ¨¡åž‹å‚æ•°ä¸å˜ï¼Œåªæ›´æ–°ç”¨äºŽé¢„æµ‹çš„æ•°æ®ä¸Šä¸‹æ–‡
            from .models.gradient_boosting_model import GradientBoostingModel

            if isinstance(self.model, GradientBoostingModel):
                logger.info(f"æ›´æ–° GradientBoosting é¢„æµ‹èµ·ç‚¹ï¼Œæ•°æ®é•¿åº¦: {len(data)}")

                # æ›´æ–°å®Œæ•´çš„åŽ†å²æ•°æ®ï¼ˆåŒ…å«DatetimeIndexï¼‰
                self.model.last_train_data = data.copy()

                # æ›´æ–°æ»‘åŠ¨çª—å£çš„æœ€åŽå€¼
                max_window = max(self.model.lag_features, 50)
                self.model.last_train_values = data.values[-max_window:].copy()

                logger.debug(f"å·²æ›´æ–°é¢„æµ‹èµ·ç‚¹: å®Œæ•´åŽ†å²={len(data)}, çª—å£={max_window}")

        else:
            logger.warning(f"æ¨¡åž‹ç±»åž‹ {model_type} çš„é¢„æµ‹èµ·ç‚¹æ›´æ–°å°šæœªå®žçŽ°")

    def _log_config(self):
        """è®°å½•é…ç½®åˆ° MLflow"""
        config_dict = self.config.to_dict()

        # é€’å½’å±•å¹³åµŒå¥—é…ç½®ï¼ˆæ”¯æŒä»»æ„æ·±åº¦ï¼‰
        flat_config = MLFlowUtils.flatten_dict(config_dict)

        # è®°å½•æ¨¡åž‹å‚æ•°
        model_params = self.model.get_params()
        for key, value in model_params.items():
            flat_config[f"model_{key}"] = value

        MLFlowUtils.log_params_batch(flat_config)
        logger.debug(f"é…ç½®å·²è®°å½•åˆ° MLflowï¼Œå…± {len(flat_config)} ä¸ªå‚æ•°")

    def _save_model_to_mlflow(self) -> str:
        """ä¿å­˜æ¨¡åž‹åˆ° MLflowï¼ˆè‡ªåŠ¨æ”¯æŒæ‰€æœ‰å®žçŽ°äº† save_mlflow çš„æ¨¡åž‹ï¼‰

        Returns:
            æ¨¡åž‹ URI
        """
        logger.info("ä¿å­˜æ¨¡åž‹åˆ° MLflow...")

        model_type = self.config.model_type

        # æ£€æŸ¥æ¨¡åž‹æ˜¯å¦æœ‰ save_mlflow æ–¹æ³•ï¼ˆé¸­å­ç±»åž‹ï¼‰
        if hasattr(self.model, "save_mlflow") and callable(
            getattr(self.model, "save_mlflow")
        ):
            try:
                self.model.save_mlflow(artifact_path="model")
                logger.info(f"{model_type} æ¨¡åž‹å·²ä¿å­˜")
            except Exception as e:
                logger.error(f"æ¨¡åž‹ä¿å­˜å¤±è´¥: {e}")
                raise
        else:
            logger.warning(f"æ¨¡åž‹ç±»åž‹ {model_type} æ²¡æœ‰å®žçŽ° save_mlflow æ–¹æ³•")

        model_uri = f"runs:/{mlflow.active_run().info.run_id}/model"
        return model_uri

    def _register_model(self, model_uri: Optional[str]):
        """æ³¨å†Œæ¨¡åž‹åˆ° MLflow Model Registry

        Args:
            model_uri: æ¨¡åž‹ URI
        """
        if not model_uri:
            logger.warning("æ¨¡åž‹ URI ä¸ºç©ºï¼Œè·³è¿‡æ³¨å†Œ")
            return

        model_name = self.config.model_name

        try:
            logger.info(f"æ³¨å†Œæ¨¡åž‹åˆ° Model Registry: {model_name}")
            model_version = mlflow.register_model(model_uri, model_name)
            logger.info(f"æ¨¡åž‹æ³¨å†ŒæˆåŠŸ: {model_name}, ç‰ˆæœ¬: {model_version.version}")
        except Exception as e:
            logger.warning(f"æ¨¡åž‹æ³¨å†Œå¤±è´¥: {e}")

    def predict(self, steps: int) -> np.ndarray:
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹è¿›è¡Œé¢„æµ‹

        Args:
            steps: é¢„æµ‹æ­¥æ•°

        Returns:
            é¢„æµ‹ç»“æžœæ•°ç»„

        Raises:
            RuntimeError: æ¨¡åž‹æœªè®­ç»ƒ
        """
        if self.model is None:
            raise RuntimeError("æ¨¡åž‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ train() æ–¹æ³•")

        return self.model.predict(steps)

    def __repr__(self) -> str:
        model_info = f"model={self.model}" if self.model else "model=None"
        return f"UniversalTrainer(model_type={self.config.model_type}, {model_info})"
