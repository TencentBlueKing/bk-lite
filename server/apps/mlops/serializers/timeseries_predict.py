from rest_framework import serializers

from apps.core.utils.serializers import AuthSerializer
from apps.mlops.models.timeseries_predict import *
from apps.core.logger import opspilot_logger as logger


class TimeSeriesPredictDatasetSerializer(AuthSerializer):
    """æ—¶é—´åºåˆ—é¢„æµ‹æ•°æ®é›†åºåˆ—åŒ–å™¨"""

    permission_key = "dataset.timeseries_predict_dataset"

    class Meta:
        model = TimeSeriesPredictDataset
        fields = "__all__"


class TimeSeriesPredictTrainJobSerializer(AuthSerializer):
    """
    æ—¶é—´åºåˆ—é¢„æµ‹è®­ç»ƒä»»åŠ¡åºåˆ—åŒ–å™¨

    ä½¿ç”¨åŒå­—æ®µæ–¹æ¡ˆï¼š
    - hyperopt_config: JSONFieldï¼Œå­˜å‚¨åœ¨æ•°æ®åº“ï¼Œä¾›APIå¿«é€Ÿè¿”å›
    - config_url: FileFieldï¼Œè‡ªåŠ¨åŒæ­¥åˆ°MinIOï¼ˆModel.save()å¤„ç†ï¼‰
    """

    permission_key = "dataset.timeseries_predict_train_job"

    class Meta:
        model = TimeSeriesPredictTrainJob
        fields = "__all__"
        extra_kwargs = {
            "config_url": {
                "write_only": True,  # å‰ç«¯ä¸éœ€è¦çœ‹åˆ° MinIO è·¯å¾„
                "required": False,
            }
        }

    def validate(self, attrs):
        """
        éªŒè¯åˆ›å»ºæ—¶ dataset_version å¿…é¡»ä¼ å…¥
        """
        # åªåœ¨åˆ›å»ºæ—¶éªŒè¯ï¼ˆæ›´æ–°æ—¶ä¸å¼ºåˆ¶è¦æ±‚ï¼‰
        if not self.instance and not attrs.get("dataset_version"):
            raise serializers.ValidationError(
                {"dataset_version": "åˆ›å»ºè®­ç»ƒä»»åŠ¡æ—¶å¿…é¡»æŒ‡å®šæ•°æ®é›†ç‰ˆæœ¬"}
            )
        return super().validate(attrs)


class TimeSeriesPredictTrainDataSerializer(AuthSerializer):
    """æ—¶é—´åºåˆ—é¢„æµ‹è®­ç»ƒæ•°æ®åºåˆ—åŒ–å™¨"""

    permission_key = "dataset.timeseries_predict_train_data"

    class Meta:
        model = TimeSeriesPredictTrainData
        fields = "__all__"

    def __init__(self, *args, **kwargs):
        """
        åˆå§‹åŒ–åºåˆ—åŒ–å™¨ï¼Œä»è¯·æ±‚ä¸Šä¸‹æ–‡ä¸­è·å– include_train_data å‚æ•°
        """
        super().__init__(*args, **kwargs)
        request = self.context.get("request")
        if request:
            self.include_train_data = (
                request.query_params.get("include_train_data", "false").lower()
                == "true"
            )
            self.include_metadata = (
                request.query_params.get("include_metadata", "false").lower() == "true"
            )
        else:
            self.include_train_data = False
            self.include_metadata = False

    def validate_train_data(self, value):
        """æ ¡éªŒCSVæ ¼å¼"""
        import pandas as pd

        try:
            df = pd.read_csv(value)

            # æ£€æŸ¥å¿…éœ€åˆ—
            required_columns = ["timestamp", "value"]
            missing = set(required_columns) - set(df.columns)
            if missing:
                raise serializers.ValidationError(f"ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing)}")

            # æ£€æŸ¥æ•°æ®ç±»å‹
            if df["value"].isnull().any():
                raise serializers.ValidationError("'value'åˆ—åŒ…å«ç©ºå€¼")

            return value
        except pd.errors.ParserError as e:
            raise serializers.ValidationError(f"æ— æ•ˆçš„CSVæ ¼å¼: {str(e)}")

    def to_representation(self, instance):
        """
        è‡ªå®šä¹‰è¿”å›æ•°æ®ï¼Œæ ¹æ® include_train_data å‚æ•°åŠ¨æ€æ§åˆ¶ train_data å­—æ®µ
        å½“ include_train_data=true æ—¶ï¼Œåç«¯ç›´æ¥è¯»å– CSV å¹¶è§£æä¸ºç»“æ„åŒ–æ•°æ®è¿”å›
        """
        from apps.core.logger import opspilot_logger as logger
        import pandas as pd

        representation = super().to_representation(instance)

        # å¤„ç† train_dataï¼šåç«¯ç›´æ¥è¯»å–å¹¶è§£æ CSV
        if self.include_train_data and instance.train_data:
            try:
                # è¯»å– CSV æ–‡ä»¶
                df = pd.read_csv(instance.train_data.open("rb"))

                # ğŸ”¥ å¤„ç† timestamp å­—æ®µï¼šè½¬æ¢ä¸º Unix æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
                if "timestamp" in df.columns:
                    try:
                        # å°è¯•è§£æå„ç§æ—¥æœŸæ ¼å¼
                        df["timestamp"] = pd.to_datetime(df["timestamp"])
                        # è½¬æ¢ä¸º Unix æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
                        df["timestamp"] = (
                            df["timestamp"].astype("int64") / 1e9
                        ).astype("int64")
                    except Exception as e:
                        logger.warning(f"Failed to parse timestamp column: {e}")
                        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä¿æŒåŸå€¼

                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨å¹¶æ·»åŠ ç´¢å¼•
                data_list = df.to_dict("records")
                for i, row in enumerate(data_list):
                    row["index"] = i

                representation["train_data"] = data_list
                logger.info(
                    f"Successfully loaded train_data for instance {instance.id}: {len(data_list)} rows"
                )

            except Exception as e:
                logger.error(
                    f"Failed to read train_data for instance {instance.id}: {e}",
                    exc_info=True,
                )
                representation["train_data"] = []
                representation["error"] = f"è¯»å–è®­ç»ƒæ•°æ®å¤±è´¥: {str(e)}"
        elif not self.include_train_data:
            representation.pop("train_data", None)

        # å¤„ç† metadataï¼šS3JSONField è‡ªåŠ¨å¤„ç†ï¼Œç›´æ¥è¿”å›å¯¹è±¡
        if self.include_metadata and instance.metadata:
            # S3JSONField ä¼šè‡ªåŠ¨ä» MinIO è¯»å–å¹¶è§£å‹
            representation["metadata"] = instance.metadata
        elif not self.include_metadata:
            representation.pop("metadata", None)

        return representation


class TimeSeriesPredictServingSerializer(AuthSerializer):
    """æ—¶é—´åºåˆ—é¢„æµ‹æœåŠ¡åºåˆ—åŒ–å™¨"""

    permission_key = "dataset.timeseries_predict_serving"

    class Meta:
        model = TimeSeriesPredictServing
        fields = "__all__"


class TimeSeriesPredictDatasetReleaseSerializer(AuthSerializer):
    """æ—¶é—´åºåˆ—é¢„æµ‹æ•°æ®é›†å‘å¸ƒç‰ˆæœ¬åºåˆ—åŒ–å™¨"""

    permission_key = "dataset.timeseries_predict_dataset_release"

    # æ·»åŠ åªå†™å­—æ®µç”¨äºæ¥æ”¶æ–‡ä»¶ID
    train_file_id = serializers.IntegerField(write_only=True, required=False)
    val_file_id = serializers.IntegerField(write_only=True, required=False)
    test_file_id = serializers.IntegerField(write_only=True, required=False)

    class Meta:
        model = TimeSeriesPredictDatasetRelease
        fields = "__all__"
        extra_kwargs = {
            "name": {"required": False},  # åˆ›å»ºæ—¶å¯é€‰ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆ
            "dataset_file": {"required": False},  # åˆ›å»ºæ—¶ä¸éœ€è¦ç›´æ¥æä¾›æ–‡ä»¶
            "file_size": {"required": False},
            "status": {"required": False},
        }

    def create(self, validated_data):
        """
        è‡ªå®šä¹‰åˆ›å»ºæ–¹æ³•ï¼Œæ”¯æŒä»æ–‡ä»¶IDåˆ›å»ºæ•°æ®é›†å‘å¸ƒç‰ˆæœ¬
        """
        # æå–æ–‡ä»¶ID
        train_file_id = validated_data.pop("train_file_id", None)
        val_file_id = validated_data.pop("val_file_id", None)
        test_file_id = validated_data.pop("test_file_id", None)

        # å¦‚æœæä¾›äº†æ–‡ä»¶IDï¼Œåˆ™æ‰§è¡Œæ–‡ä»¶æ‰“åŒ…é€»è¾‘
        if train_file_id and val_file_id and test_file_id:
            return self._create_from_files(
                validated_data, train_file_id, val_file_id, test_file_id
            )
        else:
            # å¦åˆ™ä½¿ç”¨æ ‡å‡†åˆ›å»ºï¼ˆé€‚ç”¨äºç›´æ¥ä¸Šä¼ ZIPæ–‡ä»¶çš„åœºæ™¯ï¼‰
            return super().create(validated_data)

    def _create_from_files(
        self, validated_data, train_file_id, val_file_id, test_file_id
    ):
        """
        ä»è®­ç»ƒæ•°æ®æ–‡ä»¶IDåˆ›å»ºæ•°æ®é›†å‘å¸ƒç‰ˆæœ¬ï¼ˆå¼‚æ­¥ï¼‰

        åˆ›å»º pending çŠ¶æ€çš„è®°å½•ï¼Œè§¦å‘ Celery ä»»åŠ¡è¿›è¡Œå¼‚æ­¥å¤„ç†
        """
        dataset = validated_data.get("dataset")
        version = validated_data.get("version")
        name = validated_data.get("name")
        description = validated_data.get("description", "")

        try:
            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            train_obj = TimeSeriesPredictTrainData.objects.get(
                id=train_file_id, dataset=dataset
            )
            val_obj = TimeSeriesPredictTrainData.objects.get(
                id=val_file_id, dataset=dataset
            )
            test_obj = TimeSeriesPredictTrainData.objects.get(
                id=test_file_id, dataset=dataset
            )

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒç‰ˆæœ¬çš„è®°å½•ï¼ˆå¹‚ç­‰æ€§ä¿æŠ¤ï¼‰
            existing = (
                TimeSeriesPredictDatasetRelease.objects.filter(
                    dataset=dataset, version=version
                )
                .exclude(status="failed")
                .first()
            )

            if existing:
                logger.info(
                    f"æ•°æ®é›†ç‰ˆæœ¬å·²å­˜åœ¨ - Dataset: {dataset.id}, Version: {version}, Status: {existing.status}"
                )
                return existing

            # åˆ›å»º pending çŠ¶æ€çš„å‘å¸ƒè®°å½•
            validated_data["status"] = "pending"
            validated_data["file_size"] = 0
            validated_data["metadata"] = {}

            if not name:
                validated_data["name"] = f"{dataset.name}_v{version}"

            if not description:
                validated_data["description"] = (
                    f"ä»æ•°æ®é›†æ–‡ä»¶æ‰‹åŠ¨å‘å¸ƒ: {train_obj.name}, {val_obj.name}, {test_obj.name}"
                )

            release = TimeSeriesPredictDatasetRelease.objects.create(**validated_data)

            # è§¦å‘å¼‚æ­¥ä»»åŠ¡
            from apps.mlops.tasks.timeseries import publish_dataset_release_async

            publish_dataset_release_async.delay(
                release.id, train_file_id, val_file_id, test_file_id
            )

            logger.info(
                f"åˆ›å»ºæ•°æ®é›†å‘å¸ƒä»»åŠ¡ - Release ID: {release.id}, Dataset: {dataset.id}, Version: {version}"
            )

            return release

        except TimeSeriesPredictTrainData.DoesNotExist as e:
            logger.error(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ - {str(e)}")
            raise serializers.ValidationError(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸å±äºè¯¥æ•°æ®é›†")
        except Exception as e:
            logger.error(f"åˆ›å»ºæ•°æ®é›†å‘å¸ƒä»»åŠ¡å¤±è´¥ - {str(e)}", exc_info=True)
            raise serializers.ValidationError(f"åˆ›å»ºå‘å¸ƒä»»åŠ¡å¤±è´¥: {str(e)}")
